{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils.evaluation import *\n",
    "from utils.utils import *\n",
    "\n",
    "from data import dataset_preprocessing\n",
    "\n",
    "from utils.evaluation import get_metrics\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cortez\"\n",
    "mode=\"cv\"\n",
    "RS=68\n",
    "hct=10\n",
    "test_ratio=0.2\n",
    "val_ratio=0.1\n",
    "folds=5\n",
    "target = \"continuous\"\n",
    "experiment_name = \"EDM_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import arff # make sure to pip install liac-arff\n",
    "\n",
    "\n",
    "\n",
    "df_mat = pd.read_csv(f\"../data/raw/{dataset_name}/student-mat.csv\",sep=\";\")\n",
    "df_por = pd.read_csv(f\"../data/raw/{dataset_name}/student-por.csv\",sep=\";\")\n",
    "\n",
    "df_mat[\"subject\"] = \"mat\"\n",
    "df_por[\"subject\"] = \"por\"\n",
    "\n",
    "df = pd.concat([df_mat,df_por])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_col = \"G3\"\n",
    "demographic_cols = [\"sex\", \"age\", \"school\", \"address\", \"famsize\", \"famrel\", \"Pstatus\", \"Medu\", \"Fedu\", \"Mjob\", \"Fjob\",\"reason\",\"guardian\", \"traveltime\", \"famsup\",\"paid\",\"internet\"]\n",
    "perf_cols = [\"G1\",\"G2\", \"failures\"]\n",
    "activity_cols = [\"studytime\", \"schoolsup\", 'activities', 'nursery', 'higher', 'absences']\n",
    "other_cols = [\"subject\", \"Dalc\", \"Walc\", \"health\", 'freetime', 'goout', 'romantic']\n",
    "cat_cols = list(set(df.columns[np.logical_and(df.dtypes == \"object\", df.nunique()>2)]) - set([y_col]))\n",
    "\n",
    "set(df.columns)-set([y_col]+demographic_cols+perf_cols+activity_cols+other_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. of samples</th>\n",
       "      <th>No. of features</th>\n",
       "      <th>Performance features</th>\n",
       "      <th>Demographic features</th>\n",
       "      <th>Activity features</th>\n",
       "      <th>Other features</th>\n",
       "      <th>Categorical features</th>\n",
       "      <th>Total cardinality</th>\n",
       "      <th>% NA</th>\n",
       "      <th>Target $\\textbf{y} \\in$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cortez</th>\n",
       "      <td>1044</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1..19]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        No. of samples  No. of features  Performance features  \\\n",
       "cortez            1044               34                     3   \n",
       "\n",
       "        Demographic features  Activity features  Other features  \\\n",
       "cortez                    17                  6               7   \n",
       "\n",
       "        Categorical features  Total cardinality  % NA Target $\\textbf{y} \\in$  \n",
       "cortez                     4                 17   0.0                 [1..19]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_df_dict = {\"No. of samples\": df.shape[0],\n",
    "           \"No. of features\": df.shape[1],\n",
    "           \"Performance features\": len(perf_cols),\n",
    "           \"Demographic features\": len(demographic_cols),\n",
    "           \"Activity features\": len(activity_cols),\n",
    "           \"Other features\": len(other_cols),\n",
    "           \"Categorical features\": len(df.columns[list(np.logical_and(df.nunique() > 2, df.dtypes == \"object\"))]),     \n",
    "           \"Total cardinality\": df[df.columns[list(np.logical_and(df.nunique() > 2, df.dtypes == \"object\"))]].nunique().sum(),     \n",
    "           \"% NA\": df.isna().sum().sum()/sum(df.shape),\n",
    "           \"Target $\\textbf{y} \\in$\": f\"[1..{df[y_col].nunique()}]\",\n",
    "#            \"High cardinality levels\":  list(df.loc[:,list(df.columns[list(np.logical_and(df.nunique() >= 10, df.dtypes == \"object\"))])].nunique().sort_values().values),\n",
    "          \n",
    "}\n",
    "desc_df = pd.DataFrame([desc_df_dict],index=[\"cortez\"])\n",
    "desc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "{} &   cortez \\\\\n",
      "\\midrule\n",
      "No. of samples          &     1044 \\\\\n",
      "No. of features         &       34 \\\\\n",
      "Performance features    &        3 \\\\\n",
      "Demographic features    &       17 \\\\\n",
      "Activity features       &        6 \\\\\n",
      "Other features          &        7 \\\\\n",
      "Categorical features    &        4 \\\\\n",
      "Total cardinality       &       17 \\\\\n",
      "\\% NA                    &        0 \\\\\n",
      "Target \\$\\textbackslash textbf\\{y\\} \\textbackslash in\\$ &  [1..19] \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(desc_df.transpose().to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = f\"{mode}_RS{RS}_hct{hct}\"\n",
    "if mode == \"cv\":\n",
    "    data_path += f\"_{folds}folds\"\n",
    "elif mode == \"train_test\":\n",
    "    data_path += f\"_split{1-test_ratio*100}-{test_ratio*100}\"\n",
    "elif mode == \"train_val_test\":\n",
    "    data_path += f\"_split{round(100-(test_ratio+val_ratio)*100)}-{round(test_ratio*100)}-{round(val_ratio*100)}\"\n",
    "\n",
    "\n",
    "# If no data_dict for the configuration exists, run preprocessing, else load data_dict\n",
    "if not os.path.exists(f\"../data/prepared/{dataset_name}/\"+data_path+\"/data_dict.pickle\"):\n",
    "    dataset_preprocessing.process_dataset(dataset_name, target, mode, RS, hct, test_ratio, val_ratio, folds)\n",
    "with open(f\"../data/prepared/{dataset_name}/{data_path}/data_dict.pickle\", 'rb') as handle:\n",
    "        data_dict = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of categorical data treatment methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\"ignore\", \"ohe\", \"target\", \"ordinal\", \"catboost\", \"glmm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_rounds = 10\n",
    "max_evals = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row5_col1 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row5_col2 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row24_col4 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row24_col5 {\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >RMSE Train</th>        <th class=\"col_heading level0 col1\" >MSE Train</th>        <th class=\"col_heading level0 col2\" >R2 Train</th>        <th class=\"col_heading level0 col3\" >RMSE Test</th>        <th class=\"col_heading level0 col4\" >MSE Test</th>        <th class=\"col_heading level0 col5\" >R2 Test</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row0\" class=\"row_heading level0 row0\" >Baseline</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row0_col0\" class=\"data row0 col0\" >3.850500</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row0_col1\" class=\"data row0 col1\" >14.826700</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row0_col2\" class=\"data row0 col2\" >-0.000000</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row0_col3\" class=\"data row0 col3\" >3.918300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row0_col4\" class=\"data row0 col4\" >15.352800</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row0_col5\" class=\"data row0 col5\" >-0.013400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row1\" class=\"row_heading level0 row1\" >XGB_target</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row1_col0\" class=\"data row1 col0\" >0.049800</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row1_col1\" class=\"data row1 col1\" >0.002500</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row1_col2\" class=\"data row1 col2\" >0.999800</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row1_col3\" class=\"data row1 col3\" >1.725600</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row1_col4\" class=\"data row1 col4\" >2.977700</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row1_col5\" class=\"data row1 col5\" >0.803500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row2\" class=\"row_heading level0 row2\" >XGB_ohe</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row2_col0\" class=\"data row2 col0\" >0.042700</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row2_col1\" class=\"data row2 col1\" >0.001800</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row2_col2\" class=\"data row2 col2\" >0.999900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row2_col3\" class=\"data row2 col3\" >1.693500</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row2_col4\" class=\"data row2 col4\" >2.868100</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row2_col5\" class=\"data row2 col5\" >0.810700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row3\" class=\"row_heading level0 row3\" >XGB_ordinal</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row3_col0\" class=\"data row3 col0\" >0.045800</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row3_col1\" class=\"data row3 col1\" >0.002100</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row3_col2\" class=\"data row3 col2\" >0.999900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row3_col3\" class=\"data row3 col3\" >1.673300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row3_col4\" class=\"data row3 col4\" >2.799800</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row3_col5\" class=\"data row3 col5\" >0.815200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row4\" class=\"row_heading level0 row4\" >XGB_ignore</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row4_col0\" class=\"data row4 col0\" >0.054100</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row4_col1\" class=\"data row4 col1\" >0.002900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row4_col2\" class=\"data row4 col2\" >0.999800</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row4_col3\" class=\"data row4 col3\" >1.647400</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row4_col4\" class=\"data row4 col4\" >2.714000</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row4_col5\" class=\"data row4 col5\" >0.820900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row5\" class=\"row_heading level0 row5\" >XGB_catboost</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row5_col0\" class=\"data row5 col0\" >0.023900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row5_col1\" class=\"data row5 col1\" >0.000600</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row5_col2\" class=\"data row5 col2\" >1.000000</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row5_col3\" class=\"data row5 col3\" >1.642400</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row5_col4\" class=\"data row5 col4\" >2.697400</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row5_col5\" class=\"data row5 col5\" >0.822000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row6\" class=\"row_heading level0 row6\" >XGB_glmm</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row6_col0\" class=\"data row6 col0\" >0.029400</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row6_col1\" class=\"data row6 col1\" >0.000900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row6_col2\" class=\"data row6 col2\" >0.999900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row6_col3\" class=\"data row6 col3\" >1.642000</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row6_col4\" class=\"data row6 col4\" >2.696100</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row6_col5\" class=\"data row6 col5\" >0.822000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row7\" class=\"row_heading level0 row7\" >LR_ohe_tuned</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row7_col0\" class=\"data row7 col0\" >1.532000</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row7_col1\" class=\"data row7 col1\" >2.347100</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row7_col2\" class=\"data row7 col2\" >0.841700</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row7_col3\" class=\"data row7 col3\" >1.610800</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row7_col4\" class=\"data row7 col4\" >2.594700</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row7_col5\" class=\"data row7 col5\" >0.828700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row8\" class=\"row_heading level0 row8\" >LR_glmm_tuned</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row8_col0\" class=\"data row8 col0\" >1.526100</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row8_col1\" class=\"data row8 col1\" >2.328900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row8_col2\" class=\"data row8 col2\" >0.842900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row8_col3\" class=\"data row8 col3\" >1.603400</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row8_col4\" class=\"data row8 col4\" >2.571000</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row8_col5\" class=\"data row8 col5\" >0.830300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row9\" class=\"row_heading level0 row9\" >LR_ignore_tuned</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row9_col0\" class=\"data row9 col0\" >1.524000</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row9_col1\" class=\"data row9 col1\" >2.322700</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row9_col2\" class=\"data row9 col2\" >0.843300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row9_col3\" class=\"data row9 col3\" >1.601300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row9_col4\" class=\"data row9 col4\" >2.564100</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row9_col5\" class=\"data row9 col5\" >0.830800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row10\" class=\"row_heading level0 row10\" >LR_ignore</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row10_col0\" class=\"data row10 col0\" >1.506400</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row10_col1\" class=\"data row10 col1\" >2.269200</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row10_col2\" class=\"data row10 col2\" >0.846900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row10_col3\" class=\"data row10 col3\" >1.600700</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row10_col4\" class=\"data row10 col4\" >2.562300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row10_col5\" class=\"data row10 col5\" >0.830900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row11\" class=\"row_heading level0 row11\" >LR_target</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row11_col0\" class=\"data row11 col0\" >1.506400</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row11_col1\" class=\"data row11 col1\" >2.269200</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row11_col2\" class=\"data row11 col2\" >0.846900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row11_col3\" class=\"data row11 col3\" >1.600700</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row11_col4\" class=\"data row11 col4\" >2.562300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row11_col5\" class=\"data row11 col5\" >0.830900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row12\" class=\"row_heading level0 row12\" >LR_glmm</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row12_col0\" class=\"data row12 col0\" >1.506400</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row12_col1\" class=\"data row12 col1\" >2.269200</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row12_col2\" class=\"data row12 col2\" >0.846900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row12_col3\" class=\"data row12 col3\" >1.600700</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row12_col4\" class=\"data row12 col4\" >2.562300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row12_col5\" class=\"data row12 col5\" >0.830900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row13\" class=\"row_heading level0 row13\" >XGB_ordinal_tuned</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row13_col0\" class=\"data row13 col0\" >0.688000</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row13_col1\" class=\"data row13 col1\" >0.473300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row13_col2\" class=\"data row13 col2\" >0.968100</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row13_col3\" class=\"data row13 col3\" >1.600300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row13_col4\" class=\"data row13 col4\" >2.560900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row13_col5\" class=\"data row13 col5\" >0.831000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row14\" class=\"row_heading level0 row14\" >LR_catboost_tuned</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row14_col0\" class=\"data row14 col0\" >1.522300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row14_col1\" class=\"data row14 col1\" >2.317300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row14_col2\" class=\"data row14 col2\" >0.843700</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row14_col3\" class=\"data row14 col3\" >1.600100</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row14_col4\" class=\"data row14 col4\" >2.560400</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row14_col5\" class=\"data row14 col5\" >0.831000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row15\" class=\"row_heading level0 row15\" >LR_catboost</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row15_col0\" class=\"data row15 col0\" >1.506300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row15_col1\" class=\"data row15 col1\" >2.268900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row15_col2\" class=\"data row15 col2\" >0.847000</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row15_col3\" class=\"data row15 col3\" >1.599600</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row15_col4\" class=\"data row15 col4\" >2.558700</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row15_col5\" class=\"data row15 col5\" >0.831100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row16\" class=\"row_heading level0 row16\" >LR_ordinal</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row16_col0\" class=\"data row16 col0\" >1.505100</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row16_col1\" class=\"data row16 col1\" >2.265300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row16_col2\" class=\"data row16 col2\" >0.847200</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row16_col3\" class=\"data row16 col3\" >1.599600</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row16_col4\" class=\"data row16 col4\" >2.558600</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row16_col5\" class=\"data row16 col5\" >0.831100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row17\" class=\"row_heading level0 row17\" >LR_target_tuned</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row17_col0\" class=\"data row17 col0\" >1.519500</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row17_col1\" class=\"data row17 col1\" >2.308900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row17_col2\" class=\"data row17 col2\" >0.844300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row17_col3\" class=\"data row17 col3\" >1.598300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row17_col4\" class=\"data row17 col4\" >2.554700</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row17_col5\" class=\"data row17 col5\" >0.831400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row18\" class=\"row_heading level0 row18\" >LR_ohe</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row18_col0\" class=\"data row18 col0\" >1.501600</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row18_col1\" class=\"data row18 col1\" >2.254900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row18_col2\" class=\"data row18 col2\" >0.847900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row18_col3\" class=\"data row18 col3\" >1.597800</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row18_col4\" class=\"data row18 col4\" >2.552800</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row18_col5\" class=\"data row18 col5\" >0.831500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row19\" class=\"row_heading level0 row19\" >LR_ordinal_tuned</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row19_col0\" class=\"data row19 col0\" >1.516500</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row19_col1\" class=\"data row19 col1\" >2.299800</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row19_col2\" class=\"data row19 col2\" >0.844900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row19_col3\" class=\"data row19 col3\" >1.596800</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row19_col4\" class=\"data row19 col4\" >2.549700</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row19_col5\" class=\"data row19 col5\" >0.831700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row20\" class=\"row_heading level0 row20\" >XGB_glmm_tuned</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row20_col0\" class=\"data row20 col0\" >0.887700</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row20_col1\" class=\"data row20 col1\" >0.788000</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row20_col2\" class=\"data row20 col2\" >0.946900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row20_col3\" class=\"data row20 col3\" >1.537100</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row20_col4\" class=\"data row20 col4\" >2.362600</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row20_col5\" class=\"data row20 col5\" >0.844100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row21\" class=\"row_heading level0 row21\" >XGB_catboost_tuned</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row21_col0\" class=\"data row21 col0\" >1.029400</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row21_col1\" class=\"data row21 col1\" >1.059600</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row21_col2\" class=\"data row21 col2\" >0.928500</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row21_col3\" class=\"data row21 col3\" >1.504600</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row21_col4\" class=\"data row21 col4\" >2.264000</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row21_col5\" class=\"data row21 col5\" >0.850600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row22\" class=\"row_heading level0 row22\" >XGB_ohe_tuned</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row22_col0\" class=\"data row22 col0\" >1.030800</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row22_col1\" class=\"data row22 col1\" >1.062500</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row22_col2\" class=\"data row22 col2\" >0.928300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row22_col3\" class=\"data row22 col3\" >1.495600</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row22_col4\" class=\"data row22 col4\" >2.236800</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row22_col5\" class=\"data row22 col5\" >0.852400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row23\" class=\"row_heading level0 row23\" >XGB_target_tuned</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row23_col0\" class=\"data row23 col0\" >1.214300</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row23_col1\" class=\"data row23 col1\" >1.474600</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row23_col2\" class=\"data row23 col2\" >0.900500</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row23_col3\" class=\"data row23 col3\" >1.447800</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row23_col4\" class=\"data row23 col4\" >2.096100</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row23_col5\" class=\"data row23 col5\" >0.861600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7level0_row24\" class=\"row_heading level0 row24\" >XGB_ignore_tuned</th>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row24_col0\" class=\"data row24 col0\" >1.167500</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row24_col1\" class=\"data row24 col1\" >1.362900</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row24_col2\" class=\"data row24 col2\" >0.908100</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row24_col3\" class=\"data row24 col3\" >1.429500</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row24_col4\" class=\"data row24 col4\" >2.043400</td>\n",
       "                        <td id=\"T_215f65ae_9825_11ed_9eb1_59b4c8c782b7row24_col5\" class=\"data row24 col5\" >0.865100</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa7f83d4a00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(f\"../results/{dataset_name}/{experiment_name}/results_encodings.pickle\"):\n",
    "\n",
    "    results_encodings = {}\n",
    "    results_encodings_feature_importances = {}\n",
    "\n",
    "    for fold in range(folds):\n",
    "        target_scaler = data_dict[f\"target_scaler_{fold}\"]\n",
    "        results_encodings[fold] = {}\n",
    "        results_encodings_feature_importances[fold] = {}\n",
    "        # Create baseline\n",
    "        y_train = data_dict[f\"y_train_{fold}\"]\n",
    "        y_val = data_dict[f\"y_val_{fold}\"]\n",
    "        y_test = target_scaler.inverse_transform(data_dict[f\"y_test_{fold}\"].reshape(-1,1)).ravel()\n",
    "        y_train_val = target_scaler.inverse_transform(np.concatenate([y_train,y_val]).reshape(-1,1)).ravel()\n",
    "\n",
    "        y_train_val_pred_base = np.ones(y_train_val.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "        y_test_pred_base = np.ones(y_test.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "\n",
    "        results_encodings[fold][\"Baseline\"] = {}\n",
    "        eval_res_train = get_metrics(y_train_val, y_train_val_pred_base, target=target)\n",
    "        for metric in eval_res_train.keys():\n",
    "            results_encodings[fold][\"Baseline\"][metric + \" Train\"] = eval_res_train[metric]\n",
    "        eval_res_test = get_metrics(y_test, y_test_pred_base, target=target)\n",
    "        for metric in eval_res_test.keys():\n",
    "            results_encodings[fold][\"Baseline\"][metric + \" Test\"] = eval_res_test[metric]\n",
    "        results_encodings[fold][\"Baseline\"][\"RMSE Test\"] = np.sqrt(results_encodings[fold][\"Baseline\"][\"MSE Test\"])\n",
    "        results_encodings[fold][\"Baseline\"][\"RMSE Train\"] = np.sqrt(results_encodings[fold][\"Baseline\"][\"MSE Train\"])\n",
    "\n",
    "\n",
    "        for condition in conditions:\n",
    "            print(f\"Preparing results for fold {fold}, condition={condition}\")\n",
    "            # Retrieve data\n",
    "            z_cols = data_dict[\"z_cols\"]\n",
    "\n",
    "            X_train = data_dict[f\"X_train_{fold}\"]\n",
    "            y_train = data_dict[f\"y_train_{fold}\"]\n",
    "\n",
    "            X_val = data_dict[f\"X_val_{fold}\"]\n",
    "            y_val = data_dict[f\"y_val_{fold}\"]\n",
    "\n",
    "            X_test = data_dict[f\"X_test_{fold}\"]\n",
    "            y_test = data_dict[f\"y_test_{fold}\"]\n",
    "\n",
    "    #         Define condition data subset\n",
    "            if condition != \"ignore\":\n",
    "                z_encoded_train = data_dict[f\"z_{condition}_encoded_train_{fold}\"] \n",
    "                z_encoded_val = data_dict[f\"z_{condition}_encoded_val_{fold}\"] \n",
    "                z_encoded_test = data_dict[f\"z_{condition}_encoded_test_{fold}\"] \n",
    "\n",
    "                X_train = pd.concat([X_train,z_encoded_train],axis=1)\n",
    "                X_val = pd.concat([X_val,z_encoded_val],axis=1)\n",
    "                X_test = pd.concat([X_test,z_encoded_test],axis=1)\n",
    "\n",
    "            X_train_val = pd.concat([X_train,X_val])\n",
    "            y_train_val = np.concatenate([y_train,y_val])\n",
    "\n",
    "            # Train base models\n",
    "            res, feats = evaluate_lr(X_train_val, y_train_val, X_test, y_test, target=target,tune=False, seed=RS, target_scaler=target_scaler)\n",
    "            results_encodings[fold][\"LR_\"+condition] = res\n",
    "            results_encodings_feature_importances[fold][\"LR_\"+condition] = feats\n",
    "            results_encodings[fold][\"LR_\"+condition][\"RMSE Test\"] = np.sqrt(results_encodings[fold][\"LR_\"+condition][\"MSE Test\"])\n",
    "            results_encodings[fold][\"LR_\"+condition][\"RMSE Train\"] = np.sqrt(results_encodings[fold][\"LR_\"+condition][\"MSE Train\"])\n",
    "\n",
    "            res, feats = evaluate_xgb(X_train_val, y_train_val, X_test, y_test, target, tune=False, max_evals=max_evals, early_stopping_rounds=early_stopping_rounds, seed=RS, target_scaler=target_scaler)\n",
    "            results_encodings[fold][\"XGB_\"+condition] = res\n",
    "            results_encodings_feature_importances[fold][\"XGB_\"+condition] = feats\n",
    "            results_encodings[fold][\"XGB_\"+condition][\"RMSE Test\"] = np.sqrt(results_encodings[fold][\"XGB_\"+condition][\"MSE Test\"])\n",
    "            results_encodings[fold][\"XGB_\"+condition][\"RMSE Train\"] = np.sqrt(results_encodings[fold][\"XGB_\"+condition][\"MSE Train\"])\n",
    "\n",
    "            # Train tuned models\n",
    "            res, feats = evaluate_lr(X_train_val, y_train_val, X_test, y_test, target=target, max_evals=max_evals, tune=True, seed=RS, target_scaler=target_scaler)\n",
    "            results_encodings[fold][\"LR_\"+condition+\"_tuned\"] = res\n",
    "            results_encodings_feature_importances[fold][\"LR_\"+condition+\"_tuned\"] = feats\n",
    "            results_encodings[fold][\"LR_\"+condition+\"_tuned\"][\"RMSE Test\"] = np.sqrt(results_encodings[fold][\"LR_\"+condition+\"_tuned\"][\"MSE Test\"])\n",
    "            results_encodings[fold][\"LR_\"+condition+\"_tuned\"][\"RMSE Train\"] = np.sqrt(results_encodings[fold][\"LR_\"+condition+\"_tuned\"][\"MSE Train\"])\n",
    "\n",
    "            res, feats = evaluate_xgb(X_train_val, y_train_val, X_test, y_test, target, tune=True, max_evals=max_evals, early_stopping_rounds=early_stopping_rounds, seed=RS, target_scaler=target_scaler)\n",
    "            results_encodings[fold][\"XGB_\"+condition+\"_tuned\"] = res\n",
    "            results_encodings_feature_importances[fold][\"XGB_\"+condition+\"_tuned\"] = feats\n",
    "            results_encodings[fold][\"XGB_\"+condition+\"_tuned\"][\"RMSE Test\"] = np.sqrt(results_encodings[fold][\"XGB_\"+condition+\"_tuned\"][\"MSE Test\"])\n",
    "            results_encodings[fold][\"XGB_\"+condition+\"_tuned\"][\"RMSE Train\"] = np.sqrt(results_encodings[fold][\"XGB_\"+condition+\"_tuned\"][\"MSE Train\"])\n",
    "    \n",
    "    if not os.path.exists(f\"../results/{dataset_name}/{experiment_name}\"):\n",
    "        os.makedirs(f\"../results/{dataset_name}/{experiment_name}\")\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_encodings.pickle\", 'wb') as handle:\n",
    "        pickle.dump(results_encodings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_encodings_feature_importances.pickle\", 'wb') as handle:\n",
    "        pickle.dump(results_encodings_feature_importances, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_encodings.pickle\", 'rb') as handle:\n",
    "        results_encodings = pickle.load(handle)\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_encodings_feature_importances.pickle\", 'rb') as handle:\n",
    "        results_encodings_feature_importances = pickle.load(handle)\n",
    "    for fold in range(folds):\n",
    "        target_scaler = data_dict[f\"target_scaler_{fold}\"]\n",
    "        # Create baseline\n",
    "        y_train = data_dict[f\"y_train_{fold}\"]\n",
    "        y_val = data_dict[f\"y_val_{fold}\"]\n",
    "        y_test = target_scaler.inverse_transform(data_dict[f\"y_test_{fold}\"].reshape(-1,1)).ravel()\n",
    "        y_train_val = target_scaler.inverse_transform(np.concatenate([y_train,y_val]).reshape(-1,1)).ravel()\n",
    "\n",
    "        y_train_val_pred_base = np.ones(y_train_val.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "        y_test_pred_base = np.ones(y_test.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "\n",
    "        results_encodings[fold][\"Baseline\"] = {}\n",
    "        eval_res_train = get_metrics(y_train_val, y_train_val_pred_base, target=target)\n",
    "        for metric in eval_res_train.keys():\n",
    "            results_encodings[fold][\"Baseline\"][metric + \" Train\"] = eval_res_train[metric]\n",
    "        eval_res_test = get_metrics(y_test, y_test_pred_base, target=target)\n",
    "        for metric in eval_res_test.keys():\n",
    "            results_encodings[fold][\"Baseline\"][metric + \" Test\"] = eval_res_test[metric]\n",
    "        results_encodings[fold][\"Baseline\"][\"RMSE Test\"] = np.sqrt(results_encodings[fold][\"Baseline\"][\"MSE Test\"])\n",
    "        results_encodings[fold][\"Baseline\"][\"RMSE Train\"] = np.sqrt(results_encodings[fold][\"Baseline\"][\"MSE Train\"])\n",
    "        \n",
    "        \n",
    "results_encodings_df = pd.DataFrame(results_encodings[0]).transpose().sort_values(\"MSE Test\",ascending=False).round(4)\n",
    "results_encodings_df[[\"RMSE Train\", \"MSE Train\", \"R2 Train\", \"RMSE Test\", \"MSE Test\", \"R2 Test\"]].style.highlight_min(subset=[\"MSE Train\", \"MSE Test\"], color = 'lightgreen', axis = 0).highlight_max(subset=[\"R2 Train\", \"R2 Test\"], color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row1_col1 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row1_col2 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row24_col4 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row24_col5 {\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >RMSE Train</th>        <th class=\"col_heading level0 col1\" >MSE Train</th>        <th class=\"col_heading level0 col2\" >R2 Train</th>        <th class=\"col_heading level0 col3\" >RMSE Test</th>        <th class=\"col_heading level0 col4\" >MSE Test</th>        <th class=\"col_heading level0 col5\" >R2 Test</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row0\" class=\"row_heading level0 row0\" >Baseline</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row0_col0\" class=\"data row0 col0\" >3.822300</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row0_col1\" class=\"data row0 col1\" >14.610200</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row0_col2\" class=\"data row0 col2\" >-0.000000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row0_col3\" class=\"data row0 col3\" >4.022300</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row0_col4\" class=\"data row0 col4\" >16.178500</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row0_col5\" class=\"data row0 col5\" >-0.001800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row1\" class=\"row_heading level0 row1\" >XGB_catboost</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row1_col0\" class=\"data row1 col0\" >0.026500</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row1_col1\" class=\"data row1 col1\" >0.000700</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row1_col3\" class=\"data row1 col3\" >1.966100</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row1_col4\" class=\"data row1 col4\" >3.865700</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row1_col5\" class=\"data row1 col5\" >0.760600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row2\" class=\"row_heading level0 row2\" >LR_catboost</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row2_col0\" class=\"data row2 col0\" >1.479300</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row2_col1\" class=\"data row2 col1\" >2.188400</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row2_col2\" class=\"data row2 col2\" >0.850200</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row2_col3\" class=\"data row2 col3\" >1.724900</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row2_col4\" class=\"data row2 col4\" >2.975100</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row2_col5\" class=\"data row2 col5\" >0.815800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row3\" class=\"row_heading level0 row3\" >LR_ignore</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row3_col0\" class=\"data row3 col0\" >1.484700</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row3_col1\" class=\"data row3 col1\" >2.204300</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row3_col2\" class=\"data row3 col2\" >0.849100</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row3_col3\" class=\"data row3 col3\" >1.697600</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row3_col4\" class=\"data row3 col4\" >2.882000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row3_col5\" class=\"data row3 col5\" >0.821500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row4\" class=\"row_heading level0 row4\" >LR_target</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row4_col0\" class=\"data row4 col0\" >1.484700</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row4_col1\" class=\"data row4 col1\" >2.204300</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row4_col2\" class=\"data row4 col2\" >0.849100</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row4_col3\" class=\"data row4 col3\" >1.697600</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row4_col4\" class=\"data row4 col4\" >2.882000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row4_col5\" class=\"data row4 col5\" >0.821500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row5\" class=\"row_heading level0 row5\" >LR_glmm</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row5_col0\" class=\"data row5 col0\" >1.484200</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row5_col1\" class=\"data row5 col1\" >2.202900</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row5_col2\" class=\"data row5 col2\" >0.849200</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row5_col3\" class=\"data row5 col3\" >1.697400</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row5_col4\" class=\"data row5 col4\" >2.881000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row5_col5\" class=\"data row5 col5\" >0.821600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row6\" class=\"row_heading level0 row6\" >LR_ordinal</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row6_col0\" class=\"data row6 col0\" >1.482400</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row6_col1\" class=\"data row6 col1\" >2.197500</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row6_col2\" class=\"data row6 col2\" >0.849600</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row6_col3\" class=\"data row6 col3\" >1.696500</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row6_col4\" class=\"data row6 col4\" >2.878000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row6_col5\" class=\"data row6 col5\" >0.821800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row7\" class=\"row_heading level0 row7\" >LR_ohe</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row7_col0\" class=\"data row7 col0\" >1.478200</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row7_col1\" class=\"data row7 col1\" >2.184900</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row7_col2\" class=\"data row7 col2\" >0.850400</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row7_col3\" class=\"data row7 col3\" >1.695700</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row7_col4\" class=\"data row7 col4\" >2.875400</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row7_col5\" class=\"data row7 col5\" >0.822000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row8\" class=\"row_heading level0 row8\" >LR_ignore_tuned</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row8_col0\" class=\"data row8 col0\" >1.497600</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row8_col1\" class=\"data row8 col1\" >2.242800</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row8_col2\" class=\"data row8 col2\" >0.846500</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row8_col3\" class=\"data row8 col3\" >1.662200</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row8_col4\" class=\"data row8 col4\" >2.763000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row8_col5\" class=\"data row8 col5\" >0.828900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row9\" class=\"row_heading level0 row9\" >LR_ordinal_tuned</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row9_col0\" class=\"data row9 col0\" >1.497900</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row9_col1\" class=\"data row9 col1\" >2.243600</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row9_col2\" class=\"data row9 col2\" >0.846400</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row9_col3\" class=\"data row9 col3\" >1.658700</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row9_col4\" class=\"data row9 col4\" >2.751200</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row9_col5\" class=\"data row9 col5\" >0.829600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row10\" class=\"row_heading level0 row10\" >LR_catboost_tuned</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row10_col0\" class=\"data row10 col0\" >1.500900</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row10_col1\" class=\"data row10 col1\" >2.252700</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row10_col2\" class=\"data row10 col2\" >0.845800</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row10_col3\" class=\"data row10 col3\" >1.657400</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row10_col4\" class=\"data row10 col4\" >2.747000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row10_col5\" class=\"data row10 col5\" >0.829900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row11\" class=\"row_heading level0 row11\" >LR_glmm_tuned</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row11_col0\" class=\"data row11 col0\" >1.501400</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row11_col1\" class=\"data row11 col1\" >2.254100</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row11_col2\" class=\"data row11 col2\" >0.845700</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row11_col3\" class=\"data row11 col3\" >1.656900</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row11_col4\" class=\"data row11 col4\" >2.745500</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row11_col5\" class=\"data row11 col5\" >0.830000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row12\" class=\"row_heading level0 row12\" >LR_ohe_tuned</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row12_col0\" class=\"data row12 col0\" >1.505600</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row12_col1\" class=\"data row12 col1\" >2.266800</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row12_col2\" class=\"data row12 col2\" >0.844800</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row12_col3\" class=\"data row12 col3\" >1.652800</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row12_col4\" class=\"data row12 col4\" >2.731700</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row12_col5\" class=\"data row12 col5\" >0.830900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row13\" class=\"row_heading level0 row13\" >LR_target_tuned</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row13_col0\" class=\"data row13 col0\" >1.506300</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row13_col1\" class=\"data row13 col1\" >2.269000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row13_col2\" class=\"data row13 col2\" >0.844700</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row13_col3\" class=\"data row13 col3\" >1.652300</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row13_col4\" class=\"data row13 col4\" >2.730000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row13_col5\" class=\"data row13 col5\" >0.831000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row14\" class=\"row_heading level0 row14\" >XGB_glmm</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row14_col0\" class=\"data row14 col0\" >0.031300</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row14_col1\" class=\"data row14 col1\" >0.001000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row14_col2\" class=\"data row14 col2\" >0.999900</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row14_col3\" class=\"data row14 col3\" >1.579100</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row14_col4\" class=\"data row14 col4\" >2.493600</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row14_col5\" class=\"data row14 col5\" >0.845600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row15\" class=\"row_heading level0 row15\" >XGB_target</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row15_col0\" class=\"data row15 col0\" >0.057800</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row15_col1\" class=\"data row15 col1\" >0.003300</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row15_col2\" class=\"data row15 col2\" >0.999800</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row15_col3\" class=\"data row15 col3\" >1.575000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row15_col4\" class=\"data row15 col4\" >2.480600</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row15_col5\" class=\"data row15 col5\" >0.846400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row16\" class=\"row_heading level0 row16\" >XGB_ordinal</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row16_col0\" class=\"data row16 col0\" >0.048900</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row16_col1\" class=\"data row16 col1\" >0.002400</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row16_col2\" class=\"data row16 col2\" >0.999800</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row16_col3\" class=\"data row16 col3\" >1.570400</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row16_col4\" class=\"data row16 col4\" >2.466100</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row16_col5\" class=\"data row16 col5\" >0.847300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row17\" class=\"row_heading level0 row17\" >XGB_catboost_tuned</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row17_col0\" class=\"data row17 col0\" >0.879100</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row17_col1\" class=\"data row17 col1\" >0.772800</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row17_col2\" class=\"data row17 col2\" >0.947100</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row17_col3\" class=\"data row17 col3\" >1.559600</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row17_col4\" class=\"data row17 col4\" >2.432200</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row17_col5\" class=\"data row17 col5\" >0.849400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row18\" class=\"row_heading level0 row18\" >XGB_ordinal_tuned</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row18_col0\" class=\"data row18 col0\" >1.144500</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row18_col1\" class=\"data row18 col1\" >1.310000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row18_col2\" class=\"data row18 col2\" >0.910300</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row18_col3\" class=\"data row18 col3\" >1.543300</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row18_col4\" class=\"data row18 col4\" >2.381600</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row18_col5\" class=\"data row18 col5\" >0.852500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row19\" class=\"row_heading level0 row19\" >XGB_ohe</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row19_col0\" class=\"data row19 col0\" >0.048800</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row19_col1\" class=\"data row19 col1\" >0.002400</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row19_col2\" class=\"data row19 col2\" >0.999800</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row19_col3\" class=\"data row19 col3\" >1.541600</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row19_col4\" class=\"data row19 col4\" >2.376700</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row19_col5\" class=\"data row19 col5\" >0.852800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row20\" class=\"row_heading level0 row20\" >XGB_ohe_tuned</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row20_col0\" class=\"data row20 col0\" >1.100600</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row20_col1\" class=\"data row20 col1\" >1.211300</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row20_col2\" class=\"data row20 col2\" >0.917100</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row20_col3\" class=\"data row20 col3\" >1.523100</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row20_col4\" class=\"data row20 col4\" >2.319800</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row20_col5\" class=\"data row20 col5\" >0.856400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row21\" class=\"row_heading level0 row21\" >XGB_ignore_tuned</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row21_col0\" class=\"data row21 col0\" >0.696400</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row21_col1\" class=\"data row21 col1\" >0.485000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row21_col2\" class=\"data row21 col2\" >0.966800</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row21_col3\" class=\"data row21 col3\" >1.517000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row21_col4\" class=\"data row21 col4\" >2.301300</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row21_col5\" class=\"data row21 col5\" >0.857500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row22\" class=\"row_heading level0 row22\" >XGB_target_tuned</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row22_col0\" class=\"data row22 col0\" >0.959300</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row22_col1\" class=\"data row22 col1\" >0.920200</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row22_col2\" class=\"data row22 col2\" >0.937000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row22_col3\" class=\"data row22 col3\" >1.509900</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row22_col4\" class=\"data row22 col4\" >2.279700</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row22_col5\" class=\"data row22 col5\" >0.858800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row23\" class=\"row_heading level0 row23\" >XGB_glmm_tuned</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row23_col0\" class=\"data row23 col0\" >1.146400</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row23_col1\" class=\"data row23 col1\" >1.314300</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row23_col2\" class=\"data row23 col2\" >0.910000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row23_col3\" class=\"data row23 col3\" >1.480600</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row23_col4\" class=\"data row23 col4\" >2.192200</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row23_col5\" class=\"data row23 col5\" >0.864300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7level0_row24\" class=\"row_heading level0 row24\" >XGB_ignore</th>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row24_col0\" class=\"data row24 col0\" >0.063100</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row24_col1\" class=\"data row24 col1\" >0.004000</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row24_col2\" class=\"data row24 col2\" >0.999700</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row24_col3\" class=\"data row24 col3\" >1.474200</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row24_col4\" class=\"data row24 col4\" >2.173200</td>\n",
       "                        <td id=\"T_216a91a4_9825_11ed_9eb1_59b4c8c782b7row24_col5\" class=\"data row24 col5\" >0.865400</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa712e09730>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_encodings_df = pd.DataFrame(results_encodings[1]).transpose().sort_values(\"MSE Test\",ascending=False).round(4)\n",
    "results_encodings_df[[\"RMSE Train\", \"MSE Train\", \"R2 Train\", \"RMSE Test\", \"MSE Test\", \"R2 Test\"]].style.highlight_min(subset=[\"MSE Train\", \"MSE Test\"], color = 'lightgreen', axis = 0).highlight_max(subset=[\"R2 Train\", \"R2 Test\"], color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_217567e6_9825_11ed_9eb1_59b4c8c782b7row0_col1 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_217567e6_9825_11ed_9eb1_59b4c8c782b7row0_col2 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_217567e6_9825_11ed_9eb1_59b4c8c782b7row0_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_217567e6_9825_11ed_9eb1_59b4c8c782b7row0_col4 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_217567e6_9825_11ed_9eb1_59b4c8c782b7row0_col5 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_217567e6_9825_11ed_9eb1_59b4c8c782b7row0_col6 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_217567e6_9825_11ed_9eb1_59b4c8c782b7\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Baseline</th>        <th class=\"col_heading level0 col1\" >LR_ignore_tuned</th>        <th class=\"col_heading level0 col2\" >LR_ohe_tuned</th>        <th class=\"col_heading level0 col3\" >LR_target_tuned</th>        <th class=\"col_heading level0 col4\" >LR_ordinal_tuned</th>        <th class=\"col_heading level0 col5\" >LR_catboost_tuned</th>        <th class=\"col_heading level0 col6\" >LR_glmm_tuned</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_217567e6_9825_11ed_9eb1_59b4c8c782b7level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_217567e6_9825_11ed_9eb1_59b4c8c782b7row0_col0\" class=\"data row0 col0\" >3.862 (0.166)</td>\n",
       "                        <td id=\"T_217567e6_9825_11ed_9eb1_59b4c8c782b7row0_col1\" class=\"data row0 col1\" >1.553 (0.103)</td>\n",
       "                        <td id=\"T_217567e6_9825_11ed_9eb1_59b4c8c782b7row0_col2\" class=\"data row0 col2\" >1.552 (0.102)</td>\n",
       "                        <td id=\"T_217567e6_9825_11ed_9eb1_59b4c8c782b7row0_col3\" class=\"data row0 col3\" >1.55 (0.101)</td>\n",
       "                        <td id=\"T_217567e6_9825_11ed_9eb1_59b4c8c782b7row0_col4\" class=\"data row0 col4\" >1.553 (0.103)</td>\n",
       "                        <td id=\"T_217567e6_9825_11ed_9eb1_59b4c8c782b7row0_col5\" class=\"data row0 col5\" >1.552 (0.102)</td>\n",
       "                        <td id=\"T_217567e6_9825_11ed_9eb1_59b4c8c782b7row0_col6\" class=\"data row0 col6\" >1.551 (0.103)</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa7124a2ee0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For LR\n",
    "models = [\"Baseline\"]+[i for i in results_encodings[0].keys() if (\"tuned\" in i and \"LR\" in i)]\n",
    "metric = \"RMSE Test\"\n",
    "\n",
    "#####\n",
    "dataset_res_dict = {}\n",
    "best_models = {}\n",
    "t_test_results = {}\n",
    "\n",
    "use_df = pd.DataFrame([pd.DataFrame(results_encodings[fold_num]).loc[metric,models] for fold_num in results_encodings.keys()],index=results_encodings.keys())*-1\n",
    "\n",
    "df_mean = pd.DataFrame((-1*use_df).mean(axis=0).round(3).astype(str) + \" (\" + use_df.std(axis=0).round(3).astype(str) + \")\").transpose()\n",
    "model_dict = {i: df_mean[i].values[0] for i in df_mean.columns}\n",
    "\n",
    "best_model = use_df.columns[use_df.mean(axis=0).argmax()]\n",
    "\n",
    "t_test_res = np.array([stats.ttest_rel(use_df[best_model].values, use_df[model].values)[1] for model in models]).round(3)\n",
    "t_test_res[np.isnan(t_test_res)] = 1.\n",
    "    \n",
    "res_df_lr = pd.DataFrame([model_dict])\n",
    "\n",
    "def negative_bold(val):\n",
    "    i = np.where(val.name==np.array(models))[0][0]\n",
    "    return [\"font-weight: bold\"  if t_test_res[i]>=0.05 else \"\" for dataset_name in val.keys()]\n",
    "    # Case without transpose:\n",
    "#     return [\"font-weight: bold\"  if t_test_results[val.name][i]>=0.05 else \"\" for i in range(len(val))]\n",
    "\n",
    "res_df_lr.style.apply(negative_bold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_217ab73c_9825_11ed_9eb1_59b4c8c782b7row0_col1 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_217ab73c_9825_11ed_9eb1_59b4c8c782b7row0_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_217ab73c_9825_11ed_9eb1_59b4c8c782b7row0_col4 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_217ab73c_9825_11ed_9eb1_59b4c8c782b7row0_col5 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_217ab73c_9825_11ed_9eb1_59b4c8c782b7row0_col6 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_217ab73c_9825_11ed_9eb1_59b4c8c782b7\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Baseline</th>        <th class=\"col_heading level0 col1\" >XGB_ignore_tuned</th>        <th class=\"col_heading level0 col2\" >XGB_ohe_tuned</th>        <th class=\"col_heading level0 col3\" >XGB_target_tuned</th>        <th class=\"col_heading level0 col4\" >XGB_ordinal_tuned</th>        <th class=\"col_heading level0 col5\" >XGB_catboost_tuned</th>        <th class=\"col_heading level0 col6\" >XGB_glmm_tuned</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_217ab73c_9825_11ed_9eb1_59b4c8c782b7level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_217ab73c_9825_11ed_9eb1_59b4c8c782b7row0_col0\" class=\"data row0 col0\" >3.862 (0.166)</td>\n",
       "                        <td id=\"T_217ab73c_9825_11ed_9eb1_59b4c8c782b7row0_col1\" class=\"data row0 col1\" >1.513 (0.116)</td>\n",
       "                        <td id=\"T_217ab73c_9825_11ed_9eb1_59b4c8c782b7row0_col2\" class=\"data row0 col2\" >1.513 (0.075)</td>\n",
       "                        <td id=\"T_217ab73c_9825_11ed_9eb1_59b4c8c782b7row0_col3\" class=\"data row0 col3\" >1.464 (0.064)</td>\n",
       "                        <td id=\"T_217ab73c_9825_11ed_9eb1_59b4c8c782b7row0_col4\" class=\"data row0 col4\" >1.518 (0.064)</td>\n",
       "                        <td id=\"T_217ab73c_9825_11ed_9eb1_59b4c8c782b7row0_col5\" class=\"data row0 col5\" >1.573 (0.078)</td>\n",
       "                        <td id=\"T_217ab73c_9825_11ed_9eb1_59b4c8c782b7row0_col6\" class=\"data row0 col6\" >1.498 (0.056)</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa712dac310>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For LR\n",
    "models = [\"Baseline\"]+[i for i in results_encodings[0].keys() if (\"tuned\" in i and \"XGB\" in i)]\n",
    "metric = \"RMSE Test\"\n",
    "\n",
    "#####\n",
    "dataset_res_dict = {}\n",
    "best_models = {}\n",
    "t_test_results = {}\n",
    "\n",
    "use_df = pd.DataFrame([pd.DataFrame(results_encodings[fold_num]).loc[metric,models] for fold_num in results_encodings.keys()],index=results_encodings.keys())*-1\n",
    "\n",
    "df_mean = pd.DataFrame((-1*use_df).mean(axis=0).round(3).astype(str) + \" (\" + use_df.std(axis=0).round(3).astype(str) + \")\").transpose()\n",
    "model_dict = {i: df_mean[i].values[0] for i in df_mean.columns}\n",
    "\n",
    "best_model = use_df.columns[use_df.mean(axis=0).argmax()]\n",
    "\n",
    "t_test_res = np.array([stats.ttest_rel(use_df[best_model].values, use_df[model].values)[1] for model in models]).round(3)\n",
    "t_test_res[np.isnan(t_test_res)] = 1.\n",
    "    \n",
    "res_df_xgb = pd.DataFrame([model_dict])\n",
    "    \n",
    "def negative_bold(val):\n",
    "    i = np.where(val.name==np.array(models))[0][0]\n",
    "    return [\"font-weight: bold\"  if t_test_res[i]>=0.05 else \"\" for dataset_name in val.keys()]\n",
    "    # Case without transpose:\n",
    "#     return [\"font-weight: bold\"  if t_test_results[val.name][i]>=0.05 else \"\" for i in range(len(val))]\n",
    "\n",
    "res_df_xgb.style.apply(negative_bold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>ignore</th>\n",
       "      <th>ohe</th>\n",
       "      <th>target</th>\n",
       "      <th>ordinal</th>\n",
       "      <th>catboost</th>\n",
       "      <th>glmm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>3.862 (0.166)</td>\n",
       "      <td>1.553 (0.103)</td>\n",
       "      <td>1.552 (0.102)</td>\n",
       "      <td>1.55 (0.101)</td>\n",
       "      <td>1.553 (0.103)</td>\n",
       "      <td>1.552 (0.102)</td>\n",
       "      <td>1.551 (0.103)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>3.862 (0.166)</td>\n",
       "      <td>1.513 (0.116)</td>\n",
       "      <td>1.513 (0.075)</td>\n",
       "      <td>1.464 (0.064)</td>\n",
       "      <td>1.518 (0.064)</td>\n",
       "      <td>1.573 (0.078)</td>\n",
       "      <td>1.498 (0.056)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline         ignore            ohe         target  \\\n",
       "LR   3.862 (0.166)  1.553 (0.103)  1.552 (0.102)   1.55 (0.101)   \n",
       "XGB  3.862 (0.166)  1.513 (0.116)  1.513 (0.075)  1.464 (0.064)   \n",
       "\n",
       "           ordinal       catboost           glmm  \n",
       "LR   1.553 (0.103)  1.552 (0.102)  1.551 (0.103)  \n",
       "XGB  1.518 (0.064)  1.573 (0.078)  1.498 (0.056)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_lr.columns = [i.split(\"_\")[1] if i != \"Baseline\" else \"Baseline\" for i in res_df_lr.columns]    \n",
    "res_df_xgb.columns = [i.split(\"_\")[1] if i != \"Baseline\" else \"Baseline\" for i in res_df_xgb.columns]    \n",
    "\n",
    "latex_df_encodings = pd.concat([res_df_lr,res_df_xgb],axis=0)\n",
    "latex_df_encodings.index = [\"LR\", \"XGB\"]\n",
    "latex_df_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "{} &       Baseline &         ignore &            ohe &         target &        ordinal &       catboost &           glmm \\\\\n",
      "\\midrule\n",
      "LR  &  3.862 (0.166) &  1.553 (0.103) &  1.552 (0.102) &   1.55 (0.101) &  1.553 (0.103) &  1.552 (0.102) &  1.551 (0.103) \\\\\n",
      "XGB &  3.862 (0.166) &  1.513 (0.116) &  1.513 (0.075) &  1.464 (0.064) &  1.518 (0.064) &  1.573 (0.078) &  1.498 (0.056) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex_df_encodings.round(2).to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data subset comparisons\n",
    "\n",
    "As it does not matter which encoding method is used we use 5CV-GLMM encoding for LR and Ordinal encoding for XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = {\"demo_only\": demographic_cols,\n",
    "           \"perfact_only\": perf_cols+activity_cols,\n",
    "           \"perfact_and_demo\": perf_cols+activity_cols+demographic_cols,\n",
    "           \"all\": list(df.columns)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row6_col1 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row6_col2 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row16_col4 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row16_col5 {\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >RMSE Train</th>        <th class=\"col_heading level0 col1\" >MSE Train</th>        <th class=\"col_heading level0 col2\" >R2 Train</th>        <th class=\"col_heading level0 col3\" >RMSE Test</th>        <th class=\"col_heading level0 col4\" >MSE Test</th>        <th class=\"col_heading level0 col5\" >R2 Test</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row0\" class=\"row_heading level0 row0\" >XGB_demo_only</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row0_col0\" class=\"data row0 col0\" >1.367600</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row0_col1\" class=\"data row0 col1\" >1.870400</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row0_col2\" class=\"data row0 col2\" >0.873800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row0_col3\" class=\"data row0 col3\" >4.448700</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row0_col4\" class=\"data row0 col4\" >19.790900</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row0_col5\" class=\"data row0 col5\" >-0.306300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row1\" class=\"row_heading level0 row1\" >Baseline</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row1_col0\" class=\"data row1 col0\" >3.850500</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row1_col1\" class=\"data row1 col1\" >14.826700</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row1_col2\" class=\"data row1 col2\" >-0.000000</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row1_col3\" class=\"data row1 col3\" >3.918300</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row1_col4\" class=\"data row1 col4\" >15.352800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row1_col5\" class=\"data row1 col5\" >-0.013400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row2\" class=\"row_heading level0 row2\" >LR_demo_only</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row2_col0\" class=\"data row2 col0\" >3.672200</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row2_col1\" class=\"data row2 col1\" >13.485000</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row2_col2\" class=\"data row2 col2\" >0.090500</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row2_col3\" class=\"data row2 col3\" >3.812200</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row2_col4\" class=\"data row2 col4\" >14.533000</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row2_col5\" class=\"data row2 col5\" >0.040700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row3\" class=\"row_heading level0 row3\" >XGB_demo_only_tuned</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row3_col0\" class=\"data row3 col0\" >2.167900</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row3_col1\" class=\"data row3 col1\" >4.699800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row3_col2\" class=\"data row3 col2\" >0.683000</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row3_col3\" class=\"data row3 col3\" >3.799400</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row3_col4\" class=\"data row3 col4\" >14.435600</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row3_col5\" class=\"data row3 col5\" >0.047200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row4\" class=\"row_heading level0 row4\" >LR_demo_only_tuned</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row4_col0\" class=\"data row4 col0\" >3.677700</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row4_col1\" class=\"data row4 col1\" >13.525400</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row4_col2\" class=\"data row4 col2\" >0.087800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row4_col3\" class=\"data row4 col3\" >3.795500</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row4_col4\" class=\"data row4 col4\" >14.405800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row4_col5\" class=\"data row4 col5\" >0.049100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row5\" class=\"row_heading level0 row5\" >XGB_perfact_and_demo</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row5_col0\" class=\"data row5 col0\" >0.082500</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row5_col1\" class=\"data row5 col1\" >0.006800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row5_col2\" class=\"data row5 col2\" >0.999500</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row5_col3\" class=\"data row5 col3\" >1.900100</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row5_col4\" class=\"data row5 col4\" >3.610600</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row5_col5\" class=\"data row5 col5\" >0.761700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row6\" class=\"row_heading level0 row6\" >XGB_all</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row6_col0\" class=\"data row6 col0\" >0.045800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row6_col1\" class=\"data row6 col1\" >0.002100</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row6_col2\" class=\"data row6 col2\" >0.999900</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row6_col3\" class=\"data row6 col3\" >1.673300</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row6_col4\" class=\"data row6 col4\" >2.799800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row6_col5\" class=\"data row6 col5\" >0.815200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row7\" class=\"row_heading level0 row7\" >XGB_perfact_only</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row7_col0\" class=\"data row7 col0\" >0.533900</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row7_col1\" class=\"data row7 col1\" >0.285000</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row7_col2\" class=\"data row7 col2\" >0.980800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row7_col3\" class=\"data row7 col3\" >1.669200</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row7_col4\" class=\"data row7 col4\" >2.786200</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row7_col5\" class=\"data row7 col5\" >0.816100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row8\" class=\"row_heading level0 row8\" >LR_perfact_and_demo_tuned</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row8_col0\" class=\"data row8 col0\" >1.557800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row8_col1\" class=\"data row8 col1\" >2.426800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row8_col2\" class=\"data row8 col2\" >0.836300</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row8_col3\" class=\"data row8 col3\" >1.640700</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row8_col4\" class=\"data row8 col4\" >2.691800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row8_col5\" class=\"data row8 col5\" >0.822300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row9\" class=\"row_heading level0 row9\" >LR_perfact_only_tuned</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row9_col0\" class=\"data row9 col0\" >1.554800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row9_col1\" class=\"data row9 col1\" >2.417400</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row9_col2\" class=\"data row9 col2\" >0.837000</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row9_col3\" class=\"data row9 col3\" >1.632400</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row9_col4\" class=\"data row9 col4\" >2.664800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row9_col5\" class=\"data row9 col5\" >0.824100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row10\" class=\"row_heading level0 row10\" >LR_perfact_only</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row10_col0\" class=\"data row10 col0\" >1.549800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row10_col1\" class=\"data row10 col1\" >2.401900</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row10_col2\" class=\"data row10 col2\" >0.838000</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row10_col3\" class=\"data row10 col3\" >1.631900</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row10_col4\" class=\"data row10 col4\" >2.663100</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row10_col5\" class=\"data row10 col5\" >0.824200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row11\" class=\"row_heading level0 row11\" >LR_perfact_and_demo</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row11_col0\" class=\"data row11 col0\" >1.532100</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row11_col1\" class=\"data row11 col1\" >2.347400</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row11_col2\" class=\"data row11 col2\" >0.841700</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row11_col3\" class=\"data row11 col3\" >1.609400</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row11_col4\" class=\"data row11 col4\" >2.590000</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row11_col5\" class=\"data row11 col5\" >0.829000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row12\" class=\"row_heading level0 row12\" >LR_all_tuned</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row12_col0\" class=\"data row12 col0\" >1.529200</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row12_col1\" class=\"data row12 col1\" >2.338400</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row12_col2\" class=\"data row12 col2\" >0.842300</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row12_col3\" class=\"data row12 col3\" >1.607200</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row12_col4\" class=\"data row12 col4\" >2.583100</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row12_col5\" class=\"data row12 col5\" >0.829500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row13\" class=\"row_heading level0 row13\" >LR_all</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row13_col0\" class=\"data row13 col0\" >1.504000</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row13_col1\" class=\"data row13 col1\" >2.262000</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row13_col2\" class=\"data row13 col2\" >0.847400</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row13_col3\" class=\"data row13 col3\" >1.594900</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row13_col4\" class=\"data row13 col4\" >2.543600</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row13_col5\" class=\"data row13 col5\" >0.832100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row14\" class=\"row_heading level0 row14\" >XGB_perfact_and_demo_tuned</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row14_col0\" class=\"data row14 col0\" >1.208800</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row14_col1\" class=\"data row14 col1\" >1.461300</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row14_col2\" class=\"data row14 col2\" >0.901400</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row14_col3\" class=\"data row14 col3\" >1.521500</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row14_col4\" class=\"data row14 col4\" >2.314900</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row14_col5\" class=\"data row14 col5\" >0.847200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row15\" class=\"row_heading level0 row15\" >XGB_all_tuned</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row15_col0\" class=\"data row15 col0\" >1.062100</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row15_col1\" class=\"data row15 col1\" >1.128000</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row15_col2\" class=\"data row15 col2\" >0.923900</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row15_col3\" class=\"data row15 col3\" >1.486300</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row15_col4\" class=\"data row15 col4\" >2.209000</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row15_col5\" class=\"data row15 col5\" >0.854200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7level0_row16\" class=\"row_heading level0 row16\" >XGB_perfact_only_tuned</th>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row16_col0\" class=\"data row16 col0\" >1.161300</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row16_col1\" class=\"data row16 col1\" >1.348500</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row16_col2\" class=\"data row16 col2\" >0.909000</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row16_col3\" class=\"data row16 col3\" >1.470300</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row16_col4\" class=\"data row16 col4\" >2.161900</td>\n",
       "                        <td id=\"T_21a6ee74_9825_11ed_9eb1_59b4c8c782b7row16_col5\" class=\"data row16 col5\" >0.857300</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa712dac910>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(f\"../results/{dataset_name}/{experiment_name}/results_subsets.pickle\"):\n",
    "\n",
    "    results_subsets = {}\n",
    "    results_subsets_feature_importances = {}\n",
    "\n",
    "    for fold in range(folds):\n",
    "        target_scaler = data_dict[f\"target_scaler_{fold}\"]\n",
    "        results_subsets[fold] = {}\n",
    "        results_subsets_feature_importances[fold] = {}\n",
    "        # Create baseline\n",
    "        y_train = data_dict[f\"y_train_{fold}\"]\n",
    "        y_val = data_dict[f\"y_val_{fold}\"]\n",
    "        y_test = target_scaler.inverse_transform(data_dict[f\"y_test_{fold}\"].reshape(-1,1)).ravel()\n",
    "        y_train_val = target_scaler.inverse_transform(np.concatenate([y_train,y_val]).reshape(-1,1)).ravel()\n",
    "\n",
    "        y_train_val_pred_base = np.ones(y_train_val.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "        y_test_pred_base = np.ones(y_test.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "\n",
    "        results_subsets[fold][\"Baseline\"] = {}\n",
    "        eval_res_train = get_metrics(y_train_val, y_train_val_pred_base, target=target)\n",
    "        for metric in eval_res_train.keys():\n",
    "            results_subsets[fold][\"Baseline\"][metric + \" Train\"] = eval_res_train[metric]\n",
    "        eval_res_test = get_metrics(y_test, y_test_pred_base, target=target)\n",
    "        for metric in eval_res_test.keys():\n",
    "            results_subsets[fold][\"Baseline\"][metric + \" Test\"] = eval_res_test[metric]\n",
    "        results_subsets[fold][\"Baseline\"][\"RMSE Test\"] = np.sqrt(results_subsets[fold][\"Baseline\"][\"MSE Test\"])\n",
    "        results_subsets[fold][\"Baseline\"][\"RMSE Train\"] = np.sqrt(results_subsets[fold][\"Baseline\"][\"MSE Train\"])\n",
    "\n",
    "\n",
    "        for subset_key in subsets:\n",
    "            print(f\"Preparing results for fold {fold}, subset={subset_key}\")\n",
    "            # Retrieve data\n",
    "            z_cols = data_dict[\"z_cols\"]\n",
    "\n",
    "            X_train = data_dict[f\"X_train_{fold}\"]\n",
    "            y_train = data_dict[f\"y_train_{fold}\"]\n",
    "\n",
    "            X_val = data_dict[f\"X_val_{fold}\"]\n",
    "            y_val = data_dict[f\"y_val_{fold}\"]\n",
    "\n",
    "            X_test = data_dict[f\"X_test_{fold}\"]\n",
    "            y_test = data_dict[f\"y_test_{fold}\"]\n",
    "        \n",
    "            y_train_val = np.concatenate([y_train,y_val])\n",
    "\n",
    "            # Define data subset for LR\n",
    "            z_glmm_encoded_train = data_dict[f\"z_glmm_encoded_train_{fold}\"] \n",
    "            z_glmm_encoded_val = data_dict[f\"z_glmm_encoded_val_{fold}\"] \n",
    "            z_glmm_encoded_test = data_dict[f\"z_glmm_encoded_test_{fold}\"] \n",
    "            \n",
    "            X_train_lr = pd.concat([X_train,z_glmm_encoded_train],axis=1)\n",
    "            X_val_lr = pd.concat([X_val,z_glmm_encoded_val],axis=1)\n",
    "            X_test_lr = pd.concat([X_test,z_glmm_encoded_test],axis=1)      \n",
    "            X_train_val_lr = pd.concat([X_train_lr,X_val_lr])\n",
    "\n",
    "            # Rescale GLMM\n",
    "            for col in z_glmm_encoded_train.columns:\n",
    "                z_mean = X_train_val_lr[col].mean()\n",
    "                z_std = X_train_val_lr[col].std()\n",
    "            \n",
    "                X_train_val_lr[col] = (X_train_val_lr[col]-z_mean)/z_std\n",
    "                X_test_lr[col] = (X_test_lr[col]-z_mean)/z_std\n",
    "            \n",
    "            \n",
    "            # Define data subset for XGB\n",
    "            z_ordinal_encoded_train = data_dict[f\"z_ordinal_encoded_train_{fold}\"] \n",
    "            z_ordinal_encoded_val = data_dict[f\"z_ordinal_encoded_val_{fold}\"] \n",
    "            z_ordinal_encoded_test = data_dict[f\"z_ordinal_encoded_test_{fold}\"] \n",
    "            X_train_xgb = pd.concat([X_train,z_ordinal_encoded_train],axis=1)\n",
    "            X_val_xgb = pd.concat([X_val,z_ordinal_encoded_val],axis=1)\n",
    "            X_test_xgb = pd.concat([X_test,z_ordinal_encoded_test],axis=1)\n",
    "            X_train_val_xgb = pd.concat([X_train_xgb,X_val_xgb])\n",
    "\n",
    "\n",
    "            # Define data subset for evaluation\n",
    "            X_train_val_lr = X_train_val_lr[[i for i in X_train_val_lr.columns if i in subsets[subset_key]]]\n",
    "            X_test_lr = X_test_lr[[i for i in X_test_lr.columns if i in subsets[subset_key]]]\n",
    "            X_train_val_xgb = X_train_val_xgb[[i for i in X_train_val_xgb.columns if i in subsets[subset_key]]]\n",
    "            X_test_xgb = X_test_xgb[[i for i in X_test_xgb.columns if i in subsets[subset_key]]]\n",
    "\n",
    "\n",
    "            # Train base models\n",
    "            res, feats = evaluate_lr(X_train_val_lr, y_train_val, X_test_lr, y_test, target=target,tune=False, seed=RS, target_scaler=target_scaler)\n",
    "            results_subsets[fold][\"LR_\"+subset_key] = res\n",
    "            results_subsets_feature_importances[fold][\"LR_\"+subset_key] = feats\n",
    "            results_subsets[fold][\"LR_\"+subset_key][\"RMSE Test\"] = np.sqrt(results_subsets[fold][\"LR_\"+subset_key][\"MSE Test\"])\n",
    "            results_subsets[fold][\"LR_\"+subset_key][\"RMSE Train\"] = np.sqrt(results_subsets[fold][\"LR_\"+subset_key][\"MSE Train\"])\n",
    "\n",
    "            res, feats = evaluate_xgb(X_train_val_xgb, y_train_val, X_test_xgb, y_test, target, tune=False, max_evals=max_evals, early_stopping_rounds=early_stopping_rounds, seed=RS, target_scaler=target_scaler)\n",
    "            results_subsets[fold][\"XGB_\"+subset_key] = res\n",
    "            results_subsets_feature_importances[fold][\"XGB_\"+subset_key] = feats\n",
    "            results_subsets[fold][\"XGB_\"+subset_key][\"RMSE Test\"] = np.sqrt(results_subsets[fold][\"XGB_\"+subset_key][\"MSE Test\"])\n",
    "            results_subsets[fold][\"XGB_\"+subset_key][\"RMSE Train\"] = np.sqrt(results_subsets[fold][\"XGB_\"+subset_key][\"MSE Train\"])\n",
    "\n",
    "            # Train tuned models\n",
    "            res, feats = evaluate_lr(X_train_val_lr, y_train_val, X_test_lr, y_test, target=target, max_evals=max_evals, tune=True, seed=RS, target_scaler=target_scaler)\n",
    "            results_subsets[fold][\"LR_\"+subset_key+\"_tuned\"] = res\n",
    "            results_subsets_feature_importances[fold][\"LR_\"+subset_key+\"_tuned\"] = feats\n",
    "            results_subsets[fold][\"LR_\"+subset_key+\"_tuned\"][\"RMSE Test\"] = np.sqrt(results_subsets[fold][\"LR_\"+subset_key+\"_tuned\"][\"MSE Test\"])\n",
    "            results_subsets[fold][\"LR_\"+subset_key+\"_tuned\"][\"RMSE Train\"] = np.sqrt(results_subsets[fold][\"LR_\"+subset_key+\"_tuned\"][\"MSE Train\"])\n",
    "\n",
    "            res, feats = evaluate_xgb(X_train_val_xgb, y_train_val, X_test_xgb, y_test, target, tune=True, max_evals=max_evals, early_stopping_rounds=early_stopping_rounds, seed=RS, target_scaler=target_scaler)\n",
    "            results_subsets[fold][\"XGB_\"+subset_key+\"_tuned\"] = res\n",
    "            results_subsets_feature_importances[fold][\"XGB_\"+subset_key+\"_tuned\"] = feats\n",
    "            results_subsets[fold][\"XGB_\"+subset_key+\"_tuned\"][\"RMSE Test\"] = np.sqrt(results_subsets[fold][\"XGB_\"+subset_key+\"_tuned\"][\"MSE Test\"])\n",
    "            results_subsets[fold][\"XGB_\"+subset_key+\"_tuned\"][\"RMSE Train\"] = np.sqrt(results_subsets[fold][\"XGB_\"+subset_key+\"_tuned\"][\"MSE Train\"])\n",
    "    \n",
    "    if not os.path.exists(f\"../results/{dataset_name}/{experiment_name}\"):\n",
    "        os.makedirs(f\"../results/{dataset_name}/{experiment_name}\")\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_subsets.pickle\", 'wb') as handle:\n",
    "        pickle.dump(results_subsets, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_subsets_feature_importances.pickle\", 'wb') as handle:\n",
    "        pickle.dump(results_subsets_feature_importances, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_subsets.pickle\", 'rb') as handle:\n",
    "        results_subsets = pickle.load(handle)\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_subsets_feature_importances.pickle\", 'rb') as handle:\n",
    "        results_subsets_feature_importances = pickle.load(handle)\n",
    "    for fold in range(folds):\n",
    "        target_scaler = data_dict[f\"target_scaler_{fold}\"]\n",
    "        # Create baseline\n",
    "        y_train = data_dict[f\"y_train_{fold}\"]\n",
    "        y_val = data_dict[f\"y_val_{fold}\"]\n",
    "        y_test = target_scaler.inverse_transform(data_dict[f\"y_test_{fold}\"].reshape(-1,1)).ravel()\n",
    "        y_train_val = target_scaler.inverse_transform(np.concatenate([y_train,y_val]).reshape(-1,1)).ravel()\n",
    "\n",
    "        y_train_val_pred_base = np.ones(y_train_val.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "        y_test_pred_base = np.ones(y_test.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "\n",
    "        results_subsets[fold][\"Baseline\"] = {}\n",
    "        eval_res_train = get_metrics(y_train_val, y_train_val_pred_base, target=target)\n",
    "        for metric in eval_res_train.keys():\n",
    "            results_subsets[fold][\"Baseline\"][metric + \" Train\"] = eval_res_train[metric]\n",
    "        eval_res_test = get_metrics(y_test, y_test_pred_base, target=target)\n",
    "        for metric in eval_res_test.keys():\n",
    "            results_subsets[fold][\"Baseline\"][metric + \" Test\"] = eval_res_test[metric]\n",
    "        results_subsets[fold][\"Baseline\"][\"RMSE Test\"] = np.sqrt(results_subsets[fold][\"Baseline\"][\"MSE Test\"])\n",
    "        results_subsets[fold][\"Baseline\"][\"RMSE Train\"] = np.sqrt(results_subsets[fold][\"Baseline\"][\"MSE Train\"])\n",
    "        \n",
    "        \n",
    "results_subsets_df = pd.DataFrame(results_subsets[0]).transpose().sort_values(\"RMSE Test\",ascending=False).round(4)\n",
    "results_subsets_df[[\"RMSE Train\", \"MSE Train\", \"R2 Train\", \"RMSE Test\", \"MSE Test\", \"R2 Test\"]].style.highlight_min(subset=[\"MSE Train\", \"MSE Test\"], color = 'lightgreen', axis = 0).highlight_max(subset=[\"R2 Train\", \"R2 Test\"], color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row15_col1 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row15_col2 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row16_col4 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row16_col5 {\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >RMSE Train</th>        <th class=\"col_heading level0 col1\" >MSE Train</th>        <th class=\"col_heading level0 col2\" >R2 Train</th>        <th class=\"col_heading level0 col3\" >RMSE Test</th>        <th class=\"col_heading level0 col4\" >MSE Test</th>        <th class=\"col_heading level0 col5\" >R2 Test</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row0\" class=\"row_heading level0 row0\" >XGB_demo_only</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row0_col0\" class=\"data row0 col0\" >1.282100</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row0_col1\" class=\"data row0 col1\" >1.643800</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row0_col2\" class=\"data row0 col2\" >0.887500</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row0_col3\" class=\"data row0 col3\" >4.437700</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row0_col4\" class=\"data row0 col4\" >19.693100</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row0_col5\" class=\"data row0 col5\" >-0.219400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row1\" class=\"row_heading level0 row1\" >Baseline</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row1_col0\" class=\"data row1 col0\" >3.822300</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row1_col1\" class=\"data row1 col1\" >14.610200</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row1_col2\" class=\"data row1 col2\" >-0.000000</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row1_col3\" class=\"data row1 col3\" >4.022300</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row1_col4\" class=\"data row1 col4\" >16.178500</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row1_col5\" class=\"data row1 col5\" >-0.001800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row2\" class=\"row_heading level0 row2\" >XGB_demo_only_tuned</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row2_col0\" class=\"data row2 col0\" >2.479800</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row2_col1\" class=\"data row2 col1\" >6.149600</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row2_col2\" class=\"data row2 col2\" >0.579100</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row2_col3\" class=\"data row2 col3\" >4.000500</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row2_col4\" class=\"data row2 col4\" >16.004000</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row2_col5\" class=\"data row2 col5\" >0.009000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row3\" class=\"row_heading level0 row3\" >LR_demo_only</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row3_col0\" class=\"data row3 col0\" >3.635800</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row3_col1\" class=\"data row3 col1\" >13.218800</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row3_col2\" class=\"data row3 col2\" >0.095200</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row3_col3\" class=\"data row3 col3\" >3.932500</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row3_col4\" class=\"data row3 col4\" >15.464800</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row3_col5\" class=\"data row3 col5\" >0.042400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row4\" class=\"row_heading level0 row4\" >LR_demo_only_tuned</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row4_col0\" class=\"data row4 col0\" >3.647000</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row4_col1\" class=\"data row4 col1\" >13.300500</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row4_col2\" class=\"data row4 col2\" >0.089600</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row4_col3\" class=\"data row4 col3\" >3.907700</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row4_col4\" class=\"data row4 col4\" >15.270200</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row4_col5\" class=\"data row4 col5\" >0.054500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row5\" class=\"row_heading level0 row5\" >XGB_perfact_only</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row5_col0\" class=\"data row5 col0\" >0.528000</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row5_col1\" class=\"data row5 col1\" >0.278800</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row5_col2\" class=\"data row5 col2\" >0.980900</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row5_col3\" class=\"data row5 col3\" >1.789300</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row5_col4\" class=\"data row5 col4\" >3.201600</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row5_col5\" class=\"data row5 col5\" >0.801800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row6\" class=\"row_heading level0 row6\" >XGB_perfact_and_demo_tuned</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row6_col0\" class=\"data row6 col0\" >0.447800</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row6_col1\" class=\"data row6 col1\" >0.200500</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row6_col2\" class=\"data row6 col2\" >0.986300</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row6_col3\" class=\"data row6 col3\" >1.785900</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row6_col4\" class=\"data row6 col4\" >3.189400</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row6_col5\" class=\"data row6 col5\" >0.802500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row7\" class=\"row_heading level0 row7\" >XGB_perfact_and_demo</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row7_col0\" class=\"data row7 col0\" >0.078700</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row7_col1\" class=\"data row7 col1\" >0.006200</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row7_col2\" class=\"data row7 col2\" >0.999600</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row7_col3\" class=\"data row7 col3\" >1.761600</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row7_col4\" class=\"data row7 col4\" >3.103300</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row7_col5\" class=\"data row7 col5\" >0.807800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row8\" class=\"row_heading level0 row8\" >LR_all</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row8_col0\" class=\"data row8 col0\" >1.482700</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row8_col1\" class=\"data row8 col1\" >2.198300</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row8_col2\" class=\"data row8 col2\" >0.849500</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row8_col3\" class=\"data row8 col3\" >1.698600</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row8_col4\" class=\"data row8 col4\" >2.885300</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row8_col5\" class=\"data row8 col5\" >0.821300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row9\" class=\"row_heading level0 row9\" >LR_perfact_and_demo</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row9_col0\" class=\"data row9 col0\" >1.515200</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row9_col1\" class=\"data row9 col1\" >2.295800</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row9_col2\" class=\"data row9 col2\" >0.842900</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row9_col3\" class=\"data row9 col3\" >1.687500</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row9_col4\" class=\"data row9 col4\" >2.847800</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row9_col5\" class=\"data row9 col5\" >0.823700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row10\" class=\"row_heading level0 row10\" >LR_perfact_and_demo_tuned</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row10_col0\" class=\"data row10 col0\" >1.524900</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row10_col1\" class=\"data row10 col1\" >2.325300</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row10_col2\" class=\"data row10 col2\" >0.840800</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row10_col3\" class=\"data row10 col3\" >1.670600</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row10_col4\" class=\"data row10 col4\" >2.790900</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row10_col5\" class=\"data row10 col5\" >0.827200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row11\" class=\"row_heading level0 row11\" >LR_perfact_only_tuned</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row11_col0\" class=\"data row11 col0\" >1.545800</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row11_col1\" class=\"data row11 col1\" >2.389400</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row11_col2\" class=\"data row11 col2\" >0.836500</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row11_col3\" class=\"data row11 col3\" >1.659200</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row11_col4\" class=\"data row11 col4\" >2.753000</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row11_col5\" class=\"data row11 col5\" >0.829500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row12\" class=\"row_heading level0 row12\" >LR_all_tuned</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row12_col0\" class=\"data row12 col0\" >1.500700</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row12_col1\" class=\"data row12 col1\" >2.252000</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row12_col2\" class=\"data row12 col2\" >0.845900</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row12_col3\" class=\"data row12 col3\" >1.656600</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row12_col4\" class=\"data row12 col4\" >2.744400</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row12_col5\" class=\"data row12 col5\" >0.830100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row13\" class=\"row_heading level0 row13\" >LR_perfact_only</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row13_col0\" class=\"data row13 col0\" >1.543100</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row13_col1\" class=\"data row13 col1\" >2.381300</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row13_col2\" class=\"data row13 col2\" >0.837000</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row13_col3\" class=\"data row13 col3\" >1.653600</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row13_col4\" class=\"data row13 col4\" >2.734400</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row13_col5\" class=\"data row13 col5\" >0.830700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row14\" class=\"row_heading level0 row14\" >XGB_all_tuned</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row14_col0\" class=\"data row14 col0\" >0.786600</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row14_col1\" class=\"data row14 col1\" >0.618800</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row14_col2\" class=\"data row14 col2\" >0.957600</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row14_col3\" class=\"data row14 col3\" >1.599700</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row14_col4\" class=\"data row14 col4\" >2.559000</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row14_col5\" class=\"data row14 col5\" >0.841500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row15\" class=\"row_heading level0 row15\" >XGB_all</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row15_col0\" class=\"data row15 col0\" >0.048900</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row15_col1\" class=\"data row15 col1\" >0.002400</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row15_col2\" class=\"data row15 col2\" >0.999800</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row15_col3\" class=\"data row15 col3\" >1.570400</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row15_col4\" class=\"data row15 col4\" >2.466100</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row15_col5\" class=\"data row15 col5\" >0.847300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7level0_row16\" class=\"row_heading level0 row16\" >XGB_perfact_only_tuned</th>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row16_col0\" class=\"data row16 col0\" >1.364700</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row16_col1\" class=\"data row16 col1\" >1.862500</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row16_col2\" class=\"data row16 col2\" >0.872500</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row16_col3\" class=\"data row16 col3\" >1.489100</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row16_col4\" class=\"data row16 col4\" >2.217500</td>\n",
       "                        <td id=\"T_21aef0f6_9825_11ed_9eb1_59b4c8c782b7row16_col5\" class=\"data row16 col5\" >0.862700</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa712dfd5b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_subsets_df = pd.DataFrame(results_subsets[1]).transpose().sort_values(\"RMSE Test\",ascending=False).round(4)\n",
    "results_subsets_df[[\"RMSE Train\", \"MSE Train\", \"R2 Train\", \"RMSE Test\", \"MSE Test\", \"R2 Test\"]].style.highlight_min(subset=[\"MSE Train\", \"MSE Test\"], color = 'lightgreen', axis = 0).highlight_max(subset=[\"R2 Train\", \"R2 Test\"], color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_21bb653e_9825_11ed_9eb1_59b4c8c782b7row0_col4 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_21bb653e_9825_11ed_9eb1_59b4c8c782b7\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Baseline</th>        <th class=\"col_heading level0 col1\" >LR_demo_only_tuned</th>        <th class=\"col_heading level0 col2\" >LR_perfact_only_tuned</th>        <th class=\"col_heading level0 col3\" >LR_perfact_and_demo_tuned</th>        <th class=\"col_heading level0 col4\" >LR_all_tuned</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_21bb653e_9825_11ed_9eb1_59b4c8c782b7level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_21bb653e_9825_11ed_9eb1_59b4c8c782b7row0_col0\" class=\"data row0 col0\" >3.86 (0.166)</td>\n",
       "                        <td id=\"T_21bb653e_9825_11ed_9eb1_59b4c8c782b7row0_col1\" class=\"data row0 col1\" >3.76 (0.107)</td>\n",
       "                        <td id=\"T_21bb653e_9825_11ed_9eb1_59b4c8c782b7row0_col2\" class=\"data row0 col2\" >1.57 (0.099)</td>\n",
       "                        <td id=\"T_21bb653e_9825_11ed_9eb1_59b4c8c782b7row0_col3\" class=\"data row0 col3\" >1.58 (0.1)</td>\n",
       "                        <td id=\"T_21bb653e_9825_11ed_9eb1_59b4c8c782b7row0_col4\" class=\"data row0 col4\" >1.56 (0.101)</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa712d1ef40>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For LR\n",
    "models = [\"Baseline\"]+[i for i in results_subsets[0].keys() if (\"tuned\" in i and \"LR\" in i)]\n",
    "metric = \"RMSE Test\"\n",
    "\n",
    "#####\n",
    "dataset_res_dict = {}\n",
    "best_models = {}\n",
    "t_test_results = {}\n",
    "\n",
    "use_df = pd.DataFrame([pd.DataFrame(results_subsets[fold_num]).loc[metric,models] for fold_num in results_subsets.keys()],index=results_subsets.keys())*-1\n",
    "\n",
    "df_mean = pd.DataFrame((-1*use_df).mean(axis=0).round(2).astype(str) + \" (\" + use_df.std(axis=0).round(3).astype(str) + \")\").transpose()\n",
    "model_dict = {i: df_mean[i].values[0] for i in df_mean.columns}\n",
    "\n",
    "best_model = use_df.columns[use_df.mean(axis=0).argmax()]\n",
    "\n",
    "t_test_res = np.array([stats.ttest_rel(use_df[best_model].values, use_df[model].values)[1] for model in models]).round(3)\n",
    "t_test_res[np.isnan(t_test_res)] = 1.\n",
    "    \n",
    "res_df_lr = pd.DataFrame([model_dict])\n",
    "\n",
    "def negative_bold(val):\n",
    "    i = np.where(val.name==np.array(models))[0][0]\n",
    "    return [\"font-weight: bold\"  if t_test_res[i]>=0.05 else \"\" for dataset_name in val.keys()]\n",
    "    # Case without transpose:\n",
    "#     return [\"font-weight: bold\"  if t_test_results[val.name][i]>=0.05 else \"\" for i in range(len(val))]\n",
    "\n",
    "res_df_lr.style.apply(negative_bold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_21c17032_9825_11ed_9eb1_59b4c8c782b7row0_col2 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_21c17032_9825_11ed_9eb1_59b4c8c782b7row0_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_21c17032_9825_11ed_9eb1_59b4c8c782b7row0_col4 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_21c17032_9825_11ed_9eb1_59b4c8c782b7\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Baseline</th>        <th class=\"col_heading level0 col1\" >XGB_demo_only_tuned</th>        <th class=\"col_heading level0 col2\" >XGB_perfact_only_tuned</th>        <th class=\"col_heading level0 col3\" >XGB_perfact_and_demo_tuned</th>        <th class=\"col_heading level0 col4\" >XGB_all_tuned</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_21c17032_9825_11ed_9eb1_59b4c8c782b7level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_21c17032_9825_11ed_9eb1_59b4c8c782b7row0_col0\" class=\"data row0 col0\" >3.86 (0.166)</td>\n",
       "                        <td id=\"T_21c17032_9825_11ed_9eb1_59b4c8c782b7row0_col1\" class=\"data row0 col1\" >3.83 (0.149)</td>\n",
       "                        <td id=\"T_21c17032_9825_11ed_9eb1_59b4c8c782b7row0_col2\" class=\"data row0 col2\" >1.49 (0.089)</td>\n",
       "                        <td id=\"T_21c17032_9825_11ed_9eb1_59b4c8c782b7row0_col3\" class=\"data row0 col3\" >1.54 (0.138)</td>\n",
       "                        <td id=\"T_21c17032_9825_11ed_9eb1_59b4c8c782b7row0_col4\" class=\"data row0 col4\" >1.54 (0.054)</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa712d1e280>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For XGB\n",
    "models = [\"Baseline\"]+[i for i in results_subsets[0].keys() if (\"tuned\" in i and \"XGB\" in i)]\n",
    "metric = \"RMSE Test\"\n",
    "\n",
    "#####\n",
    "dataset_res_dict = {}\n",
    "best_models = {}\n",
    "t_test_results = {}\n",
    "\n",
    "use_df = pd.DataFrame([pd.DataFrame(results_subsets[fold_num]).loc[metric,models] for fold_num in results_subsets.keys()],index=results_subsets.keys())*-1\n",
    "\n",
    "df_mean = pd.DataFrame((-1*use_df).mean(axis=0).round(2).astype(str) + \" (\" + use_df.std(axis=0).round(3).astype(str) + \")\").transpose()\n",
    "model_dict = {i: df_mean[i].values[0] for i in df_mean.columns}\n",
    "\n",
    "best_model = use_df.columns[use_df.mean(axis=0).argmax()]\n",
    "\n",
    "t_test_res = np.array([stats.ttest_rel(use_df[best_model].values, use_df[model].values)[1] for model in models]).round(3)\n",
    "t_test_res[np.isnan(t_test_res)] = 1.\n",
    "    \n",
    "res_df_xgb = pd.DataFrame([model_dict])\n",
    "\n",
    "def negative_bold(val):\n",
    "    i = np.where(val.name==np.array(models))[0][0]\n",
    "    return [\"font-weight: bold\"  if t_test_res[i]>=0.05 else \"\" for dataset_name in val.keys()]\n",
    "    # Case without transpose:\n",
    "#     return [\"font-weight: bold\"  if t_test_results[val.name][i]>=0.05 else \"\" for i in range(len(val))]\n",
    "\n",
    "res_df_xgb.style.apply(negative_bold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>demo_only</th>\n",
       "      <th>perfact_only</th>\n",
       "      <th>perfact_and_demo</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>3.86 (0.166)</td>\n",
       "      <td>3.76 (0.107)</td>\n",
       "      <td>1.57 (0.099)</td>\n",
       "      <td>1.58 (0.1)</td>\n",
       "      <td>1.56 (0.101)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>3.86 (0.166)</td>\n",
       "      <td>3.83 (0.149)</td>\n",
       "      <td>1.49 (0.089)</td>\n",
       "      <td>1.54 (0.138)</td>\n",
       "      <td>1.54 (0.054)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Baseline     demo_only  perfact_only perfact_and_demo           all\n",
       "LR   3.86 (0.166)  3.76 (0.107)  1.57 (0.099)       1.58 (0.1)  1.56 (0.101)\n",
       "XGB  3.86 (0.166)  3.83 (0.149)  1.49 (0.089)     1.54 (0.138)  1.54 (0.054)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_lr.columns = [i[3:-6] if i != \"Baseline\" else \"Baseline\" for i in res_df_lr.columns]    \n",
    "res_df_xgb.columns = [i[4:-6] if i != \"Baseline\" else \"Baseline\" for i in res_df_xgb.columns]    \n",
    "\n",
    "latex_df_subsets = pd.concat([res_df_lr,res_df_xgb],axis=0)\n",
    "latex_df_subsets.index = [\"LR\", \"XGB\"]\n",
    "latex_df_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "{} &            LR &           XGB \\\\\n",
      "\\midrule\n",
      "Baseline         &  3.86 (0.166) &  3.86 (0.166) \\\\\n",
      "demo\\_only        &  3.76 (0.107) &  3.83 (0.149) \\\\\n",
      "perfact\\_only     &  1.57 (0.099) &  1.49 (0.089) \\\\\n",
      "perfact\\_and\\_demo &    1.58 (0.1) &  1.54 (0.138) \\\\\n",
      "all              &  1.56 (0.101) &  1.54 (0.054) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex_df_subsets.round(2).transpose().to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_10_importances = {}\n",
    "\n",
    "# for model in list(results_subsets_feature_importances[fold].keys()):\n",
    "#     imp_df = pd.concat([results_subsets_feature_importances[fold][model] for fold in range(folds)],axis=1)\n",
    "\n",
    "#     if \"LR\" in model:\n",
    "#         direction = imp_df.apply(lambda x: np.sign(x))\n",
    "#         imp_df = imp_df.abs()\n",
    "\n",
    "#     imp_df = imp_df/imp_df.sum(axis=0)\n",
    "\n",
    "#     mean_imp_df = imp_df.mean(axis=1)\n",
    "#     std_imp_df = imp_df.std(axis=1)\n",
    "\n",
    "#     mean_imp_df = mean_imp_df.sort_values(ascending=False)\n",
    "#     std_imp_df = std_imp_df.loc[mean_imp_df.index]\n",
    "#     final_imps = mean_imp_df[:10]\n",
    "#     final_imps[\"Rest\"] = sum(mean_imp_df[10:])\n",
    "#     top_5_importances[model] = np.array([final_imps.index.values, final_imps.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_importances = {}\n",
    "demo_importances_stds = {}\n",
    "\n",
    "for model in list(results_subsets_feature_importances[fold].keys()):\n",
    "    if \"demo\" in model or \"all\" in model:\n",
    "        imp_df_all = pd.concat([results_subsets_feature_importances[fold][model] for fold in range(folds)],axis=1)\n",
    "        \n",
    "        if \"LR\" in model:\n",
    "            direction = imp_df_all.apply(lambda x: np.sign(x))\n",
    "            imp_df_all = imp_df_all.abs()\n",
    "        if imp_df_all.sum().sum()!=0:\n",
    "            imp_df = imp_df_all/imp_df_all.sum(axis=0)\n",
    "        imp_df = imp_df.fillna(1/imp_df.shape[0])\n",
    "#         imp_df = imp_df.loc[demographic_cols]\n",
    "\n",
    "#         mean_imp_df = imp_df.mean(axis=1)\n",
    "#         std_imp_df = imp_df.std(axis=1)\n",
    "\n",
    "#         mean_imp_df = mean_imp_df.sort_values(ascending=False)\n",
    "#         std_imp_df = std_imp_df.loc[mean_imp_df.index]\n",
    "#         final_imps = mean_imp_df#[:10]\n",
    "#         final_imps[\"Rest\"] = sum(mean_imp_df[10:])\n",
    "#         final_imps[\"Total\"] = sum(mean_imp_df)\n",
    "        demo_importances[model] = np.round(np.mean(imp_df.loc[demographic_cols].sum(axis=0)),2)#final_imps.values\n",
    "        demo_importances_stds[model] = np.round(np.std(imp_df.loc[demographic_cols].sum(axis=0)),2)#final_imps.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_only</th>\n",
       "      <th>perfact_and_demo</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>1.0 (0.0)</td>\n",
       "      <td>0.08 (0.04)</td>\n",
       "      <td>0.03 (0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>1.0 (0.0)</td>\n",
       "      <td>0.26 (0.04)</td>\n",
       "      <td>0.16 (0.04)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     demo_only perfact_and_demo          all\n",
       "LR   1.0 (0.0)      0.08 (0.04)  0.03 (0.02)\n",
       "XGB  1.0 (0.0)      0.26 (0.04)  0.16 (0.04)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_demo_imp = pd.Series({i: demo_importances[i] for i in demo_importances if \"LR\" in i and \"tuned\" in i})\n",
    "xgb_demo_imp = pd.Series({i: demo_importances[i] for i in demo_importances if \"XGB\" in i and \"tuned\" in i})\n",
    "lr_demo_imp.index = [i[3:-6] for i in lr_demo_imp.index]    \n",
    "xgb_demo_imp.index = [i[4:-6] for i in xgb_demo_imp.index]    \n",
    "\n",
    "lr_demo_imp_stds = pd.Series({i: demo_importances_stds[i] for i in demo_importances_stds if \"LR\" in i and \"tuned\" in i})\n",
    "xgb_demo_imp_stds = pd.Series({i: demo_importances_stds[i] for i in demo_importances_stds if \"XGB\" in i and \"tuned\" in i})\n",
    "lr_demo_imp_stds.index = [i[3:-6] for i in lr_demo_imp_stds.index]    \n",
    "xgb_demo_imp_stds.index = [i[4:-6] for i in xgb_demo_imp_stds.index]    \n",
    "\n",
    "\n",
    "latex_df_imp = pd.DataFrame([lr_demo_imp.astype(str) + \" (\" + lr_demo_imp_stds.astype(str) + \")\",\n",
    "                             xgb_demo_imp.astype(str) + \" (\" + xgb_demo_imp_stds.astype(str) + \")\"])\n",
    "latex_df_imp.index = [\"LR\", \"XGB\"]\n",
    "latex_df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "{} &           LR &          XGB \\\\\n",
      "\\midrule\n",
      "demo\\_only        &    1.0 (0.0) &    1.0 (0.0) \\\\\n",
      "perfact\\_and\\_demo &  0.08 (0.04) &  0.26 (0.04) \\\\\n",
      "all              &  0.03 (0.02) &  0.16 (0.04) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex_df_imp.transpose().to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean impact of using demo features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.33772816154692337                            \n",
      "SCORE: 0.1603906219740407                             \n",
      "SCORE: 0.16655529760918364                                                       \n",
      "SCORE: 0.2626296144222785                                                       \n",
      "SCORE: 0.23775787075615923                                                      \n",
      "SCORE: 0.33467140692763786                                                      \n",
      "SCORE: 0.23834428845620986                                                      \n",
      "SCORE: 0.397071498986012                                                        \n",
      "SCORE: 0.36275741001466816                                                      \n",
      "SCORE: 0.25263909647371036                                                      \n",
      "SCORE: 0.1726794165149927                                                        \n",
      "SCORE: 0.3164141382542377                                                        \n",
      "SCORE: 0.19054061381638826                                                       \n",
      "SCORE: 0.2918823308850561                                                        \n",
      "SCORE: 0.19395281691972885                                                       \n",
      "SCORE: 0.17761068441042516                                                       \n",
      "SCORE: 0.3459258528164558                                                        \n",
      "SCORE: 0.22818528302311272                                                       \n",
      "SCORE: 0.2829401710056309                                                        \n",
      "SCORE: 0.23024703681779096                                                       \n",
      "SCORE: 0.16117708050241755                                                       \n",
      "SCORE: 0.16151214820223614                                                       \n",
      "SCORE: 0.1613226507088079                                                        \n",
      "SCORE: 0.20633551272222692                                                       \n",
      "SCORE: 0.167714392257164                                                         \n",
      "SCORE: 0.17853724468769616                                                       \n",
      "SCORE: 0.1670035964029988                                                        \n",
      "SCORE: 0.16038598185265424                                                       \n",
      "SCORE: 0.20870370207252814                                                        \n",
      "SCORE: 0.1714107531030861                                                         \n",
      "SCORE: 0.18613224607963774                                                        \n",
      "SCORE: 0.16336572997896115                                                        \n",
      "SCORE: 0.2061459376007999                                                         \n",
      "SCORE: 0.1699812984477079                                                         \n",
      "SCORE: 0.18002693731890737                                                        \n",
      "SCORE: 0.42414984405906236                                                        \n",
      "SCORE: 0.16361079160613415                                                        \n",
      "SCORE: 0.21930158307305173                                                        \n",
      "SCORE: 0.17325191299867918                                                        \n",
      "SCORE: 0.19864613833328867                                                        \n",
      "SCORE: 0.18436659230601876                                                        \n",
      "SCORE: 0.1619710808656545                                                         \n",
      "SCORE: 0.27858004938284675                                                        \n",
      "SCORE: 0.17446468708107804                                                        \n",
      "SCORE: 0.16833792718390664                                                        \n",
      "SCORE: 0.2567724549852143                                                         \n",
      "SCORE: 0.31031631781270264                                                        \n",
      "SCORE: 0.24026961768866228                                                        \n",
      "SCORE: 0.1908653235877002                                                         \n",
      "SCORE: 0.21825855956410675                                                        \n",
      "100%|| 50/50 [00:03<00:00, 14.61trial/s, best loss: 0.16038598185265424]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'alpha': 0.011377784323762902}\n",
      "Mean absolute Difference w\\o Demo: 0.28\n",
      "RMSE Difference w\\o Demo: 0.29\n",
      "SCORE: 0.2557503637601425                             \n",
      "SCORE: 0.17277563567849824                            \n",
      "SCORE: 0.27782298134828526                                                       \n",
      "SCORE: 0.17300257249688827                                                       \n",
      "SCORE: 0.3562978538123326                                                        \n",
      "SCORE: 0.3007846079391242                                                        \n",
      "SCORE: 0.20789018108789517                                                       \n",
      "SCORE: 0.22334904160826818                                                       \n",
      "SCORE: 0.18575050570736779                                                       \n",
      "SCORE: 0.3368964099945491                                                        \n",
      "SCORE: 0.3969063082455194                                                         \n",
      "SCORE: 0.2066798779366672                                                         \n",
      "SCORE: 0.20614900767773428                                                        \n",
      "SCORE: 0.29650379780950703                                                        \n",
      "SCORE: 0.17245849849140457                                                        \n",
      "SCORE: 0.2574332950886419                                                         \n",
      "SCORE: 0.3545383068658209                                                         \n",
      "SCORE: 0.32731907241401414                                                        \n",
      "SCORE: 0.19000960302039602                                                        \n",
      "SCORE: 0.4050761103559103                                                         \n",
      "SCORE: 0.1694243383876181                                                         \n",
      "SCORE: 0.16246038053880024                                                        \n",
      "SCORE: 0.16348782788156963                                                        \n",
      "SCORE: 0.1657964471314793                                                         \n",
      "SCORE: 0.16476715078833828                                                        \n",
      "SCORE: 0.18810709435714412                                                        \n",
      "SCORE: 0.17959454997807117                                                        \n",
      "SCORE: 0.16501199316207432                                                        \n",
      "SCORE: 0.17731017470628896                                                        \n",
      "SCORE: 0.22741558264630973                                                        \n",
      "SCORE: 0.16398215662416255                                                        \n",
      "SCORE: 0.2539958334503658                                                         \n",
      "SCORE: 0.17884326226896713                                                        \n",
      "SCORE: 0.16928695957591597                                                        \n",
      "SCORE: 0.19621277669333265                                                        \n",
      "SCORE: 0.17440947821767214                                                        \n",
      "SCORE: 0.1636618230455905                                                         \n",
      "SCORE: 0.4330782595474094                                                         \n",
      "SCORE: 0.24432187174028294                                                        \n",
      "SCORE: 0.1722912870132615                                                         \n",
      "SCORE: 0.19824488709706486                                                        \n",
      "SCORE: 0.21427571349641603                                                        \n",
      "SCORE: 0.1831420565446678                                                         \n",
      "SCORE: 0.289597524360952                                                          \n",
      "SCORE: 0.17471284600077058                                                        \n",
      "SCORE: 0.19458795647407062                                                        \n",
      "SCORE: 0.222678088821114                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.2660191823530487                                                         \n",
      "SCORE: 0.17139356495620234                                                        \n",
      "SCORE: 0.18244313549402041                                                        \n",
      "100%|| 50/50 [00:03<00:00, 14.77trial/s, best loss: 0.16246038053880024]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'alpha': 0.006185208905399513}\n",
      "Mean absolute Difference w\\o Demo: 0.37\n",
      "RMSE Difference w\\o Demo: 0.39\n",
      "SCORE: 0.2852219206921866                             \n",
      "SCORE: 0.3477436864125875                             \n",
      "SCORE: 0.24064055653366676                                                      \n",
      "SCORE: 0.17872346284965465                                                      \n",
      "SCORE: 0.17539512542426353                                                       \n",
      "SCORE: 0.3252347525810041                                                        \n",
      "SCORE: 0.3577988519511469                                                        \n",
      "SCORE: 0.1815076699111618                                                        \n",
      "SCORE: 0.24536369267575586                                                       \n",
      "SCORE: 0.350593838408901                                                         \n",
      "SCORE: 0.19029843822329506                                                        \n",
      "SCORE: 0.1867836186823556                                                         \n",
      "SCORE: 0.3660207685652284                                                         \n",
      "SCORE: 0.24833377066542991                                                        \n",
      "SCORE: 0.19079057942136388                                                        \n",
      "SCORE: 0.3445589700877799                                                         \n",
      "SCORE: 0.22214283227432974                                                        \n",
      "SCORE: 0.2832547777987649                                                         \n",
      "SCORE: 0.1942660836185662                                                         \n",
      "SCORE: 0.26274487964430276                                                        \n",
      "SCORE: 0.17610595803692797                                                        \n",
      "SCORE: 0.2090054484981633                                                         \n",
      "SCORE: 0.1756014179426685                                                         \n",
      "SCORE: 0.4139444238488821                                                         \n",
      "SCORE: 0.2059132384381614                                                         \n",
      "SCORE: 0.17687169232053074                                                        \n",
      "SCORE: 0.18472682267622018                                                        \n",
      "SCORE: 0.20283588075130723                                                        \n",
      "SCORE: 0.2262080581690374                                                         \n",
      "SCORE: 0.1975485263798265                                                         \n",
      "SCORE: 0.17573642526530642                                                        \n",
      "SCORE: 0.22080339374583433                                                        \n",
      "SCORE: 0.1847934825163593                                                         \n",
      "SCORE: 0.4307652970186224                                                         \n",
      "SCORE: 0.2970576318586578                                                         \n",
      "SCORE: 0.17762183328706                                                           \n",
      "SCORE: 0.18703300471912315                                                        \n",
      "SCORE: 0.2141588161222739                                                         \n",
      "SCORE: 0.1813580385077283                                                         \n",
      "SCORE: 0.23411768095064467                                                        \n",
      "SCORE: 0.19789640372743283                                                        \n",
      "SCORE: 0.3899204511268926                                                         \n",
      "SCORE: 0.3040574599034772                                                         \n",
      "SCORE: 0.17964556586824026                                                        \n",
      "SCORE: 0.26755528552635405                                                        \n",
      "SCORE: 0.18826053463017828                                                        \n",
      "SCORE: 0.18392077823703157                                                        \n",
      "SCORE: 0.19302016562436775                                                        \n",
      "SCORE: 0.3189100689771992                                                         \n",
      "SCORE: 0.2622343228296293                                                         \n",
      "100%|| 50/50 [00:03<00:00, 14.62trial/s, best loss: 0.17539512542426353]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'alpha': 0.008885765433360698}\n",
      "Mean absolute Difference w\\o Demo: 0.33\n",
      "RMSE Difference w\\o Demo: 0.34\n",
      "SCORE: 0.17673545396451354                            \n",
      "SCORE: 0.2684323362101836                             \n",
      "SCORE: 0.19143707662704834                                                       \n",
      "SCORE: 0.165669332167058                                                         \n",
      "SCORE: 0.3284676402375222                                                        \n",
      "SCORE: 0.16312065485672392                                                     \n",
      "SCORE: 0.294375452810268                                                         \n",
      "SCORE: 0.40392333588843377                                                       \n",
      "SCORE: 0.28536963208843924                                                       \n",
      "SCORE: 0.3525077923803915                                                        \n",
      "SCORE: 0.169548892604414                                                          \n",
      "SCORE: 0.1651000869979987                                                         \n",
      "SCORE: 0.3426798062315699                                                         \n",
      "SCORE: 0.25239879106710567                                                        \n",
      "SCORE: 0.28689032751852467                                                        \n",
      "SCORE: 0.3633836877350485                                                         \n",
      "SCORE: 0.3590875456435353                                                         \n",
      "SCORE: 0.26395326662112173                                                        \n",
      "SCORE: 0.18072060230377632                                                        \n",
      "SCORE: 0.3913510285371633                                                         \n",
      "SCORE: 0.20517400047084222                                                        \n",
      "SCORE: 0.16365662405873665                                                        \n",
      "SCORE: 0.22658232535719475                                                        \n",
      "SCORE: 0.16780835520083578                                                        \n",
      "SCORE: 0.17437491242300812                                                        \n",
      "SCORE: 0.20234076638512014                                                        \n",
      "SCORE: 0.18595892720964538                                                        \n",
      "SCORE: 0.17188307613684076                                                        \n",
      "SCORE: 0.16464896810853974                                                        \n",
      "SCORE: 0.2203606352370397                                                         \n",
      "SCORE: 0.17629741852321637                                                        \n",
      "SCORE: 0.1946850362092585                                                         \n",
      "SCORE: 0.18196705787391312                                                        \n",
      "SCORE: 0.21247592349466699                                                        \n",
      "SCORE: 0.24243632278409014                                                        \n",
      "SCORE: 0.1720391413656413                                                         \n",
      "SCORE: 0.16321239835693785                                                        \n",
      "SCORE: 0.19193158075586808                                                        \n",
      "SCORE: 0.16999860702847025                                                        \n",
      "SCORE: 0.16411732302105678                                                        \n",
      "SCORE: 0.18143830883957543                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.31643455804198883                                                        \n",
      "SCORE: 0.1738386672833208                                                         \n",
      "SCORE: 0.19520041884745185                                                        \n",
      "SCORE: 0.2395806972387236                                                         \n",
      "SCORE: 0.18705179664507093                                                        \n",
      "SCORE: 0.16938833245915919                                                        \n",
      "SCORE: 0.1771383144825181                                                         \n",
      "SCORE: 0.2999503316721232                                                         \n",
      "SCORE: 0.2713607721923562                                                         \n",
      "100%|| 50/50 [00:03<00:00, 15.23trial/s, best loss: 0.16312065485672392]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'alpha': 0.018542617441564106}\n",
      "Mean absolute Difference w\\o Demo: 0.18\n",
      "RMSE Difference w\\o Demo: 0.18\n",
      "SCORE: 0.3769241119787114                             \n",
      "SCORE: 0.1669267188688528                             \n",
      "SCORE: 0.16830856494388985                                                      \n",
      "SCORE: 0.16801590198172017                                                      \n",
      "SCORE: 0.3516645754138569                                                       \n",
      "SCORE: 0.29503048188913344                                                      \n",
      "SCORE: 0.21394598346555654                                                      \n",
      "SCORE: 0.16697216424615183                                                      \n",
      "SCORE: 0.38965664615772166                                                      \n",
      "SCORE: 0.18916629151189898                                                      \n",
      "SCORE: 0.21898359848031607                                                       \n",
      "SCORE: 0.2800673708477387                                                        \n",
      "SCORE: 0.42081859657011816                                                       \n",
      "SCORE: 0.22794682062493465                                                       \n",
      "SCORE: 0.38338318127713944                                                       \n",
      "SCORE: 0.1929146004497369                                                        \n",
      "SCORE: 0.1761643117426649                                                        \n",
      "SCORE: 0.18432264039216703                                                       \n",
      "SCORE: 0.2192683632683551                                                        \n",
      "SCORE: 0.33399758171101307                                                       \n",
      "SCORE: 0.16243843933632823                                                       \n",
      "SCORE: 0.15914241186599581                                                       \n",
      "SCORE: 0.16573172721504148                                                        \n",
      "SCORE: 0.15914720071216815                                                        \n",
      "SCORE: 0.17305779315146513                                                        \n",
      "SCORE: 0.16639141950618191                                                        \n",
      "SCORE: 0.24444442156893126                                                        \n",
      "SCORE: 0.1770630695020135                                                         \n",
      "SCORE: 0.20549591156621916                                                        \n",
      "SCORE: 0.25136594652689015                                                        \n",
      "SCORE: 0.16117508207813197                                                        \n",
      "SCORE: 0.1717903964368004                                                         \n",
      "SCORE: 0.2002918616400045                                                         \n",
      "SCORE: 0.16977261064183485                                                        \n",
      "SCORE: 0.18308394240803316                                                        \n",
      "SCORE: 0.16342659440179982                                                        \n",
      "SCORE: 0.29228839342483154                                                        \n",
      "SCORE: 0.16785640944179403                                                        \n",
      "SCORE: 0.17920285701357175                                                        \n",
      "SCORE: 0.1643997424629872                                                         \n",
      "SCORE: 0.33163835936836905                                                        \n",
      "SCORE: 0.2606145731481798                                                         \n",
      "SCORE: 0.19952460826752577                                                        \n",
      "SCORE: 0.17009372619593774                                                        \n",
      "SCORE: 0.18993467651421886                                                        \n",
      "SCORE: 0.15933639019417323                                                        \n",
      "SCORE: 0.16717793166125292                                                        \n",
      "SCORE: 0.23615018366659246                                                        \n",
      "SCORE: 0.17473627673603223                                                        \n",
      "SCORE: 0.4084470554072789                                                         \n",
      "100%|| 50/50 [00:03<00:00, 14.98trial/s, best loss: 0.15914241186599581]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'alpha': 0.012897303746370017}\n",
      "Mean absolute Difference w\\o Demo: 0.26\n",
      "RMSE Difference w\\o Demo: 0.27\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RS)\n",
    "mean_abs_differences = []\n",
    "for fold in range(folds):\n",
    "    X_train = data_dict[f\"X_train_{fold}\"]\n",
    "    y_train = data_dict[f\"y_train_{fold}\"]\n",
    "\n",
    "    X_val = data_dict[f\"X_val_{fold}\"]\n",
    "    y_val = data_dict[f\"y_val_{fold}\"]\n",
    "\n",
    "    X_test = data_dict[f\"X_test_{fold}\"]\n",
    "    y_test = data_dict[f\"y_test_{fold}\"]\n",
    "\n",
    "    target_scaler = data_dict[f\"target_scaler_{fold}\"]\n",
    "\n",
    "    y_train_val = np.concatenate([y_train,y_val])\n",
    "\n",
    "    # Define data subset for LR\n",
    "    z_glmm_encoded_train = data_dict[f\"z_glmm_encoded_train_{fold}\"] \n",
    "    z_glmm_encoded_val = data_dict[f\"z_glmm_encoded_val_{fold}\"] \n",
    "    z_glmm_encoded_test = data_dict[f\"z_glmm_encoded_test_{fold}\"] \n",
    "\n",
    "    X_train_lr = pd.concat([X_train,z_glmm_encoded_train],axis=1)\n",
    "    X_val_lr = pd.concat([X_val,z_glmm_encoded_val],axis=1)\n",
    "    X_test_lr = pd.concat([X_test,z_glmm_encoded_test],axis=1)      \n",
    "    X_train_val_lr = pd.concat([X_train_lr,X_val_lr])\n",
    "\n",
    "    # Rescale GLMM\n",
    "    for col in z_glmm_encoded_train.columns:\n",
    "        z_mean = X_train_val_lr[col].mean()\n",
    "        z_std = X_train_val_lr[col].std()\n",
    "\n",
    "        X_train_val_lr[col] = (X_train_val_lr[col]-z_mean)/z_std\n",
    "        X_test_lr[col] = (X_test_lr[col]-z_mean)/z_std\n",
    "\n",
    "\n",
    "    # Define data subset for XGB\n",
    "    z_ordinal_encoded_train = data_dict[f\"z_ordinal_encoded_train_{fold}\"] \n",
    "    z_ordinal_encoded_val = data_dict[f\"z_ordinal_encoded_val_{fold}\"] \n",
    "    z_ordinal_encoded_test = data_dict[f\"z_ordinal_encoded_test_{fold}\"] \n",
    "    X_train_xgb = pd.concat([X_train,z_ordinal_encoded_train],axis=1)\n",
    "    X_val_xgb = pd.concat([X_val,z_ordinal_encoded_val],axis=1)\n",
    "    X_test_xgb = pd.concat([X_test,z_ordinal_encoded_test],axis=1)\n",
    "    X_train_val_xgb = pd.concat([X_train_xgb,X_val_xgb])\n",
    "\n",
    "    final_hyperparameters = tune_lasso(X_train_val_lr, y_train_val, max_evals=max_evals, seed=RS)\n",
    "    lr = Lasso(alpha=final_hyperparameters[\"alpha\"],\n",
    "               random_state=RS)\n",
    "#     lr = Lasso(alpha=0.001)\n",
    "    lr.fit(X_train_val_lr,y_train_val)\n",
    "    y_pred = target_scaler.inverse_transform(lr.predict(X_test_lr).reshape(-1,1)).ravel()\n",
    "\n",
    "    is_not_demo = [i not in demographic_cols for i in X_train_val_lr.columns]\n",
    "    y_pred_notdemo = target_scaler.inverse_transform(np.dot(X_test_lr.loc[:,is_not_demo],lr.coef_[is_not_demo]).reshape(-1,1)).ravel()\n",
    "    mean_abs_diff = np.round(np.mean(np.abs(y_pred-y_pred_notdemo)),2)\n",
    "    print(f\"Mean absolute Difference w\\o Demo: {mean_abs_diff}\")\n",
    "    print(f\"RMSE Difference w\\o Demo: {np.round(np.sqrt(np.mean(np.power(y_pred-y_pred_notdemo,2))),2)}\")\n",
    "    mean_abs_differences.append(mean_abs_diff)\n",
    "    # is_demo = [i in demographic_cols for i in X_train_val_lr.columns]\n",
    "    # y_pred_demo = target_scaler.inverse_transform(np.dot(X_test_lr.loc[:,is_demo],lr.coef_[is_demo]).reshape(-1,1)).ravel()\n",
    "\n",
    "    # print(f\"Mean absolute Difference with Demo: {np.mean(np.abs(y_pred-y_pred_demo))}\")\n",
    "    # print(f\"RMSE Difference with Demo: {np.sqrt(np.mean(np.power(y_pred-y_pred_demo,2)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.28, 0.06)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mean_abs_differences).round(2),np.std(mean_abs_differences).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc07112e7ae1e8e28a0232207620ff002934c05692de8df42430404c766a0a8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
