{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils.evaluation import *\n",
    "from utils.utils import *\n",
    "\n",
    "from data import dataset_preprocessing\n",
    "\n",
    "from utils.evaluation import get_metrics\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"OULAD\"\n",
    "mode=\"cv\"\n",
    "RS=68\n",
    "hct=10\n",
    "test_ratio=0.2\n",
    "val_ratio=0.1\n",
    "folds=5\n",
    "target = \"binary\"\n",
    "experiment_name = \"EDM_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########  Preprocessing #################################\n",
    "if not os.path.exists(f\"../data/prepared/{dataset_name}/df_prepared.pickle\"):\n",
    "\n",
    "    assessments_df = pd.read_csv(f'../data/raw/{dataset_name}/assessments.csv')\n",
    "    courses_df = pd.read_csv(f'../data/raw/{dataset_name}/courses.csv')\n",
    "    studentAssessment_df = pd.read_csv(f'../data/raw/{dataset_name}/studentAssessment.csv')\n",
    "    studentInfo_df = pd.read_csv(f'../data/raw/{dataset_name}/studentInfo.csv')\n",
    "    studentRegistration_df = pd.read_csv(f'../data/raw/{dataset_name}/studentRegistration.csv')\n",
    "    studentVle_df = pd.read_csv(f'../data/raw/{dataset_name}/studentVle.csv')\n",
    "    vle_df = pd.read_csv(f'../data/raw/{dataset_name}/vle.csv')\n",
    "\n",
    "\n",
    "    # Remove all withdrawn\n",
    "    studentInfo_df = studentInfo_df.loc[studentInfo_df.final_result!=\"Withdrawn\"]\n",
    "    studentInfo_df.shape\n",
    "\n",
    "    # Assessment performance features\n",
    "    merged_assessments_df = pd.merge(studentAssessment_df,assessments_df,on=\"id_assessment\")\n",
    "\n",
    "    avg_tma = [merged_assessments_df.loc[np.logical_and(merged_assessments_df.id_student==i,merged_assessments_df.assessment_type==\"TMA\"),\"score\"].mean() for i in studentInfo_df.id_student.values]\n",
    "    avg_cma = [merged_assessments_df.loc[np.logical_and(merged_assessments_df.id_student==i,merged_assessments_df.assessment_type==\"CMA\"),\"score\"].mean() for i in studentInfo_df.id_student.values]\n",
    "    avg_exam = [merged_assessments_df.loc[np.logical_and(merged_assessments_df.id_student==i,merged_assessments_df.assessment_type==\"Exam\"),\"score\"].mean() for i in studentInfo_df.id_student.values]\n",
    "\n",
    "    studentInfo_df[\"avg_tma\"] = avg_tma\n",
    "    studentInfo_df[\"avg_cma\"] = avg_cma\n",
    "    studentInfo_df[\"avg_exam\"] = avg_exam\n",
    "\n",
    "    # Get VLE features\n",
    "    vle_merged = pd.merge(studentVle_df,vle_df,on=[\"code_module\", \"code_presentation\", \"id_site\"])\n",
    "    for activity_type in vle_df.activity_type.unique():\n",
    "        agg = vle_merged.loc[vle_merged.activity_type==activity_type].groupby(\"id_student\")\n",
    "        count_click_dict = dict(agg.count()[\"sum_click\"])\n",
    "        sum_click_dict = dict(agg.sum()[\"sum_click\"])\n",
    "        studentInfo_df[f\"Count_Visits_{activity_type}\"] = studentInfo_df[\"id_student\"].apply(lambda x: sum_click_dict[x] if x in count_click_dict.keys() else 0)\n",
    "        studentInfo_df[f\"Sum_Clicks_{activity_type}\"] = studentInfo_df[\"id_student\"].apply(lambda x: sum_click_dict[x] if x in sum_click_dict.keys() else 0)\n",
    "\n",
    "    with open(f\"../data/prepared/{dataset_name}/df_prepared.pickle\", 'wb') as handle:\n",
    "        pickle.dump(studentInfo_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    df = studentInfo_df\n",
    "\n",
    "else:    \n",
    "    with open(f\"../data/prepared/{dataset_name}/df_prepared.pickle\", 'rb') as handle:\n",
    "        df = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop([\"id_student\", \"code_module\", \"code_presentation\", \"avg_exam\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"final_result\"] = df[\"final_result\"].apply(lambda x: 0 if x==\"Fail\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_col = \"final_result\"\n",
    "demographic_cols = ['gender', 'region', 'imd_band', 'age_band', 'disability', 'highest_education']\n",
    "perf_cols = [\"avg_cma\", \"avg_tma\", 'num_of_prev_attempts', 'studied_credits']\n",
    "activity_cols = [i for i in df.columns if \"Sum_Clicks\" in i] + [i for i in df.columns if \"Count_Visits\" in i]\n",
    "other_cols = []\n",
    "\n",
    "set(df.columns)-set([y_col]+demographic_cols+perf_cols+activity_cols+other_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. of samples</th>\n",
       "      <th>No. of features</th>\n",
       "      <th>Performance features</th>\n",
       "      <th>Demographic features</th>\n",
       "      <th>Activity features</th>\n",
       "      <th>Other features</th>\n",
       "      <th>Categorical features</th>\n",
       "      <th>Total cardinality</th>\n",
       "      <th>% NA</th>\n",
       "      <th>Target $\\textbf{y} \\in$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cortez</th>\n",
       "      <td>22437</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>0.480034</td>\n",
       "      <td>[1..2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        No. of samples  No. of features  Performance features  \\\n",
       "cortez           22437               51                     4   \n",
       "\n",
       "        Demographic features  Activity features  Other features  \\\n",
       "cortez                     6                 40               0   \n",
       "\n",
       "        Categorical features  Total cardinality      % NA  \\\n",
       "cortez                     4                 31  0.480034   \n",
       "\n",
       "       Target $\\textbf{y} \\in$  \n",
       "cortez                  [1..2]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_df_dict = {\"No. of samples\": df.shape[0],\n",
    "           \"No. of features\": df.shape[1],\n",
    "           \"Performance features\": len(perf_cols),\n",
    "           \"Demographic features\": len(demographic_cols),\n",
    "           \"Activity features\": len(activity_cols),\n",
    "           \"Other features\": len(other_cols),\n",
    "           \"Categorical features\": len(df.columns[list(np.logical_and(df.nunique() > 2, df.dtypes == \"object\"))]),     \n",
    "           \"Total cardinality\": df[df.columns[list(np.logical_and(df.nunique() > 2, df.dtypes == \"object\"))]].nunique().sum(),     \n",
    "           \"% NA\": df.isna().sum().sum()/sum(df.shape),\n",
    "           \"Target $\\textbf{y} \\in$\": f\"[1..{df[y_col].nunique()}]\",\n",
    "#            \"High cardinality levels\":  list(df.loc[:,list(df.columns[list(np.logical_and(df.nunique() >= 10, df.dtypes == \"object\"))])].nunique().sort_values().values),\n",
    "          \n",
    "}\n",
    "desc_df = pd.DataFrame([desc_df_dict],index=[\"cortez\"])\n",
    "desc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "{} &    cortez \\\\\n",
      "\\midrule\n",
      "No. of samples          &     22437 \\\\\n",
      "No. of features         &        51 \\\\\n",
      "Performance features    &         4 \\\\\n",
      "Demographic features    &         6 \\\\\n",
      "Activity features       &        40 \\\\\n",
      "Other features          &         0 \\\\\n",
      "Categorical features    &         4 \\\\\n",
      "Total cardinality       &        31 \\\\\n",
      "\\% NA                    &  0.480034 \\\\\n",
      "Target \\$\\textbackslash textbf\\{y\\} \\textbackslash in\\$ &    [1..2] \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(desc_df.transpose().to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = f\"{mode}_RS{RS}_hct{hct}\"\n",
    "if mode == \"cv\":\n",
    "    data_path += f\"_{folds}folds\"\n",
    "elif mode == \"train_test\":\n",
    "    data_path += f\"_split{1-test_ratio*100}-{test_ratio*100}\"\n",
    "elif mode == \"train_val_test\":\n",
    "    data_path += f\"_split{round(100-(test_ratio+val_ratio)*100)}-{round(test_ratio*100)}-{round(val_ratio*100)}\"\n",
    "\n",
    "\n",
    "# If no data_dict for the configuration exists, run preprocessing, else load data_dict\n",
    "if not os.path.exists(f\"../data/prepared/{dataset_name}/\"+data_path+\"/data_dict.pickle\"):\n",
    "    dataset_preprocessing.process_dataset(dataset_name, target, mode, RS, hct, test_ratio, val_ratio, folds)\n",
    "with open(f\"../data/prepared/{dataset_name}/{data_path}/data_dict.pickle\", 'rb') as handle:\n",
    "        data_dict = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of categorical data treatment methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\"ignore\", \"ohe\", \"target\", \"ordinal\", \"catboost\", \"glmm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_rounds = 10\n",
    "max_evals = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_f1a65b40_9826_11ed_921d_5fdcc57329f8row0_col3 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1a65b40_9826_11ed_921d_5fdcc57329f8row0_col4 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1a65b40_9826_11ed_921d_5fdcc57329f8row0_col5 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1a65b40_9826_11ed_921d_5fdcc57329f8row7_col2 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1a65b40_9826_11ed_921d_5fdcc57329f8row9_col0 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1a65b40_9826_11ed_921d_5fdcc57329f8row9_col1 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1a65b40_9826_11ed_921d_5fdcc57329f8row9_col2 {\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy Train</th>        <th class=\"col_heading level0 col1\" >F1 Train</th>        <th class=\"col_heading level0 col2\" >AUROC Train</th>        <th class=\"col_heading level0 col3\" >Accuracy Test</th>        <th class=\"col_heading level0 col4\" >F1 Test</th>        <th class=\"col_heading level0 col5\" >AUROC Test</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row0\" class=\"row_heading level0 row0\" >XGB_glmm_tuned</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row0_col0\" class=\"data row0 col0\" >0.910700</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row0_col1\" class=\"data row0 col1\" >0.936800</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row0_col2\" class=\"data row0 col2\" >0.965200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row0_col3\" class=\"data row0 col3\" >0.875400</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row0_col4\" class=\"data row0 col4\" >0.911900</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row0_col5\" class=\"data row0 col5\" >0.929700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row1\" class=\"row_heading level0 row1\" >XGB_target_tuned</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row1_col0\" class=\"data row1 col0\" >0.931700</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row1_col1\" class=\"data row1 col1\" >0.951300</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row1_col2\" class=\"data row1 col2\" >0.978800</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row1_col3\" class=\"data row1 col3\" >0.872300</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row1_col4\" class=\"data row1 col4\" >0.909000</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row1_col5\" class=\"data row1 col5\" >0.927800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row2\" class=\"row_heading level0 row2\" >XGB_catboost_tuned</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row2_col0\" class=\"data row2 col0\" >0.912000</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row2_col1\" class=\"data row2 col1\" >0.937700</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row2_col2\" class=\"data row2 col2\" >0.966300</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row2_col3\" class=\"data row2 col3\" >0.869200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row2_col4\" class=\"data row2 col4\" >0.908400</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row2_col5\" class=\"data row2 col5\" >0.928200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row3\" class=\"row_heading level0 row3\" >XGB_ohe_tuned</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row3_col0\" class=\"data row3 col0\" >0.896900</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row3_col1\" class=\"data row3 col1\" >0.927000</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row3_col2\" class=\"data row3 col2\" >0.953200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row3_col3\" class=\"data row3 col3\" >0.868500</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row3_col4\" class=\"data row3 col4\" >0.906900</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row3_col5\" class=\"data row3 col5\" >0.927400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row4\" class=\"row_heading level0 row4\" >XGB_ignore_tuned</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row4_col0\" class=\"data row4 col0\" >0.911100</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row4_col1\" class=\"data row4 col1\" >0.937000</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row4_col2\" class=\"data row4 col2\" >0.966200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row4_col3\" class=\"data row4 col3\" >0.867600</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row4_col4\" class=\"data row4 col4\" >0.906200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row4_col5\" class=\"data row4 col5\" >0.925300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row5\" class=\"row_heading level0 row5\" >XGB_ordinal_tuned</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row5_col0\" class=\"data row5 col0\" >0.944100</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row5_col1\" class=\"data row5 col1\" >0.960000</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row5_col2\" class=\"data row5 col2\" >0.987100</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row5_col3\" class=\"data row5 col3\" >0.867400</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row5_col4\" class=\"data row5 col4\" >0.905500</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row5_col5\" class=\"data row5 col5\" >0.923500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row6\" class=\"row_heading level0 row6\" >XGB_ignore</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row6_col0\" class=\"data row6 col0\" >0.940600</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row6_col1\" class=\"data row6 col1\" >0.957700</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row6_col2\" class=\"data row6 col2\" >0.986600</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row6_col3\" class=\"data row6 col3\" >0.864800</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row6_col4\" class=\"data row6 col4\" >0.904000</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row6_col5\" class=\"data row6 col5\" >0.918300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row7\" class=\"row_heading level0 row7\" >XGB_glmm</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row7_col0\" class=\"data row7 col0\" >0.952800</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row7_col1\" class=\"data row7 col1\" >0.966200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row7_col2\" class=\"data row7 col2\" >0.991500</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row7_col3\" class=\"data row7 col3\" >0.863600</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row7_col4\" class=\"data row7 col4\" >0.903300</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row7_col5\" class=\"data row7 col5\" >0.922200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row8\" class=\"row_heading level0 row8\" >XGB_target</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row8_col0\" class=\"data row8 col0\" >0.948800</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row8_col1\" class=\"data row8 col1\" >0.963400</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row8_col2\" class=\"data row8 col2\" >0.989600</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row8_col3\" class=\"data row8 col3\" >0.864100</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row8_col4\" class=\"data row8 col4\" >0.903100</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row8_col5\" class=\"data row8 col5\" >0.923800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row9\" class=\"row_heading level0 row9\" >XGB_catboost</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row9_col0\" class=\"data row9 col0\" >0.953500</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row9_col1\" class=\"data row9 col1\" >0.966700</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row9_col2\" class=\"data row9 col2\" >0.991500</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row9_col3\" class=\"data row9 col3\" >0.860300</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row9_col4\" class=\"data row9 col4\" >0.901900</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row9_col5\" class=\"data row9 col5\" >0.916600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row10\" class=\"row_heading level0 row10\" >XGB_ordinal</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row10_col0\" class=\"data row10 col0\" >0.944300</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row10_col1\" class=\"data row10 col1\" >0.960300</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row10_col2\" class=\"data row10 col2\" >0.988600</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row10_col3\" class=\"data row10 col3\" >0.860700</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row10_col4\" class=\"data row10 col4\" >0.901000</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row10_col5\" class=\"data row10 col5\" >0.921900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row11\" class=\"row_heading level0 row11\" >XGB_ohe</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row11_col0\" class=\"data row11 col0\" >0.944200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row11_col1\" class=\"data row11 col1\" >0.960100</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row11_col2\" class=\"data row11 col2\" >0.987800</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row11_col3\" class=\"data row11 col3\" >0.859200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row11_col4\" class=\"data row11 col4\" >0.899900</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row11_col5\" class=\"data row11 col5\" >0.920900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row12\" class=\"row_heading level0 row12\" >LR_catboost_tuned</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row12_col0\" class=\"data row12 col0\" >0.816900</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row12_col1\" class=\"data row12 col1\" >0.870400</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row12_col2\" class=\"data row12 col2\" >0.864100</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row12_col3\" class=\"data row12 col3\" >0.821300</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row12_col4\" class=\"data row12 col4\" >0.873600</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row12_col5\" class=\"data row12 col5\" >0.870000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row13\" class=\"row_heading level0 row13\" >LR_catboost</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row13_col0\" class=\"data row13 col0\" >0.816800</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row13_col1\" class=\"data row13 col1\" >0.870400</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row13_col2\" class=\"data row13 col2\" >0.864100</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row13_col3\" class=\"data row13 col3\" >0.821300</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row13_col4\" class=\"data row13 col4\" >0.873600</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row13_col5\" class=\"data row13 col5\" >0.869900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row14\" class=\"row_heading level0 row14\" >LR_ohe_tuned</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row14_col0\" class=\"data row14 col0\" >0.816400</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row14_col1\" class=\"data row14 col1\" >0.870300</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row14_col2\" class=\"data row14 col2\" >0.865900</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row14_col3\" class=\"data row14 col3\" >0.821100</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row14_col4\" class=\"data row14 col4\" >0.873000</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row14_col5\" class=\"data row14 col5\" >0.871700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row15\" class=\"row_heading level0 row15\" >LR_ohe</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row15_col0\" class=\"data row15 col0\" >0.816200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row15_col1\" class=\"data row15 col1\" >0.870000</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row15_col2\" class=\"data row15 col2\" >0.866200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row15_col3\" class=\"data row15 col3\" >0.820900</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row15_col4\" class=\"data row15 col4\" >0.872700</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row15_col5\" class=\"data row15 col5\" >0.871900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row16\" class=\"row_heading level0 row16\" >LR_ignore</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row16_col0\" class=\"data row16 col0\" >0.817400</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row16_col1\" class=\"data row16 col1\" >0.870900</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row16_col2\" class=\"data row16 col2\" >0.861000</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row16_col3\" class=\"data row16 col3\" >0.820200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row16_col4\" class=\"data row16 col4\" >0.872500</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row16_col5\" class=\"data row16 col5\" >0.867200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row17\" class=\"row_heading level0 row17\" >LR_ignore_tuned</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row17_col0\" class=\"data row17 col0\" >0.817300</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row17_col1\" class=\"data row17 col1\" >0.870800</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row17_col2\" class=\"data row17 col2\" >0.861000</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row17_col3\" class=\"data row17 col3\" >0.819500</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row17_col4\" class=\"data row17 col4\" >0.872000</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row17_col5\" class=\"data row17 col5\" >0.867200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row18\" class=\"row_heading level0 row18\" >LR_glmm_tuned</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row18_col0\" class=\"data row18 col0\" >0.816600</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row18_col1\" class=\"data row18 col1\" >0.870100</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row18_col2\" class=\"data row18 col2\" >0.864800</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row18_col3\" class=\"data row18 col3\" >0.819700</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row18_col4\" class=\"data row18 col4\" >0.872000</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row18_col5\" class=\"data row18 col5\" >0.871100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row19\" class=\"row_heading level0 row19\" >LR_glmm</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row19_col0\" class=\"data row19 col0\" >0.816700</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row19_col1\" class=\"data row19 col1\" >0.870100</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row19_col2\" class=\"data row19 col2\" >0.864800</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row19_col3\" class=\"data row19 col3\" >0.819500</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row19_col4\" class=\"data row19 col4\" >0.871900</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row19_col5\" class=\"data row19 col5\" >0.871100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row20\" class=\"row_heading level0 row20\" >LR_target_tuned</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row20_col0\" class=\"data row20 col0\" >0.816800</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row20_col1\" class=\"data row20 col1\" >0.870200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row20_col2\" class=\"data row20 col2\" >0.865200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row20_col3\" class=\"data row20 col3\" >0.819500</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row20_col4\" class=\"data row20 col4\" >0.871800</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row20_col5\" class=\"data row20 col5\" >0.871200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row21\" class=\"row_heading level0 row21\" >LR_target</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row21_col0\" class=\"data row21 col0\" >0.816900</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row21_col1\" class=\"data row21 col1\" >0.870300</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row21_col2\" class=\"data row21 col2\" >0.865200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row21_col3\" class=\"data row21 col3\" >0.819500</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row21_col4\" class=\"data row21 col4\" >0.871800</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row21_col5\" class=\"data row21 col5\" >0.871200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row22\" class=\"row_heading level0 row22\" >LR_ordinal</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row22_col0\" class=\"data row22 col0\" >0.816500</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row22_col1\" class=\"data row22 col1\" >0.870100</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row22_col2\" class=\"data row22 col2\" >0.862600</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row22_col3\" class=\"data row22 col3\" >0.816400</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row22_col4\" class=\"data row22 col4\" >0.870200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row22_col5\" class=\"data row22 col5\" >0.868100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row23\" class=\"row_heading level0 row23\" >LR_ordinal_tuned</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row23_col0\" class=\"data row23 col0\" >0.816400</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row23_col1\" class=\"data row23 col1\" >0.870100</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row23_col2\" class=\"data row23 col2\" >0.862500</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row23_col3\" class=\"data row23 col3\" >0.816200</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row23_col4\" class=\"data row23 col4\" >0.870100</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row23_col5\" class=\"data row23 col5\" >0.867900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8level0_row24\" class=\"row_heading level0 row24\" >Baseline</th>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row24_col0\" class=\"data row24 col0\" >0.685700</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row24_col1\" class=\"data row24 col1\" >0.813600</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row24_col2\" class=\"data row24 col2\" >0.500000</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row24_col3\" class=\"data row24 col3\" >0.685600</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row24_col4\" class=\"data row24 col4\" >0.813500</td>\n",
       "                        <td id=\"T_f1a65b40_9826_11ed_921d_5fdcc57329f8row24_col5\" class=\"data row24 col5\" >0.500000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff2284cc6a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(f\"../results/{dataset_name}/{experiment_name}/results_encodings.pickle\"):\n",
    "\n",
    "    results_encodings = {}\n",
    "    results_encodings_feature_importances = {}\n",
    "\n",
    "    for fold in range(folds):\n",
    "        results_encodings[fold] = {}\n",
    "        results_encodings_feature_importances[fold] = {}\n",
    "        # Create baseline\n",
    "        y_train = data_dict[f\"y_train_{fold}\"]\n",
    "        y_val = data_dict[f\"y_val_{fold}\"]\n",
    "        y_test = data_dict[f\"y_test_{fold}\"]\n",
    "        y_train_val = np.concatenate([y_train,y_val])\n",
    "\n",
    "        max_ = np.argmax(np.unique(y_train_val,return_counts=True)[1])\n",
    "        y_train_val_pred_base = np.ones(y_train_val.shape[0])*max_\n",
    "        y_test_pred_base = np.ones(y_test.shape[0])*max_\n",
    "\n",
    "        results_encodings[fold][\"Baseline\"] = {}\n",
    "        eval_res_train = get_metrics(y_train_val, y_train_val_pred_base, target=target)\n",
    "        for metric in eval_res_train.keys():\n",
    "            results_encodings[fold][\"Baseline\"][metric + \" Train\"] = eval_res_train[metric]\n",
    "        eval_res_test = get_metrics(y_test, y_test_pred_base, target=target)\n",
    "        for metric in eval_res_test.keys():\n",
    "            results_encodings[fold][\"Baseline\"][metric + \" Test\"] = eval_res_test[metric]\n",
    "\n",
    "        for condition in conditions:\n",
    "            print(f\"Preparing results for fold {fold}, condition={condition}\")\n",
    "            # Retrieve data\n",
    "            z_cols = data_dict[\"z_cols\"]\n",
    "\n",
    "            X_train = data_dict[f\"X_train_{fold}\"]\n",
    "            y_train = data_dict[f\"y_train_{fold}\"]\n",
    "\n",
    "            X_val = data_dict[f\"X_val_{fold}\"]\n",
    "            y_val = data_dict[f\"y_val_{fold}\"]\n",
    "\n",
    "            X_test = data_dict[f\"X_test_{fold}\"]\n",
    "            y_test = data_dict[f\"y_test_{fold}\"]\n",
    "\n",
    "            # Define condition data subset\n",
    "            if condition != \"ignore\":\n",
    "                z_encoded_train = data_dict[f\"z_{condition}_encoded_train_{fold}\"] \n",
    "                z_encoded_val = data_dict[f\"z_{condition}_encoded_val_{fold}\"] \n",
    "                z_encoded_test = data_dict[f\"z_{condition}_encoded_test_{fold}\"] \n",
    "\n",
    "                X_train = pd.concat([X_train,z_encoded_train],axis=1)\n",
    "                X_val = pd.concat([X_val,z_encoded_val],axis=1)\n",
    "                X_test = pd.concat([X_test,z_encoded_test],axis=1)\n",
    "\n",
    "            X_train_val = pd.concat([X_train,X_val])\n",
    "            y_train_val = np.concatenate([y_train,y_val])\n",
    "\n",
    "            # Train base models\n",
    "            res, feats = evaluate_logreg(X_train_val, y_train_val, X_test, y_test, target=target,tune=False, seed=RS)\n",
    "            results_encodings[fold][\"LR_\"+condition] = res\n",
    "            results_encodings_feature_importances[fold][\"LR_\"+condition] = feats\n",
    "\n",
    "            res, feats = evaluate_xgb(X_train_val, y_train_val, X_test, y_test, target, tune=False, max_evals=max_evals, early_stopping_rounds=early_stopping_rounds, seed=RS)\n",
    "            results_encodings[fold][\"XGB_\"+condition] = res\n",
    "            results_encodings_feature_importances[fold][\"XGB_\"+condition] = feats\n",
    "\n",
    "            # Train tuned models\n",
    "            res, feats = evaluate_logreg(X_train_val, y_train_val, X_test, y_test, target=target, max_evals=max_evals, tune=True, seed=RS)\n",
    "            results_encodings[fold][\"LR_\"+condition+\"_tuned\"] = res\n",
    "            results_encodings_feature_importances[fold][\"LR_\"+condition+\"_tuned\"] = feats\n",
    "\n",
    "            res, feats = evaluate_xgb(X_train_val, y_train_val, X_test, y_test, target, tune=True, max_evals=max_evals, early_stopping_rounds=early_stopping_rounds, seed=RS)\n",
    "            results_encodings[fold][\"XGB_\"+condition+\"_tuned\"] = res\n",
    "            results_encodings_feature_importances[fold][\"XGB_\"+condition+\"_tuned\"] = feats\n",
    "    \n",
    "    if not os.path.exists(f\"../results/{dataset_name}/{experiment_name}\"):\n",
    "        os.makedirs(f\"../results/{dataset_name}/{experiment_name}\")\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_encodings.pickle\", 'wb') as handle:\n",
    "        pickle.dump(results_encodings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_encodings_feature_importances.pickle\", 'wb') as handle:\n",
    "        pickle.dump(results_encodings_feature_importances, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_encodings.pickle\", 'rb') as handle:\n",
    "        results_encodings = pickle.load(handle)\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_encodings_feature_importances.pickle\", 'rb') as handle:\n",
    "        results_encodings_feature_importances = pickle.load(handle)\n",
    "        \n",
    "        \n",
    "results_encodings_df = pd.DataFrame(results_encodings[0]).transpose().sort_values(\"F1 Test\",ascending=False).round(4)\n",
    "results_encodings_df[[\"Accuracy Train\", \"F1 Train\", \"AUROC Train\", \"Accuracy Test\", \"F1 Test\", \"AUROC Test\"]].style.highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_f1b2c376_9826_11ed_921d_5fdcc57329f8row0_col3 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1b2c376_9826_11ed_921d_5fdcc57329f8row0_col4 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1b2c376_9826_11ed_921d_5fdcc57329f8row2_col5 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1b2c376_9826_11ed_921d_5fdcc57329f8row11_col0 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1b2c376_9826_11ed_921d_5fdcc57329f8row11_col1 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1b2c376_9826_11ed_921d_5fdcc57329f8row11_col2 {\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy Train</th>        <th class=\"col_heading level0 col1\" >F1 Train</th>        <th class=\"col_heading level0 col2\" >AUROC Train</th>        <th class=\"col_heading level0 col3\" >Accuracy Test</th>        <th class=\"col_heading level0 col4\" >F1 Test</th>        <th class=\"col_heading level0 col5\" >AUROC Test</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row0\" class=\"row_heading level0 row0\" >XGB_ignore_tuned</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row0_col0\" class=\"data row0 col0\" >0.928200</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row0_col1\" class=\"data row0 col1\" >0.948900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row0_col2\" class=\"data row0 col2\" >0.976600</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row0_col3\" class=\"data row0 col3\" >0.875700</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row0_col4\" class=\"data row0 col4\" >0.912200</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row0_col5\" class=\"data row0 col5\" >0.924400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row1\" class=\"row_heading level0 row1\" >XGB_ohe_tuned</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row1_col0\" class=\"data row1 col0\" >0.898000</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row1_col1\" class=\"data row1 col1\" >0.927900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row1_col2\" class=\"data row1 col2\" >0.955800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row1_col3\" class=\"data row1 col3\" >0.873400</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row1_col4\" class=\"data row1 col4\" >0.910600</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row1_col5\" class=\"data row1 col5\" >0.926000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row2\" class=\"row_heading level0 row2\" >XGB_glmm_tuned</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row2_col0\" class=\"data row2 col0\" >0.929300</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row2_col1\" class=\"data row2 col1\" >0.949600</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row2_col2\" class=\"data row2 col2\" >0.978700</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row2_col3\" class=\"data row2 col3\" >0.871700</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row2_col4\" class=\"data row2 col4\" >0.909400</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row2_col5\" class=\"data row2 col5\" >0.926600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row3\" class=\"row_heading level0 row3\" >XGB_catboost_tuned</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row3_col0\" class=\"data row3 col0\" >0.945800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row3_col1\" class=\"data row3 col1\" >0.961200</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row3_col2\" class=\"data row3 col2\" >0.987500</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row3_col3\" class=\"data row3 col3\" >0.870800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row3_col4\" class=\"data row3 col4\" >0.908800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row3_col5\" class=\"data row3 col5\" >0.925400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row4\" class=\"row_heading level0 row4\" >XGB_glmm</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row4_col0\" class=\"data row4 col0\" >0.953800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row4_col1\" class=\"data row4 col1\" >0.966900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row4_col2\" class=\"data row4 col2\" >0.991100</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row4_col3\" class=\"data row4 col3\" >0.871200</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row4_col4\" class=\"data row4 col4\" >0.908800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row4_col5\" class=\"data row4 col5\" >0.920400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row5\" class=\"row_heading level0 row5\" >XGB_target</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row5_col0\" class=\"data row5 col0\" >0.949900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row5_col1\" class=\"data row5 col1\" >0.964100</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row5_col2\" class=\"data row5 col2\" >0.990200</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row5_col3\" class=\"data row5 col3\" >0.870500</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row5_col4\" class=\"data row5 col4\" >0.908700</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row5_col5\" class=\"data row5 col5\" >0.919800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row6\" class=\"row_heading level0 row6\" >XGB_target_tuned</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row6_col0\" class=\"data row6 col0\" >0.921900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row6_col1\" class=\"data row6 col1\" >0.944400</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row6_col2\" class=\"data row6 col2\" >0.973700</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row6_col3\" class=\"data row6 col3\" >0.870500</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row6_col4\" class=\"data row6 col4\" >0.908500</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row6_col5\" class=\"data row6 col5\" >0.925200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row7\" class=\"row_heading level0 row7\" >XGB_ordinal</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row7_col0\" class=\"data row7 col0\" >0.948900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row7_col1\" class=\"data row7 col1\" >0.963400</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row7_col2\" class=\"data row7 col2\" >0.990100</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row7_col3\" class=\"data row7 col3\" >0.869700</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row7_col4\" class=\"data row7 col4\" >0.907900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row7_col5\" class=\"data row7 col5\" >0.919700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row8\" class=\"row_heading level0 row8\" >XGB_ignore</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row8_col0\" class=\"data row8 col0\" >0.943200</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row8_col1\" class=\"data row8 col1\" >0.959500</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row8_col2\" class=\"data row8 col2\" >0.986100</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row8_col3\" class=\"data row8 col3\" >0.868500</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row8_col4\" class=\"data row8 col4\" >0.907500</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row8_col5\" class=\"data row8 col5\" >0.919300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row9\" class=\"row_heading level0 row9\" >XGB_ordinal_tuned</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row9_col0\" class=\"data row9 col0\" >0.949600</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row9_col1\" class=\"data row9 col1\" >0.963900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row9_col2\" class=\"data row9 col2\" >0.989200</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row9_col3\" class=\"data row9 col3\" >0.869000</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row9_col4\" class=\"data row9 col4\" >0.907500</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row9_col5\" class=\"data row9 col5\" >0.920600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row10\" class=\"row_heading level0 row10\" >XGB_ohe</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row10_col0\" class=\"data row10 col0\" >0.948600</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row10_col1\" class=\"data row10 col1\" >0.963200</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row10_col2\" class=\"data row10 col2\" >0.989400</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row10_col3\" class=\"data row10 col3\" >0.869200</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row10_col4\" class=\"data row10 col4\" >0.907400</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row10_col5\" class=\"data row10 col5\" >0.920600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row11\" class=\"row_heading level0 row11\" >XGB_catboost</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row11_col0\" class=\"data row11 col0\" >0.954800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row11_col1\" class=\"data row11 col1\" >0.967600</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row11_col2\" class=\"data row11 col2\" >0.992200</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row11_col3\" class=\"data row11 col3\" >0.865900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row11_col4\" class=\"data row11 col4\" >0.905200</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row11_col5\" class=\"data row11 col5\" >0.917700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row12\" class=\"row_heading level0 row12\" >LR_glmm_tuned</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row12_col0\" class=\"data row12 col0\" >0.812900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row12_col1\" class=\"data row12 col1\" >0.867500</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row12_col2\" class=\"data row12 col2\" >0.862600</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row12_col3\" class=\"data row12 col3\" >0.827300</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row12_col4\" class=\"data row12 col4\" >0.878300</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row12_col5\" class=\"data row12 col5\" >0.877100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row13\" class=\"row_heading level0 row13\" >LR_ohe</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row13_col0\" class=\"data row13 col0\" >0.813400</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row13_col1\" class=\"data row13 col1\" >0.867900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row13_col2\" class=\"data row13 col2\" >0.864200</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row13_col3\" class=\"data row13 col3\" >0.827100</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row13_col4\" class=\"data row13 col4\" >0.878100</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row13_col5\" class=\"data row13 col5\" >0.876900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row14\" class=\"row_heading level0 row14\" >LR_glmm</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row14_col0\" class=\"data row14 col0\" >0.812600</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row14_col1\" class=\"data row14 col1\" >0.867300</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row14_col2\" class=\"data row14 col2\" >0.862600</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row14_col3\" class=\"data row14 col3\" >0.827100</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row14_col4\" class=\"data row14 col4\" >0.877900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row14_col5\" class=\"data row14 col5\" >0.877200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row15\" class=\"row_heading level0 row15\" >LR_target_tuned</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row15_col0\" class=\"data row15 col0\" >0.812600</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row15_col1\" class=\"data row15 col1\" >0.867300</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row15_col2\" class=\"data row15 col2\" >0.863000</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row15_col3\" class=\"data row15 col3\" >0.826900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row15_col4\" class=\"data row15 col4\" >0.877900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row15_col5\" class=\"data row15 col5\" >0.877200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row16\" class=\"row_heading level0 row16\" >LR_target</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row16_col0\" class=\"data row16 col0\" >0.812500</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row16_col1\" class=\"data row16 col1\" >0.867200</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row16_col2\" class=\"data row16 col2\" >0.863000</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row16_col3\" class=\"data row16 col3\" >0.826900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row16_col4\" class=\"data row16 col4\" >0.877900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row16_col5\" class=\"data row16 col5\" >0.877200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row17\" class=\"row_heading level0 row17\" >LR_catboost</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row17_col0\" class=\"data row17 col0\" >0.813600</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row17_col1\" class=\"data row17 col1\" >0.868000</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row17_col2\" class=\"data row17 col2\" >0.862700</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row17_col3\" class=\"data row17 col3\" >0.825100</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row17_col4\" class=\"data row17 col4\" >0.877900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row17_col5\" class=\"data row17 col5\" >0.876600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row18\" class=\"row_heading level0 row18\" >LR_ohe_tuned</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row18_col0\" class=\"data row18 col0\" >0.812900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row18_col1\" class=\"data row18 col1\" >0.867800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row18_col2\" class=\"data row18 col2\" >0.863900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row18_col3\" class=\"data row18 col3\" >0.826400</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row18_col4\" class=\"data row18 col4\" >0.877800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row18_col5\" class=\"data row18 col5\" >0.876600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row19\" class=\"row_heading level0 row19\" >LR_catboost_tuned</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row19_col0\" class=\"data row19 col0\" >0.813800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row19_col1\" class=\"data row19 col1\" >0.868200</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row19_col2\" class=\"data row19 col2\" >0.862700</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row19_col3\" class=\"data row19 col3\" >0.824900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row19_col4\" class=\"data row19 col4\" >0.877700</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row19_col5\" class=\"data row19 col5\" >0.876600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row20\" class=\"row_heading level0 row20\" >LR_ordinal</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row20_col0\" class=\"data row20 col0\" >0.812000</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row20_col1\" class=\"data row20 col1\" >0.867000</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row20_col2\" class=\"data row20 col2\" >0.860800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row20_col3\" class=\"data row20 col3\" >0.824400</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row20_col4\" class=\"data row20 col4\" >0.876100</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row20_col5\" class=\"data row20 col5\" >0.874600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row21\" class=\"row_heading level0 row21\" >LR_ignore</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row21_col0\" class=\"data row21 col0\" >0.813000</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row21_col1\" class=\"data row21 col1\" >0.867600</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row21_col2\" class=\"data row21 col2\" >0.859100</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row21_col3\" class=\"data row21 col3\" >0.823800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row21_col4\" class=\"data row21 col4\" >0.875900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row21_col5\" class=\"data row21 col5\" >0.872400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row22\" class=\"row_heading level0 row22\" >LR_ignore_tuned</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row22_col0\" class=\"data row22 col0\" >0.811500</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row22_col1\" class=\"data row22 col1\" >0.866800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row22_col2\" class=\"data row22 col2\" >0.858800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row22_col3\" class=\"data row22 col3\" >0.823300</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row22_col4\" class=\"data row22 col4\" >0.875800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row22_col5\" class=\"data row22 col5\" >0.872000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row23\" class=\"row_heading level0 row23\" >LR_ordinal_tuned</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row23_col0\" class=\"data row23 col0\" >0.811900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row23_col1\" class=\"data row23 col1\" >0.867100</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row23_col2\" class=\"data row23 col2\" >0.860400</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row23_col3\" class=\"data row23 col3\" >0.823500</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row23_col4\" class=\"data row23 col4\" >0.875800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row23_col5\" class=\"data row23 col5\" >0.874000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8level0_row24\" class=\"row_heading level0 row24\" >Baseline</th>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row24_col0\" class=\"data row24 col0\" >0.684800</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row24_col1\" class=\"data row24 col1\" >0.812900</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row24_col2\" class=\"data row24 col2\" >0.500000</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row24_col3\" class=\"data row24 col3\" >0.689400</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row24_col4\" class=\"data row24 col4\" >0.816100</td>\n",
       "                        <td id=\"T_f1b2c376_9826_11ed_921d_5fdcc57329f8row24_col5\" class=\"data row24 col5\" >0.500000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff30d3026d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_encodings_df = pd.DataFrame(results_encodings[1]).transpose().sort_values(\"F1 Test\",ascending=False).round(4)\n",
    "results_encodings_df[[\"Accuracy Train\", \"F1 Train\", \"AUROC Train\", \"Accuracy Test\", \"F1 Test\", \"AUROC Test\"]].style.highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_f1bc0c06_9826_11ed_921d_5fdcc57329f8row0_col2 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_f1bc0c06_9826_11ed_921d_5fdcc57329f8row0_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_f1bc0c06_9826_11ed_921d_5fdcc57329f8row0_col5 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_f1bc0c06_9826_11ed_921d_5fdcc57329f8row0_col6 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_f1bc0c06_9826_11ed_921d_5fdcc57329f8\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Baseline</th>        <th class=\"col_heading level0 col1\" >LR_ignore_tuned</th>        <th class=\"col_heading level0 col2\" >LR_ohe_tuned</th>        <th class=\"col_heading level0 col3\" >LR_target_tuned</th>        <th class=\"col_heading level0 col4\" >LR_ordinal_tuned</th>        <th class=\"col_heading level0 col5\" >LR_catboost_tuned</th>        <th class=\"col_heading level0 col6\" >LR_glmm_tuned</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f1bc0c06_9826_11ed_921d_5fdcc57329f8level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_f1bc0c06_9826_11ed_921d_5fdcc57329f8row0_col0\" class=\"data row0 col0\" >0.81 (0.004)</td>\n",
       "                        <td id=\"T_f1bc0c06_9826_11ed_921d_5fdcc57329f8row0_col1\" class=\"data row0 col1\" >0.87 (0.008)</td>\n",
       "                        <td id=\"T_f1bc0c06_9826_11ed_921d_5fdcc57329f8row0_col2\" class=\"data row0 col2\" >0.87 (0.008)</td>\n",
       "                        <td id=\"T_f1bc0c06_9826_11ed_921d_5fdcc57329f8row0_col3\" class=\"data row0 col3\" >0.87 (0.008)</td>\n",
       "                        <td id=\"T_f1bc0c06_9826_11ed_921d_5fdcc57329f8row0_col4\" class=\"data row0 col4\" >0.87 (0.009)</td>\n",
       "                        <td id=\"T_f1bc0c06_9826_11ed_921d_5fdcc57329f8row0_col5\" class=\"data row0 col5\" >0.87 (0.008)</td>\n",
       "                        <td id=\"T_f1bc0c06_9826_11ed_921d_5fdcc57329f8row0_col6\" class=\"data row0 col6\" >0.87 (0.008)</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff22857bf70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For LR\n",
    "models = [\"Baseline\"]+[i for i in results_encodings[0].keys() if (\"tuned\" in i and \"LR\" in i)]\n",
    "metric = \"F1 Test\"\n",
    "\n",
    "#####\n",
    "dataset_res_dict = {}\n",
    "best_models = {}\n",
    "t_test_results = {}\n",
    "\n",
    "use_df = pd.DataFrame([pd.DataFrame(results_encodings[fold_num]).loc[metric,models] for fold_num in results_encodings.keys()],index=results_encodings.keys())\n",
    "\n",
    "df_mean = pd.DataFrame((use_df).mean(axis=0).round(2).astype(str) + \" (\" + use_df.std(axis=0).round(3).astype(str) + \")\").transpose()\n",
    "model_dict = {i: df_mean[i].values[0] for i in df_mean.columns}\n",
    "\n",
    "best_model = use_df.columns[use_df.mean(axis=0).argmax()]\n",
    "\n",
    "t_test_res = np.array([stats.ttest_rel(use_df[best_model].values, use_df[model].values)[1] for model in models]).round(3)\n",
    "t_test_res[np.isnan(t_test_res)] = 1.\n",
    "    \n",
    "res_df_lr = pd.DataFrame([model_dict])\n",
    "\n",
    "def negative_bold(val):\n",
    "    i = np.where(val.name==np.array(models))[0][0]\n",
    "    return [\"font-weight: bold\"  if t_test_res[i]>=0.05 else \"\" for dataset_name in val.keys()]\n",
    "    # Case without transpose:\n",
    "#     return [\"font-weight: bold\"  if t_test_results[val.name][i]>=0.05 else \"\" for i in range(len(val))]\n",
    "\n",
    "res_df_lr.style.apply(negative_bold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_f1c28900_9826_11ed_921d_5fdcc57329f8row0_col1 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_f1c28900_9826_11ed_921d_5fdcc57329f8row0_col2 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_f1c28900_9826_11ed_921d_5fdcc57329f8row0_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_f1c28900_9826_11ed_921d_5fdcc57329f8row0_col4 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_f1c28900_9826_11ed_921d_5fdcc57329f8row0_col5 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_f1c28900_9826_11ed_921d_5fdcc57329f8row0_col6 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_f1c28900_9826_11ed_921d_5fdcc57329f8\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Baseline</th>        <th class=\"col_heading level0 col1\" >XGB_ignore_tuned</th>        <th class=\"col_heading level0 col2\" >XGB_ohe_tuned</th>        <th class=\"col_heading level0 col3\" >XGB_target_tuned</th>        <th class=\"col_heading level0 col4\" >XGB_ordinal_tuned</th>        <th class=\"col_heading level0 col5\" >XGB_catboost_tuned</th>        <th class=\"col_heading level0 col6\" >XGB_glmm_tuned</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f1c28900_9826_11ed_921d_5fdcc57329f8level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_f1c28900_9826_11ed_921d_5fdcc57329f8row0_col0\" class=\"data row0 col0\" >0.81 (0.004)</td>\n",
       "                        <td id=\"T_f1c28900_9826_11ed_921d_5fdcc57329f8row0_col1\" class=\"data row0 col1\" >0.91 (0.005)</td>\n",
       "                        <td id=\"T_f1c28900_9826_11ed_921d_5fdcc57329f8row0_col2\" class=\"data row0 col2\" >0.91 (0.004)</td>\n",
       "                        <td id=\"T_f1c28900_9826_11ed_921d_5fdcc57329f8row0_col3\" class=\"data row0 col3\" >0.91 (0.004)</td>\n",
       "                        <td id=\"T_f1c28900_9826_11ed_921d_5fdcc57329f8row0_col4\" class=\"data row0 col4\" >0.91 (0.001)</td>\n",
       "                        <td id=\"T_f1c28900_9826_11ed_921d_5fdcc57329f8row0_col5\" class=\"data row0 col5\" >0.91 (0.002)</td>\n",
       "                        <td id=\"T_f1c28900_9826_11ed_921d_5fdcc57329f8row0_col6\" class=\"data row0 col6\" >0.91 (0.004)</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff2285120a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For LR\n",
    "models = [\"Baseline\"]+[i for i in results_encodings[0].keys() if (\"tuned\" in i and \"XGB\" in i)]\n",
    "metric = \"F1 Test\"\n",
    "\n",
    "#####\n",
    "dataset_res_dict = {}\n",
    "best_models = {}\n",
    "t_test_results = {}\n",
    "\n",
    "use_df = pd.DataFrame([pd.DataFrame(results_encodings[fold_num]).loc[metric,models] for fold_num in results_encodings.keys()],index=results_encodings.keys())\n",
    "\n",
    "df_mean = pd.DataFrame((use_df).mean(axis=0).round(2).astype(str) + \" (\" + use_df.std(axis=0).round(3).astype(str) + \")\").transpose()\n",
    "model_dict = {i: df_mean[i].values[0] for i in df_mean.columns}\n",
    "\n",
    "best_model = use_df.columns[use_df.mean(axis=0).argmax()]\n",
    "\n",
    "t_test_res = np.array([stats.ttest_rel(use_df[best_model].values, use_df[model].values)[1] for model in models]).round(3)\n",
    "t_test_res[np.isnan(t_test_res)] = 1.\n",
    "    \n",
    "res_df_xgb = pd.DataFrame([model_dict])\n",
    "\n",
    "def negative_bold(val):\n",
    "    i = np.where(val.name==np.array(models))[0][0]\n",
    "    return [\"font-weight: bold\"  if t_test_res[i]>=0.05 else \"\" for dataset_name in val.keys()]\n",
    "    # Case without transpose:\n",
    "#     return [\"font-weight: bold\"  if t_test_results[val.name][i]>=0.05 else \"\" for i in range(len(val))]\n",
    "\n",
    "res_df_xgb.style.apply(negative_bold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>ignore</th>\n",
       "      <th>ohe</th>\n",
       "      <th>target</th>\n",
       "      <th>ordinal</th>\n",
       "      <th>catboost</th>\n",
       "      <th>glmm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.81 (0.004)</td>\n",
       "      <td>0.87 (0.008)</td>\n",
       "      <td>0.87 (0.008)</td>\n",
       "      <td>0.87 (0.008)</td>\n",
       "      <td>0.87 (0.009)</td>\n",
       "      <td>0.87 (0.008)</td>\n",
       "      <td>0.87 (0.008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.81 (0.004)</td>\n",
       "      <td>0.91 (0.005)</td>\n",
       "      <td>0.91 (0.004)</td>\n",
       "      <td>0.91 (0.004)</td>\n",
       "      <td>0.91 (0.001)</td>\n",
       "      <td>0.91 (0.002)</td>\n",
       "      <td>0.91 (0.004)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Baseline        ignore           ohe        target       ordinal  \\\n",
       "LR   0.81 (0.004)  0.87 (0.008)  0.87 (0.008)  0.87 (0.008)  0.87 (0.009)   \n",
       "XGB  0.81 (0.004)  0.91 (0.005)  0.91 (0.004)  0.91 (0.004)  0.91 (0.001)   \n",
       "\n",
       "         catboost          glmm  \n",
       "LR   0.87 (0.008)  0.87 (0.008)  \n",
       "XGB  0.91 (0.002)  0.91 (0.004)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_lr.columns = [i.split(\"_\")[1] if i != \"Baseline\" else \"Baseline\" for i in res_df_lr.columns]    \n",
    "res_df_xgb.columns = [i.split(\"_\")[1] if i != \"Baseline\" else \"Baseline\" for i in res_df_xgb.columns]    \n",
    "\n",
    "latex_df_encodings = pd.concat([res_df_lr,res_df_xgb],axis=0)\n",
    "latex_df_encodings.index = [\"LR\", \"XGB\"]\n",
    "latex_df_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "{} &      Baseline &        ignore &           ohe &        target &       ordinal &      catboost &          glmm \\\\\n",
      "\\midrule\n",
      "LR  &  0.81 (0.004) &  0.87 (0.008) &  0.87 (0.008) &  0.87 (0.008) &  0.87 (0.009) &  0.87 (0.008) &  0.87 (0.008) \\\\\n",
      "XGB &  0.81 (0.004) &  0.91 (0.005) &  0.91 (0.004) &  0.91 (0.004) &  0.91 (0.001) &  0.91 (0.002) &  0.91 (0.004) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex_df_encodings.round(2).to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Subset Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = {\"demo_only\": demographic_cols,\n",
    "           \"perfact_only\": perf_cols+activity_cols,\n",
    "           \"perfact_and_demo\": perf_cols+activity_cols+demographic_cols,\n",
    "           \"all\": list(df.columns)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row0_col3 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row0_col4 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row0_col5 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row4_col0 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row4_col1 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row4_col2 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row5_col0 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row5_col1 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row5_col2 {\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Accuracy Train</th>        <th class=\"col_heading level0 col1\" >F1 Train</th>        <th class=\"col_heading level0 col2\" >AUROC Train</th>        <th class=\"col_heading level0 col3\" >Accuracy Test</th>        <th class=\"col_heading level0 col4\" >F1 Test</th>        <th class=\"col_heading level0 col5\" >AUROC Test</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row0\" class=\"row_heading level0 row0\" >XGB_all_tuned</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row0_col0\" class=\"data row0 col0\" >0.902700</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row0_col1\" class=\"data row0 col1\" >0.931200</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row0_col2\" class=\"data row0 col2\" >0.957900</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row0_col3\" class=\"data row0 col3\" >0.869400</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row0_col4\" class=\"data row0 col4\" >0.907700</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row0_col5\" class=\"data row0 col5\" >0.927700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row1\" class=\"row_heading level0 row1\" >XGB_perfact_and_demo_tuned</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row1_col0\" class=\"data row1 col0\" >0.896800</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row1_col1\" class=\"data row1 col1\" >0.927100</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row1_col2\" class=\"data row1 col2\" >0.954800</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row1_col3\" class=\"data row1 col3\" >0.868300</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row1_col4\" class=\"data row1 col4\" >0.907100</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row1_col5\" class=\"data row1 col5\" >0.926600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row2\" class=\"row_heading level0 row2\" >XGB_perfact_only_tuned</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row2_col0\" class=\"data row2 col0\" >0.905300</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row2_col1\" class=\"data row2 col1\" >0.932900</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row2_col2\" class=\"data row2 col2\" >0.960900</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row2_col3\" class=\"data row2 col3\" >0.868800</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row2_col4\" class=\"data row2 col4\" >0.907000</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row2_col5\" class=\"data row2 col5\" >0.924300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row3\" class=\"row_heading level0 row3\" >XGB_perfact_only</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row3_col0\" class=\"data row3 col0\" >0.941700</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row3_col1\" class=\"data row3 col1\" >0.958400</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row3_col2\" class=\"data row3 col2\" >0.986200</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row3_col3\" class=\"data row3 col3\" >0.862700</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row3_col4\" class=\"data row3 col4\" >0.902600</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row3_col5\" class=\"data row3 col5\" >0.920000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row4\" class=\"row_heading level0 row4\" >XGB_perfact_and_demo</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row4_col0\" class=\"data row4 col0\" >0.944300</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row4_col1\" class=\"data row4 col1\" >0.960300</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row4_col2\" class=\"data row4 col2\" >0.988600</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row4_col3\" class=\"data row4 col3\" >0.860700</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row4_col4\" class=\"data row4 col4\" >0.901000</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row4_col5\" class=\"data row4 col5\" >0.921900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row5\" class=\"row_heading level0 row5\" >XGB_all</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row5_col0\" class=\"data row5 col0\" >0.944300</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row5_col1\" class=\"data row5 col1\" >0.960300</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row5_col2\" class=\"data row5 col2\" >0.988600</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row5_col3\" class=\"data row5 col3\" >0.860700</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row5_col4\" class=\"data row5 col4\" >0.901000</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row5_col5\" class=\"data row5 col5\" >0.921900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row6\" class=\"row_heading level0 row6\" >LR_perfact_and_demo_tuned</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row6_col0\" class=\"data row6 col0\" >0.816400</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row6_col1\" class=\"data row6 col1\" >0.869900</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row6_col2\" class=\"data row6 col2\" >0.864700</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row6_col3\" class=\"data row6 col3\" >0.820900</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row6_col4\" class=\"data row6 col4\" >0.872800</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row6_col5\" class=\"data row6 col5\" >0.871000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row7\" class=\"row_heading level0 row7\" >LR_all_tuned</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row7_col0\" class=\"data row7 col0\" >0.816400</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row7_col1\" class=\"data row7 col1\" >0.869900</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row7_col2\" class=\"data row7 col2\" >0.864700</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row7_col3\" class=\"data row7 col3\" >0.820900</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row7_col4\" class=\"data row7 col4\" >0.872800</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row7_col5\" class=\"data row7 col5\" >0.871000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row8\" class=\"row_heading level0 row8\" >LR_perfact_and_demo</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row8_col0\" class=\"data row8 col0\" >0.816400</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row8_col1\" class=\"data row8 col1\" >0.869900</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row8_col2\" class=\"data row8 col2\" >0.864800</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row8_col3\" class=\"data row8 col3\" >0.820600</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row8_col4\" class=\"data row8 col4\" >0.872600</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row8_col5\" class=\"data row8 col5\" >0.871000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row9\" class=\"row_heading level0 row9\" >LR_all</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row9_col0\" class=\"data row9 col0\" >0.816400</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row9_col1\" class=\"data row9 col1\" >0.869900</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row9_col2\" class=\"data row9 col2\" >0.864800</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row9_col3\" class=\"data row9 col3\" >0.820600</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row9_col4\" class=\"data row9 col4\" >0.872600</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row9_col5\" class=\"data row9 col5\" >0.871000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row10\" class=\"row_heading level0 row10\" >LR_perfact_only_tuned</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row10_col0\" class=\"data row10 col0\" >0.817700</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row10_col1\" class=\"data row10 col1\" >0.870700</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row10_col2\" class=\"data row10 col2\" >0.858800</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row10_col3\" class=\"data row10 col3\" >0.818900</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row10_col4\" class=\"data row10 col4\" >0.871400</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row10_col5\" class=\"data row10 col5\" >0.864000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row11\" class=\"row_heading level0 row11\" >LR_perfact_only</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row11_col0\" class=\"data row11 col0\" >0.817500</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row11_col1\" class=\"data row11 col1\" >0.870500</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row11_col2\" class=\"data row11 col2\" >0.858900</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row11_col3\" class=\"data row11 col3\" >0.818900</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row11_col4\" class=\"data row11 col4\" >0.871400</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row11_col5\" class=\"data row11 col5\" >0.864200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row12\" class=\"row_heading level0 row12\" >Baseline</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row12_col0\" class=\"data row12 col0\" >0.685700</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row12_col1\" class=\"data row12 col1\" >0.813600</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row12_col2\" class=\"data row12 col2\" >0.500000</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row12_col3\" class=\"data row12 col3\" >0.685600</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row12_col4\" class=\"data row12 col4\" >0.813500</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row12_col5\" class=\"data row12 col5\" >0.500000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row13\" class=\"row_heading level0 row13\" >LR_demo_only_tuned</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row13_col0\" class=\"data row13 col0\" >0.687600</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row13_col1\" class=\"data row13 col1\" >0.809700</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row13_col2\" class=\"data row13 col2\" >0.632500</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row13_col3\" class=\"data row13 col3\" >0.693400</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row13_col4\" class=\"data row13 col4\" >0.813200</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row13_col5\" class=\"data row13 col5\" >0.647200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row14\" class=\"row_heading level0 row14\" >LR_demo_only</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row14_col0\" class=\"data row14 col0\" >0.687700</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row14_col1\" class=\"data row14 col1\" >0.809700</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row14_col2\" class=\"data row14 col2\" >0.632500</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row14_col3\" class=\"data row14 col3\" >0.693400</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row14_col4\" class=\"data row14 col4\" >0.812900</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row14_col5\" class=\"data row14 col5\" >0.647200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row15\" class=\"row_heading level0 row15\" >XGB_demo_only_tuned</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row15_col0\" class=\"data row15 col0\" >0.692600</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row15_col1\" class=\"data row15 col1\" >0.810500</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row15_col2\" class=\"data row15 col2\" >0.651100</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row15_col3\" class=\"data row15 col3\" >0.694700</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row15_col4\" class=\"data row15 col4\" >0.811300</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row15_col5\" class=\"data row15 col5\" >0.645200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8level0_row16\" class=\"row_heading level0 row16\" >XGB_demo_only</th>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row16_col0\" class=\"data row16 col0\" >0.708100</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row16_col1\" class=\"data row16 col1\" >0.815300</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row16_col2\" class=\"data row16 col2\" >0.703100</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row16_col3\" class=\"data row16 col3\" >0.679800</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row16_col4\" class=\"data row16 col4\" >0.796300</td>\n",
       "                        <td id=\"T_f1e5a2a0_9826_11ed_921d_5fdcc57329f8row16_col5\" class=\"data row16 col5\" >0.619000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff2f480c1c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(f\"../results/{dataset_name}/{experiment_name}/results_subsets.pickle\"):\n",
    "\n",
    "    results_subsets = {}\n",
    "    results_subsets_feature_importances = {}\n",
    "\n",
    "    for fold in range(folds):\n",
    "        results_subsets[fold] = {}\n",
    "        results_subsets_feature_importances[fold] = {}\n",
    "        # Create baseline\n",
    "        y_train = data_dict[f\"y_train_{fold}\"]\n",
    "        y_val = data_dict[f\"y_val_{fold}\"]\n",
    "        y_test = data_dict[f\"y_test_{fold}\"]\n",
    "        y_train_val = np.concatenate([y_train,y_val])\n",
    "\n",
    "        max_ = np.argmax(np.unique(y_train_val,return_counts=True)[1])\n",
    "        y_train_val_pred_base = np.ones(y_train_val.shape[0])*max_\n",
    "        y_test_pred_base = np.ones(y_test.shape[0])*max_\n",
    "\n",
    "        results_subsets[fold][\"Baseline\"] = {}\n",
    "        eval_res_train = get_metrics(y_train_val, y_train_val_pred_base, target=target)\n",
    "        for metric in eval_res_train.keys():\n",
    "            results_subsets[fold][\"Baseline\"][metric + \" Train\"] = eval_res_train[metric]\n",
    "        eval_res_test = get_metrics(y_test, y_test_pred_base, target=target)\n",
    "        for metric in eval_res_test.keys():\n",
    "            results_subsets[fold][\"Baseline\"][metric + \" Test\"] = eval_res_test[metric]\n",
    "\n",
    "\n",
    "        for subset_key in subsets:\n",
    "            print(f\"Preparing results for fold {fold}, subset={subset_key}\")\n",
    "            # Retrieve data\n",
    "            z_cols = data_dict[\"z_cols\"]\n",
    "\n",
    "            X_train = data_dict[f\"X_train_{fold}\"]\n",
    "            y_train = data_dict[f\"y_train_{fold}\"]\n",
    "\n",
    "            X_val = data_dict[f\"X_val_{fold}\"]\n",
    "            y_val = data_dict[f\"y_val_{fold}\"]\n",
    "\n",
    "            X_test = data_dict[f\"X_test_{fold}\"]\n",
    "            y_test = data_dict[f\"y_test_{fold}\"]\n",
    "        \n",
    "            y_train_val = np.concatenate([y_train,y_val])\n",
    "\n",
    "            # Define data subset for LR\n",
    "            z_glmm_encoded_train = data_dict[f\"z_glmm_encoded_train_{fold}\"] \n",
    "            z_glmm_encoded_val = data_dict[f\"z_glmm_encoded_val_{fold}\"] \n",
    "            z_glmm_encoded_test = data_dict[f\"z_glmm_encoded_test_{fold}\"] \n",
    "            X_train_lr = pd.concat([X_train,z_glmm_encoded_train],axis=1)\n",
    "            X_val_lr = pd.concat([X_val,z_glmm_encoded_val],axis=1)\n",
    "            X_test_lr = pd.concat([X_test,z_glmm_encoded_test],axis=1)      \n",
    "            X_train_val_lr = pd.concat([X_train_lr,X_val_lr])\n",
    "\n",
    "            # Rescale GLMM\n",
    "            for col in z_glmm_encoded_train.columns:\n",
    "                z_mean = X_train_val_lr[col].mean()\n",
    "                z_std = X_train_val_lr[col].std()\n",
    "            \n",
    "                X_train_val_lr[col] = (X_train_val_lr[col]-z_mean)/z_std\n",
    "                X_test_lr[col] = (X_test_lr[col]-z_mean)/z_std\n",
    "                        \n",
    "            \n",
    "            # Define data subset for XGB\n",
    "            z_ordinal_encoded_train = data_dict[f\"z_ordinal_encoded_train_{fold}\"] \n",
    "            z_ordinal_encoded_val = data_dict[f\"z_ordinal_encoded_val_{fold}\"] \n",
    "            z_ordinal_encoded_test = data_dict[f\"z_ordinal_encoded_test_{fold}\"] \n",
    "            X_train_xgb = pd.concat([X_train,z_ordinal_encoded_train],axis=1)\n",
    "            X_val_xgb = pd.concat([X_val,z_ordinal_encoded_val],axis=1)\n",
    "            X_test_xgb = pd.concat([X_test,z_ordinal_encoded_test],axis=1)\n",
    "            X_train_val_xgb = pd.concat([X_train_xgb,X_val_xgb])\n",
    "\n",
    "\n",
    "            # Define data subset for evaluation\n",
    "            X_train_val_lr = X_train_val_lr[[i for i in X_train_val_lr.columns if any([j in i for j in subsets[subset_key]])]]\n",
    "            X_test_lr = X_test_lr[[i for i in X_test_lr.columns if any([j in i for j in subsets[subset_key]])]]\n",
    "            X_train_val_xgb = X_train_val_xgb[[i for i in X_train_val_xgb.columns if any([j in i for j in subsets[subset_key]])]]\n",
    "            X_test_xgb = X_test_xgb[[i for i in X_test_xgb.columns if any([j in i for j in subsets[subset_key]])]]\n",
    "\n",
    "\n",
    "            # Train base models\n",
    "            res, feats = evaluate_logreg(X_train_val_lr, y_train_val, X_test_lr, y_test, target=target,tune=False, seed=RS)\n",
    "            results_subsets[fold][\"LR_\"+subset_key] = res\n",
    "            results_subsets_feature_importances[fold][\"LR_\"+subset_key] = feats\n",
    "\n",
    "            res, feats = evaluate_xgb(X_train_val_xgb, y_train_val, X_test_xgb, y_test, target, tune=False, max_evals=max_evals, early_stopping_rounds=early_stopping_rounds, seed=RS)\n",
    "            results_subsets[fold][\"XGB_\"+subset_key] = res\n",
    "            results_subsets_feature_importances[fold][\"XGB_\"+subset_key] = feats\n",
    "\n",
    "            # Train tuned models\n",
    "            res, feats = evaluate_logreg(X_train_val_lr, y_train_val, X_test_lr, y_test, target=target, max_evals=max_evals, tune=True, seed=RS)\n",
    "            results_subsets[fold][\"LR_\"+subset_key+\"_tuned\"] = res\n",
    "            results_subsets_feature_importances[fold][\"LR_\"+subset_key+\"_tuned\"] = feats\n",
    "\n",
    "            res, feats = evaluate_xgb(X_train_val_xgb, y_train_val, X_test_xgb, y_test, target, tune=True, max_evals=max_evals, early_stopping_rounds=early_stopping_rounds, seed=RS)\n",
    "            results_subsets[fold][\"XGB_\"+subset_key+\"_tuned\"] = res\n",
    "            results_subsets_feature_importances[fold][\"XGB_\"+subset_key+\"_tuned\"] = feats\n",
    "    \n",
    "    if not os.path.exists(f\"../results/{dataset_name}/{experiment_name}\"):\n",
    "        os.makedirs(f\"../results/{dataset_name}/{experiment_name}\")\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_subsets.pickle\", 'wb') as handle:\n",
    "        pickle.dump(results_subsets, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_subsets_feature_importances.pickle\", 'wb') as handle:\n",
    "        pickle.dump(results_subsets_feature_importances, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_subsets.pickle\", 'rb') as handle:\n",
    "        results_subsets = pickle.load(handle)\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_subsets_feature_importances.pickle\", 'rb') as handle:\n",
    "        results_subsets_feature_importances = pickle.load(handle)\n",
    "        \n",
    "        \n",
    "results_subsets_df = pd.DataFrame(results_subsets[0]).transpose().sort_values(\"F1 Test\",ascending=False).round(4)\n",
    "results_subsets_df[[\"Accuracy Train\", \"F1 Train\", \"AUROC Train\", \"Accuracy Test\", \"F1 Test\", \"AUROC Test\"]].style.highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_f1ead504_9826_11ed_921d_5fdcc57329f8row0_col2 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_f1ead504_9826_11ed_921d_5fdcc57329f8row0_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_f1ead504_9826_11ed_921d_5fdcc57329f8row0_col4 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_f1ead504_9826_11ed_921d_5fdcc57329f8\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Baseline</th>        <th class=\"col_heading level0 col1\" >LR_demo_only_tuned</th>        <th class=\"col_heading level0 col2\" >LR_perfact_only_tuned</th>        <th class=\"col_heading level0 col3\" >LR_perfact_and_demo_tuned</th>        <th class=\"col_heading level0 col4\" >LR_all_tuned</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f1ead504_9826_11ed_921d_5fdcc57329f8level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_f1ead504_9826_11ed_921d_5fdcc57329f8row0_col0\" class=\"data row0 col0\" >0.814 (0.004)</td>\n",
       "                        <td id=\"T_f1ead504_9826_11ed_921d_5fdcc57329f8row0_col1\" class=\"data row0 col1\" >0.81 (0.004)</td>\n",
       "                        <td id=\"T_f1ead504_9826_11ed_921d_5fdcc57329f8row0_col2\" class=\"data row0 col2\" >0.87 (0.008)</td>\n",
       "                        <td id=\"T_f1ead504_9826_11ed_921d_5fdcc57329f8row0_col3\" class=\"data row0 col3\" >0.869 (0.008)</td>\n",
       "                        <td id=\"T_f1ead504_9826_11ed_921d_5fdcc57329f8row0_col4\" class=\"data row0 col4\" >0.869 (0.008)</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff2284bc8e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For LR\n",
    "models = [\"Baseline\"]+[i for i in results_subsets[0].keys() if (\"tuned\" in i and \"LR\" in i)]\n",
    "metric = \"F1 Test\"\n",
    "\n",
    "#####\n",
    "dataset_res_dict = {}\n",
    "best_models = {}\n",
    "t_test_results = {}\n",
    "\n",
    "use_df = pd.DataFrame([pd.DataFrame(results_subsets[fold_num]).loc[metric,models] for fold_num in results_subsets.keys()],index=results_subsets.keys())\n",
    "\n",
    "df_mean = pd.DataFrame((use_df).mean(axis=0).round(3).astype(str) + \" (\" + use_df.std(axis=0).round(3).astype(str) + \")\").transpose()\n",
    "model_dict = {i: df_mean[i].values[0] for i in df_mean.columns}\n",
    "\n",
    "best_model = use_df.columns[use_df.mean(axis=0).argmax()]\n",
    "\n",
    "t_test_res = np.array([stats.ttest_rel(use_df[best_model].values, use_df[model].values)[1] for model in models]).round(3)\n",
    "t_test_res[np.isnan(t_test_res)] = 1.\n",
    "    \n",
    "res_df_lr = pd.DataFrame([model_dict])\n",
    "\n",
    "def negative_bold(val):\n",
    "    i = np.where(val.name==np.array(models))[0][0]\n",
    "    return [\"font-weight: bold\"  if t_test_res[i]>=0.05 else \"\" for dataset_name in val.keys()]\n",
    "    # Case without transpose:\n",
    "#     return [\"font-weight: bold\"  if t_test_results[val.name][i]>=0.05 else \"\" for i in range(len(val))]\n",
    "\n",
    "res_df_lr.style.apply(negative_bold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_f1f759aa_9826_11ed_921d_5fdcc57329f8row0_col2 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_f1f759aa_9826_11ed_921d_5fdcc57329f8row0_col3 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_f1f759aa_9826_11ed_921d_5fdcc57329f8row0_col4 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_f1f759aa_9826_11ed_921d_5fdcc57329f8\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Baseline</th>        <th class=\"col_heading level0 col1\" >XGB_demo_only_tuned</th>        <th class=\"col_heading level0 col2\" >XGB_perfact_only_tuned</th>        <th class=\"col_heading level0 col3\" >XGB_perfact_and_demo_tuned</th>        <th class=\"col_heading level0 col4\" >XGB_all_tuned</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f1f759aa_9826_11ed_921d_5fdcc57329f8level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_f1f759aa_9826_11ed_921d_5fdcc57329f8row0_col0\" class=\"data row0 col0\" >0.814 (0.004)</td>\n",
       "                        <td id=\"T_f1f759aa_9826_11ed_921d_5fdcc57329f8row0_col1\" class=\"data row0 col1\" >0.809 (0.004)</td>\n",
       "                        <td id=\"T_f1f759aa_9826_11ed_921d_5fdcc57329f8row0_col2\" class=\"data row0 col2\" >0.906 (0.003)</td>\n",
       "                        <td id=\"T_f1f759aa_9826_11ed_921d_5fdcc57329f8row0_col3\" class=\"data row0 col3\" >0.907 (0.004)</td>\n",
       "                        <td id=\"T_f1f759aa_9826_11ed_921d_5fdcc57329f8row0_col4\" class=\"data row0 col4\" >0.907 (0.003)</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff228512b20>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For XGB\n",
    "models = [\"Baseline\"]+[i for i in results_subsets[0].keys() if (\"tuned\" in i and \"XGB\" in i)]\n",
    "metric = \"F1 Test\"\n",
    "\n",
    "#####\n",
    "dataset_res_dict = {}\n",
    "best_models = {}\n",
    "t_test_results = {}\n",
    "\n",
    "use_df = pd.DataFrame([pd.DataFrame(results_subsets[fold_num]).loc[metric,models] for fold_num in results_subsets.keys()],index=results_subsets.keys())\n",
    "\n",
    "df_mean = pd.DataFrame((use_df).mean(axis=0).round(3).astype(str) + \" (\" + use_df.std(axis=0).round(3).astype(str) + \")\").transpose()\n",
    "model_dict = {i: df_mean[i].values[0] for i in df_mean.columns}\n",
    "\n",
    "best_model = use_df.columns[use_df.mean(axis=0).argmax()]\n",
    "\n",
    "t_test_res = np.array([stats.ttest_rel(use_df[best_model].values, use_df[model].values)[1] for model in models]).round(3)\n",
    "t_test_res[np.isnan(t_test_res)] = 1.\n",
    "    \n",
    "res_df_xgb = pd.DataFrame([model_dict])\n",
    "\n",
    "def negative_bold(val):\n",
    "    i = np.where(val.name==np.array(models))[0][0]\n",
    "    return [\"font-weight: bold\"  if t_test_res[i]>=0.05 else \"\" for dataset_name in val.keys()]\n",
    "    # Case without transpose:\n",
    "#     return [\"font-weight: bold\"  if t_test_results[val.name][i]>=0.05 else \"\" for i in range(len(val))]\n",
    "\n",
    "res_df_xgb.style.apply(negative_bold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>demo_only</th>\n",
       "      <th>perfact_only</th>\n",
       "      <th>perfact_and_demo</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.814 (0.004)</td>\n",
       "      <td>0.81 (0.004)</td>\n",
       "      <td>0.87 (0.008)</td>\n",
       "      <td>0.869 (0.008)</td>\n",
       "      <td>0.869 (0.008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.814 (0.004)</td>\n",
       "      <td>0.809 (0.004)</td>\n",
       "      <td>0.906 (0.003)</td>\n",
       "      <td>0.907 (0.004)</td>\n",
       "      <td>0.907 (0.003)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline      demo_only   perfact_only perfact_and_demo  \\\n",
       "LR   0.814 (0.004)   0.81 (0.004)   0.87 (0.008)    0.869 (0.008)   \n",
       "XGB  0.814 (0.004)  0.809 (0.004)  0.906 (0.003)    0.907 (0.004)   \n",
       "\n",
       "               all  \n",
       "LR   0.869 (0.008)  \n",
       "XGB  0.907 (0.003)  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_lr.columns = [i[3:-6] if i != \"Baseline\" else \"Baseline\" for i in res_df_lr.columns]    \n",
    "res_df_xgb.columns = [i[4:-6] if i != \"Baseline\" else \"Baseline\" for i in res_df_xgb.columns]    \n",
    "\n",
    "latex_df_subsets = pd.concat([res_df_lr,res_df_xgb],axis=0)\n",
    "latex_df_subsets.index = [\"LR\", \"XGB\"]\n",
    "latex_df_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "{} &             LR &            XGB \\\\\n",
      "\\midrule\n",
      "Baseline         &  0.814 (0.004) &  0.814 (0.004) \\\\\n",
      "demo\\_only        &   0.81 (0.004) &  0.809 (0.004) \\\\\n",
      "perfact\\_only     &   0.87 (0.008) &  0.906 (0.003) \\\\\n",
      "perfact\\_and\\_demo &  0.869 (0.008) &  0.907 (0.004) \\\\\n",
      "all              &  0.869 (0.008) &  0.907 (0.003) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex_df_subsets.round(2).transpose().to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_10_importances = {}\n",
    "\n",
    "# for model in list(results_subsets_feature_importances[fold].keys()):\n",
    "#     imp_df = pd.concat([results_subsets_feature_importances[fold][model] for fold in range(folds)],axis=1)\n",
    "\n",
    "#     if \"LR\" in model:\n",
    "#         direction = imp_df.apply(lambda x: np.sign(x))\n",
    "#         imp_df = imp_df.abs()\n",
    "\n",
    "#     imp_df = imp_df/imp_df.sum(axis=0)\n",
    "\n",
    "#     mean_imp_df = imp_df.mean(axis=1)\n",
    "#     std_imp_df = imp_df.std(axis=1)\n",
    "\n",
    "#     mean_imp_df = mean_imp_df.sort_values(ascending=False)\n",
    "#     std_imp_df = std_imp_df.loc[mean_imp_df.index]\n",
    "#     final_imps = mean_imp_df[:10]\n",
    "#     final_imps[\"Rest\"] = sum(mean_imp_df[10:])\n",
    "#     top_5_importances[model] = np.array([final_imps.index.values, final_imps.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_importances = {}\n",
    "demo_importances_stds = {}\n",
    "\n",
    "for model in list(results_subsets_feature_importances[0].keys()):\n",
    "    if \"demo\" in model or \"all\" in model:\n",
    "        imp_df_all = pd.concat([results_subsets_feature_importances[fold][model] for fold in range(folds)],axis=1)\n",
    "        \n",
    "        if \"LR\" in model:\n",
    "            direction = imp_df_all.apply(lambda x: np.sign(x))\n",
    "            imp_df_all = imp_df_all.abs()\n",
    "        if imp_df_all.sum().sum()!=0:\n",
    "            imp_df = imp_df_all/imp_df_all.sum(axis=0)\n",
    "        imp_df = imp_df.fillna(1/imp_df.shape[0])\n",
    "#         imp_df = imp_df.loc[demographic_cols]\n",
    "\n",
    "#         mean_imp_df = imp_df.mean(axis=1)\n",
    "#         std_imp_df = imp_df.std(axis=1)\n",
    "\n",
    "#         mean_imp_df = mean_imp_df.sort_values(ascending=False)\n",
    "#         std_imp_df = std_imp_df.loc[mean_imp_df.index]\n",
    "#         final_imps = mean_imp_df#[:10]\n",
    "#         final_imps[\"Rest\"] = sum(mean_imp_df[10:])\n",
    "#         final_imps[\"Total\"] = sum(mean_imp_df)\n",
    "        demo_importances[model] = np.round(np.mean(imp_df.loc[[i for i in imp_df.index if any([j in i for j in demographic_cols])]].sum(axis=0)),2)#final_imps.values\n",
    "        demo_importances_stds[model] = np.round(np.std(imp_df.loc[[i for i in imp_df.index if any([j in i for j in demographic_cols])]].sum(axis=0)),2)#final_imps.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_only</th>\n",
       "      <th>perfact_and_demo</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>1.0 (0.0)</td>\n",
       "      <td>0.13 (0.0)</td>\n",
       "      <td>0.13 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>1.0 (0.0)</td>\n",
       "      <td>0.08 (0.0)</td>\n",
       "      <td>0.08 (0.01)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     demo_only perfact_and_demo          all\n",
       "LR   1.0 (0.0)       0.13 (0.0)   0.13 (0.0)\n",
       "XGB  1.0 (0.0)       0.08 (0.0)  0.08 (0.01)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_demo_imp = pd.Series({i: demo_importances[i] for i in demo_importances if \"LR\" in i and \"tuned\" in i})\n",
    "xgb_demo_imp = pd.Series({i: demo_importances[i] for i in demo_importances if \"XGB\" in i and \"tuned\" in i})\n",
    "lr_demo_imp.index = [i[3:-6] for i in lr_demo_imp.index]    \n",
    "xgb_demo_imp.index = [i[4:-6] for i in xgb_demo_imp.index]    \n",
    "\n",
    "lr_demo_imp_stds = pd.Series({i: demo_importances_stds[i] for i in demo_importances_stds if \"LR\" in i and \"tuned\" in i})\n",
    "xgb_demo_imp_stds = pd.Series({i: demo_importances_stds[i] for i in demo_importances_stds if \"XGB\" in i and \"tuned\" in i})\n",
    "lr_demo_imp_stds.index = [i[3:-6] for i in lr_demo_imp_stds.index]    \n",
    "xgb_demo_imp_stds.index = [i[4:-6] for i in xgb_demo_imp_stds.index]    \n",
    "\n",
    "\n",
    "latex_df_imp = pd.DataFrame([lr_demo_imp.astype(str) + \" (\" + lr_demo_imp_stds.astype(str) + \")\",\n",
    "                             xgb_demo_imp.astype(str) + \" (\" + xgb_demo_imp_stds.astype(str) + \")\"])\n",
    "latex_df_imp.index = [\"LR\", \"XGB\"]\n",
    "latex_df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "{} &       Baseline &      demo\\_only &   perfact\\_only & perfact\\_and\\_demo &            all \\\\\n",
      "\\midrule\n",
      "LR  &  0.814 (0.004) &   0.81 (0.004) &   0.87 (0.008) &    0.869 (0.008) &  0.869 (0.008) \\\\\n",
      "XGB &  0.814 (0.004) &  0.809 (0.004) &  0.906 (0.003) &    0.907 (0.004) &  0.907 (0.003) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex_df_subsets.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean impact of using demo features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.4322915300872288                             \n",
      "SCORE: 0.43228128842956404                                                      \n",
      "SCORE: 0.43228948172390097                                                       \n",
      "SCORE: 0.4322899097654872                                                        \n",
      "SCORE: 0.43228742570731615                                                       \n",
      "SCORE: 0.4323942102163515                                                        \n",
      "SCORE: 0.43228998861173196                                                       \n",
      "SCORE: 0.43229175160722305                                                       \n",
      "SCORE: 0.4323931314096486                                                        \n",
      "SCORE: 0.43229218839084016                                                       \n",
      "SCORE: 0.4322903296119067                                                         \n",
      "SCORE: 0.4322850873154495                                                         \n",
      "SCORE: 0.4322883434266374                                                         \n",
      "SCORE: 0.4322890578359632                                                         \n",
      "SCORE: 0.432289201743532                                                          \n",
      "SCORE: 0.43228800479489937                                                        \n",
      "SCORE: 0.4322879366214855                                                         \n",
      "SCORE: 0.4322922664357682                                                         \n",
      "SCORE: 0.4324358874938453                                                         \n",
      "SCORE: 0.4322868321546259                                                         \n",
      "SCORE: 0.4322821588782498                                                         \n",
      "SCORE: 0.4322828125839636                                                         \n",
      "SCORE: 0.4324512318823143                                                         \n",
      "SCORE: 0.4322838982531779                                                         \n",
      "SCORE: 0.4324252845939446                                                         \n",
      "SCORE: 0.43228395233105293                                                        \n",
      "SCORE: 0.4324323000936488                                                         \n",
      "SCORE: 0.43228509346321636                                                        \n",
      "SCORE: 0.43229095330689093                                                        \n",
      "SCORE: 0.43729603305619713                                                        \n",
      "SCORE: 0.43228169863901833                                                        \n",
      "SCORE: 0.4322900174238538                                                         \n",
      "SCORE: 0.43228497895835705                                                        \n",
      "SCORE: 0.4324089066626572                                                         \n",
      "SCORE: 0.43228305585652754                                                        \n",
      "SCORE: 0.43228785728857505                                                        \n",
      "SCORE: 0.43228575693000104                                                        \n",
      "SCORE: 0.4325222844959725                                                         \n",
      "SCORE: 0.43229051806832813                                                        \n",
      "SCORE: 0.43243410779488284                                                        \n",
      "SCORE: 0.43239859985446116                                                        \n",
      "SCORE: 0.4322806902392782                                                         \n",
      "SCORE: 0.4322833985187917                                                         \n",
      "SCORE: 0.4322841572953008                                                        \n",
      "SCORE: 0.4322876853876657                                                        \n",
      "SCORE: 0.43228790138989004                                                       \n",
      "SCORE: 0.4322905398465057                                                        \n",
      "SCORE: 0.4324491259434202                                                        \n",
      "SCORE: 0.4322859361678216                                                        \n",
      "SCORE: 0.4324361490176198                                                        \n",
      "100%|| 50/50 [00:35<00:00,  1.41trial/s, best loss: 0.4322806902392782]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'C': 0.27358381557729206}\n",
      "% different predictions w\\o Demo: 0.33845811051693403\n",
      "Mean absolute % difference w\\o Demo: 0.30632151948584674\n",
      "RMSE Difference w\\o Demo: 0.5817715277640648\n",
      "SCORE: 0.43771022227502365                            \n",
      "SCORE: 0.43771406001091523                                                       \n",
      "SCORE: 0.4375701372393429                                                        \n",
      "SCORE: 0.43771393048004315                                                       \n",
      "SCORE: 0.43771142950241415                                                      \n",
      "SCORE: 0.4376467722484976                                                       \n",
      "SCORE: 0.43772542556727795                                                      \n",
      "SCORE: 0.43759603104146116                                                      \n",
      "SCORE: 0.4386711704744646                                                       \n",
      "SCORE: 0.4376296981183672                                                       \n",
      "SCORE: 0.43772131149501003                                                       \n",
      "SCORE: 0.4377196579445825                                                        \n",
      "SCORE: 0.4375334348110191                                                        \n",
      "SCORE: 0.4376859769658156                                                        \n",
      "SCORE: 0.43746527995067375                                                       \n",
      "SCORE: 0.4377140942726223                                                         \n",
      "SCORE: 0.4376353749288152                                                         \n",
      "SCORE: 0.4375741378305615                                                         \n",
      "SCORE: 0.43753826158889797                                                        \n",
      "SCORE: 0.43762377958455234                                                        \n",
      "SCORE: 0.4374199704591528                                                         \n",
      "SCORE: 0.4505236011617795                                                         \n",
      "SCORE: 0.4374474526272718                                                        \n",
      "SCORE: 0.43743162558281146                                                       \n",
      "SCORE: 0.4374153217666882                                                        \n",
      "SCORE: 0.437342918121324                                                         \n",
      "SCORE: 0.43740198303981465                                                       \n",
      "SCORE: 0.4375153828600736                                                       \n",
      "SCORE: 0.43757004891536333                                                      \n",
      "SCORE: 0.4630818207174762                                                       \n",
      "SCORE: 0.437335071326476                                                        \n",
      "SCORE: 0.43760259339012286                                                      \n",
      "SCORE: 0.4376992319471095                                                       \n",
      "SCORE: 0.43755684391354316                                                      \n",
      "SCORE: 0.4376468717300247                                                       \n",
      "SCORE: 0.4373587155686752                                                       \n",
      "SCORE: 0.4375070501929403                                                       \n",
      "SCORE: 0.43759599766853574                                                      \n",
      "SCORE: 0.43747398127376336                                                      \n",
      "SCORE: 0.4373763824060646                                                       \n",
      "SCORE: 0.4376174414750486                                                       \n",
      "SCORE: 0.43764181835878785                                                      \n",
      "SCORE: 0.4377271663478551                                                       \n",
      "SCORE: 0.4375805307556194                                                       \n",
      "SCORE: 0.437545594249413                                                        \n",
      "SCORE: 0.437705367513443                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.43750222069208855                                                      \n",
      "SCORE: 0.43768394606962086                                                      \n",
      "SCORE: 0.43755657955796484                                                      \n",
      "SCORE: 0.4373439297253034                                                       \n",
      "100%|| 50/50 [00:28<00:00,  1.78trial/s, best loss: 0.437335071326476]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'C': 0.03399621392273323}\n",
      "% different predictions w\\o Demo: 0.3333333333333333\n",
      "Mean absolute % difference w\\o Demo: 0.29732279518306154\n",
      "RMSE Difference w\\o Demo: 0.5773502691896257\n",
      "SCORE: 0.4294369489113656                             \n",
      "SCORE: 0.42934892700162725                                                      \n",
      "SCORE: 0.42944578611279083                                                       \n",
      "SCORE: 0.4293473960244123                                                        \n",
      "SCORE: 0.42947504162747674                                                       \n",
      "SCORE: 0.4294723446680866                                                       \n",
      "SCORE: 0.42945626527992475                                                      \n",
      "SCORE: 0.4293492761881085                                                       \n",
      "SCORE: 0.43099201817578053                                                      \n",
      "SCORE: 0.4293494550510314                                                       \n",
      "SCORE: 0.4294406921070163                                                        \n",
      "SCORE: 0.42935084727693107                                                       \n",
      "SCORE: 0.4294074306155145                                                        \n",
      "SCORE: 0.4293472708807797                                                        \n",
      "SCORE: 0.4294438065225246                                                        \n",
      "SCORE: 0.42947716294753463                                                       \n",
      "SCORE: 0.4294424698749461                                                        \n",
      "SCORE: 0.429465913015295                                                         \n",
      "SCORE: 0.4294694435198937                                                        \n",
      "SCORE: 0.4294779078996299                                                        \n",
      "SCORE: 0.4294602426356729                                                        \n",
      "SCORE: 0.42945829891270326                                                       \n",
      "SCORE: 0.4293473768257785                                                        \n",
      "SCORE: 0.4343804745864187                                                        \n",
      "SCORE: 0.42946496350830765                                                       \n",
      "SCORE: 0.4293478863212334                                                        \n",
      "SCORE: 0.4294534560335155                                                        \n",
      "SCORE: 0.4294639035351839                                                        \n",
      "SCORE: 0.42946971653094296                                                       \n",
      "SCORE: 0.4294163091320531                                                        \n",
      "SCORE: 0.4294793182663678                                                        \n",
      "SCORE: 0.429349581068048                                                         \n",
      "SCORE: 0.4293486963917478                                                        \n",
      "SCORE: 0.42945330713871793                                                       \n",
      "SCORE: 0.42947424317087124                                                       \n",
      "SCORE: 0.4294498055825824                                                        \n",
      "SCORE: 0.4294622633867361                                                        \n",
      "SCORE: 0.4293474095770716                                                        \n",
      "SCORE: 0.4294687984872139                                                        \n",
      "SCORE: 0.42938708772529777                                                       \n",
      "SCORE: 0.4294345626944104                                                        \n",
      "SCORE: 0.4294715697224919                                                        \n",
      "SCORE: 0.4293477067933166                                                        \n",
      "SCORE: 0.42934847351728783                                                       \n",
      "SCORE: 0.42944867831142536                                                       \n",
      "SCORE: 0.43093155643795217                                                       \n",
      "SCORE: 0.4294742243545773                                                        \n",
      "SCORE: 0.42946775712544616                                                       \n",
      "SCORE: 0.4294393337584082                                                        \n",
      "SCORE: 0.4293935555958801                                                        \n",
      "100%|| 50/50 [00:25<00:00,  1.94trial/s, best loss: 0.4293472708807797]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'C': 0.12208238080120547}\n",
      "% different predictions w\\o Demo: 0.3278359705816804\n",
      "Mean absolute % difference w\\o Demo: 0.3061228520007071\n",
      "RMSE Difference w\\o Demo: 0.5725696207289385\n",
      "SCORE: 0.43281376568800517                            \n",
      "SCORE: 0.43280227234114943                                                       \n",
      "SCORE: 0.4328919880253996                                                        \n",
      "SCORE: 0.4327509770578358                                                        \n",
      "SCORE: 0.4328401631452833                                                        \n",
      "SCORE: 0.43262403786308923                                                      \n",
      "SCORE: 0.43292608441346747                                                       \n",
      "SCORE: 0.4328792172205854                                                        \n",
      "SCORE: 0.43290805941429567                                                       \n",
      "SCORE: 0.43285076726855276                                                       \n",
      "SCORE: 0.43276291944342216                                                        \n",
      "SCORE: 0.4328406796978495                                                         \n",
      "SCORE: 0.4327759553138022                                                         \n",
      "SCORE: 0.432812881793749                                                          \n",
      "SCORE: 0.4326574121521527                                                         \n",
      "SCORE: 0.4326652987475266                                                         \n",
      "SCORE: 0.4328906694312251                                                         \n",
      "SCORE: 0.43290456967805946                                                        \n",
      "SCORE: 0.43288964215662185                                                        \n",
      "SCORE: 0.4326802312420863                                                         \n",
      "SCORE: 0.43332143310964427                                                        \n",
      "SCORE: 0.43263854772213206                                                        \n",
      "SCORE: 0.43294585215245485                                                        \n",
      "SCORE: 0.43282360764635897                                                        \n",
      "SCORE: 0.43560886408634303                                                        \n",
      "SCORE: 0.4327306411947414                                                         \n",
      "SCORE: 0.43283057002648817                                                        \n",
      "SCORE: 0.43270422543041676                                                        \n",
      "SCORE: 0.4326248570366504                                                         \n",
      "SCORE: 0.4328257448358809                                                         \n",
      "SCORE: 0.4327972742461993                                                         \n",
      "SCORE: 0.4326410843462793                                                         \n",
      "SCORE: 0.43280703037048796                                                        \n",
      "SCORE: 0.43270963914053284                                                        \n",
      "SCORE: 0.43291797293780326                                                        \n",
      "SCORE: 0.4328406449091329                                                         \n",
      "SCORE: 0.43287613691421745                                                        \n",
      "SCORE: 0.43279253039401466                                                        \n",
      "SCORE: 0.4326274872850619                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.43272473980120785                                                        \n",
      "SCORE: 0.4327511683553663                                                         \n",
      "SCORE: 0.43284082326850815                                                        \n",
      "SCORE: 0.432689372370762                                                          \n",
      "SCORE: 0.43290162152578854                                                        \n",
      "SCORE: 0.4328778079751638                                                         \n",
      "SCORE: 0.4328471053830258                                                         \n",
      "SCORE: 0.4327692510914588                                                         \n",
      "SCORE: 0.4328223426536826                                                         \n",
      "SCORE: 0.43286027026121143                                                        \n",
      "SCORE: 0.43262490047454555                                                        \n",
      "100%|| 50/50 [00:31<00:00,  1.60trial/s, best loss: 0.43262403786308923]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'C': 0.055293192355797244}\n",
      "% different predictions w\\o Demo: 0.32427011366168934\n",
      "Mean absolute % difference w\\o Demo: 0.30082909204200947\n",
      "RMSE Difference w\\o Demo: 0.5694472000648431\n",
      "SCORE: 0.4283518286812072                             \n",
      "SCORE: 0.4287191717118334                                                       \n",
      "SCORE: 0.4287747029967616                                                       \n",
      "SCORE: 0.42878575818781994                                                      \n",
      "SCORE: 0.428708448673245                                                        \n",
      "SCORE: 0.42869337052852474                                                      \n",
      "SCORE: 0.42852143055511915                                                      \n",
      "SCORE: 0.42872118186900476                                                      \n",
      "SCORE: 0.42869349750078156                                                      \n",
      "SCORE: 0.4283855158095971                                                       \n",
      "SCORE: 0.4286911324332602                                                        \n",
      "SCORE: 0.42867562538017623                                                       \n",
      "SCORE: 0.42872346838262504                                                       \n",
      "SCORE: 0.42864955849221653                                                       \n",
      "SCORE: 0.42871756866426125                                                       \n",
      "SCORE: 0.4286910418315489                                                        \n",
      "SCORE: 0.42870996976220466                                                       \n",
      "SCORE: 0.4285970804246998                                                        \n",
      "SCORE: 0.4287847047463044                                                        \n",
      "SCORE: 0.4284578528577634                                                        \n",
      "SCORE: 0.42861451910480425                                                       \n",
      "SCORE: 0.4283607267002214                                                        \n",
      "SCORE: 0.4304578141709456                                                        \n",
      "SCORE: 0.4285248445792792                                                        \n",
      "SCORE: 0.42837168321283486                                                       \n",
      "SCORE: 0.42863232646832994                                                       \n",
      "SCORE: 0.42853225492509706                                                       \n",
      "SCORE: 0.42859673113382335                                                       \n",
      "SCORE: 0.4284781658784363                                                        \n",
      "SCORE: 0.4286593279958362                                                        \n",
      "SCORE: 0.4285806992582657                                                        \n",
      "SCORE: 0.4284327498379191                                                        \n",
      "SCORE: 0.42864204708074405                                                       \n",
      "SCORE: 0.42836580451838524                                                       \n",
      "SCORE: 0.43955789232055203                                                       \n",
      "SCORE: 0.42849808420669416                                                       \n",
      "SCORE: 0.42857428224536587                                                       \n",
      "SCORE: 0.4287794933444921                                                        \n",
      "SCORE: 0.42861836008780285                                                       \n",
      "SCORE: 0.4285606994739499                                                        \n",
      "SCORE: 0.42867575292723253                                                       \n",
      "SCORE: 0.4284981436798178                                                        \n",
      "SCORE: 0.45010769616212054                                                       \n",
      "SCORE: 0.4283820005506106                                                        \n",
      "SCORE: 0.4286651521084945                                                        \n",
      "SCORE: 0.4284576431194349                                                        \n",
      "SCORE: 0.42860302724495847                                                       \n",
      "SCORE: 0.42877044834213185                                                       \n",
      "SCORE: 0.42869982228144476                                                       \n",
      "SCORE: 0.42864897685419034                                                       \n",
      "100%|| 50/50 [00:27<00:00,  1.82trial/s, best loss: 0.4283518286812072]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'C': 0.043517412330293374}\n",
      "% different predictions w\\o Demo: 0.33808780922665477\n",
      "Mean absolute % difference w\\o Demo: 0.30303976980162367\n",
      "RMSE Difference w\\o Demo: 0.5814531874765627\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RS)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "mean_abs_differences = []\n",
    "for fold in range(folds):\n",
    "    X_train = data_dict[f\"X_train_{fold}\"]\n",
    "    y_train = data_dict[f\"y_train_{fold}\"]\n",
    "\n",
    "    X_val = data_dict[f\"X_val_{fold}\"]\n",
    "    y_val = data_dict[f\"y_val_{fold}\"]\n",
    "\n",
    "    X_test = data_dict[f\"X_test_{fold}\"]\n",
    "    y_test = data_dict[f\"y_test_{fold}\"]\n",
    "\n",
    "    y_train_val = np.concatenate([y_train,y_val])\n",
    "\n",
    "    # Define data subset for LR\n",
    "    z_glmm_encoded_train = data_dict[f\"z_glmm_encoded_train_{fold}\"] \n",
    "    z_glmm_encoded_val = data_dict[f\"z_glmm_encoded_val_{fold}\"] \n",
    "    z_glmm_encoded_test = data_dict[f\"z_glmm_encoded_test_{fold}\"] \n",
    "\n",
    "    X_train_lr = pd.concat([X_train,z_glmm_encoded_train],axis=1)\n",
    "    X_val_lr = pd.concat([X_val,z_glmm_encoded_val],axis=1)\n",
    "    X_test_lr = pd.concat([X_test,z_glmm_encoded_test],axis=1)      \n",
    "    X_train_val_lr = pd.concat([X_train_lr,X_val_lr])\n",
    "\n",
    "    # Rescale GLMM\n",
    "    for col in z_glmm_encoded_train.columns:\n",
    "        z_mean = X_train_val_lr[col].mean()\n",
    "        z_std = X_train_val_lr[col].std()\n",
    "\n",
    "        X_train_val_lr[col] = (X_train_val_lr[col]-z_mean)/z_std\n",
    "        X_test_lr[col] = (X_test_lr[col]-z_mean)/z_std\n",
    "\n",
    "\n",
    "    # Define data subset for XGB\n",
    "    z_ordinal_encoded_train = data_dict[f\"z_ordinal_encoded_train_{fold}\"] \n",
    "    z_ordinal_encoded_val = data_dict[f\"z_ordinal_encoded_val_{fold}\"] \n",
    "    z_ordinal_encoded_test = data_dict[f\"z_ordinal_encoded_test_{fold}\"] \n",
    "    X_train_xgb = pd.concat([X_train,z_ordinal_encoded_train],axis=1)\n",
    "    X_val_xgb = pd.concat([X_val,z_ordinal_encoded_val],axis=1)\n",
    "    X_test_xgb = pd.concat([X_test,z_ordinal_encoded_test],axis=1)\n",
    "    X_train_val_xgb = pd.concat([X_train_xgb,X_val_xgb])\n",
    "\n",
    "    final_hyperparameters = tune_logreg_binary(X_train_val_lr, y_train_val,target, max_evals=max_evals, seed=RS)\n",
    "    lr = LogisticRegression(penalty=\"l2\",\n",
    "                                       solver=\"lbfgs\",\n",
    "                                       C=final_hyperparameters[\"C\"],\n",
    "                                       max_iter=10000,\n",
    "                                       random_state=RS\n",
    "                                       )\n",
    "#     lr = Lasso(alpha=0.001)\n",
    "    lr.fit(X_train_val_lr,y_train_val)\n",
    "    y_pred_logits = sigmoid(lr.predict_proba(X_test_lr)[:,1])\n",
    "    y_pred = lr.predict(X_test_lr)\n",
    "\n",
    "    is_not_demo = [i not in demographic_cols for i in X_train_val_lr.columns]\n",
    "    y_pred_logits_notdemo = sigmoid(np.dot(X_test_lr.loc[:,is_not_demo],lr.coef_[0][is_not_demo]))\n",
    "    y_pred_notdemo = np.round(y_pred_logits_notdemo)\n",
    "\n",
    "    print(f\"% different predictions w\\o Demo: {np.mean(y_pred!=y_pred_notdemo)}\")\n",
    "    print(f\"Mean absolute % difference w\\o Demo: {np.mean(np.abs(y_pred_logits-y_pred_logits_notdemo))}\")\n",
    "    print(f\"RMSE Difference w\\o Demo: {np.sqrt(np.mean(np.power(y_pred-y_pred_notdemo,2)))}\")\n",
    "    mean_abs_differences.append(np.mean(y_pred!=y_pred_notdemo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33, 0.01)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mean_abs_differences).round(2),np.std(mean_abs_differences).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8568711364717071, 0.6823873121869782)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(y_test,y_pred),f1(y_test,y_pred_notdemo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc07112e7ae1e8e28a0232207620ff002934c05692de8df42430404c766a0a8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
