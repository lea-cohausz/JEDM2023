{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils.evaluation import *\n",
    "from utils.utils import *\n",
    "\n",
    "from data import dataset_preprocessing\n",
    "\n",
    "from utils.evaluation import get_metrics\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"academic_performance\"\n",
    "mode=\"cv\"\n",
    "RS=68\n",
    "hct=10\n",
    "test_ratio=0.2\n",
    "val_ratio=0.1\n",
    "folds=5\n",
    "target = \"continuous\"\n",
    "experiment_name = \"EDM_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"../data/raw/{dataset_name}/{dataset_name}.xlsx\")\n",
    "df = df.drop(\"Unnamed: 9\",axis=1)\n",
    "identifiers = [\"COD_S11\", \"Cod_SPro\"]\n",
    "alternative_targets = [\"CR_PRO\", \"QR_PRO\", \"CC_PRO\", \"WC_PRO\", \"FEP_PRO\", \"ENG_PRO\", \"QUARTILE\", \"PERCENTILE\",\n",
    "                       \"2ND_DECILE\", ]\n",
    "df = df.drop(identifiers+alternative_targets,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_col = \"G_SC\"\n",
    "demographic_cols = ['GENDER', 'EDU_FATHER', 'EDU_MOTHER', 'OCC_FATHER', 'OCC_MOTHER',\n",
    "       'STRATUM', 'SISBEN', 'PEOPLE_HOUSE', 'INTERNET', 'TV', 'COMPUTER',\n",
    "       'WASHING_MCH', 'MIC_OVEN', 'CAR', 'DVD', 'FRESH', 'PHONE', 'MOBILE','REVENUE', 'JOB', 'SCHOOL_NAME', 'SCHOOL_NAT', 'SCHOOL_TYPE','SEL', 'SEL_IHE']\n",
    "perf_cols = ['MAT_S11','CR_S11', 'CC_S11', 'BIO_S11', 'ENG_S11']\n",
    "activity_cols = []\n",
    "other_cols = ['UNIVERSITY', 'ACADEMIC_PROGRAM']\n",
    "set(df.columns)-set([y_col]+demographic_cols+perf_cols+activity_cols+other_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>d</th>\n",
       "      <th>% NA</th>\n",
       "      <th>Target</th>\n",
       "      <th>Performance features</th>\n",
       "      <th>Demographic features</th>\n",
       "      <th>Activity features</th>\n",
       "      <th>Other features</th>\n",
       "      <th>Categorical features</th>\n",
       "      <th>Total cardinality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cortez</th>\n",
       "      <td>12411</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$y \\in [$37..247]</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            N   d  % NA             Target  Performance features  \\\n",
       "cortez  12411  33   0.0  $y \\in [$37..247]                     5   \n",
       "\n",
       "        Demographic features  Activity features  Other features  \\\n",
       "cortez                    25                  0               2   \n",
       "\n",
       "        Categorical features  Total cardinality  \n",
       "cortez                    13               3980  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_df_dict = {\"N\": df.shape[0],\n",
    "           \"d\": df.shape[1],\n",
    "           \"% NA\": df.isna().sum().sum()/sum(df.shape),\n",
    "           \"Target\": f\"$y \\in [${df[y_col].min()}..{df[y_col].max()}]\",\n",
    "           \"Performance features\": len(perf_cols),\n",
    "           \"Demographic features\": len(demographic_cols),\n",
    "           \"Activity features\": len(activity_cols),\n",
    "           \"Other features\": len(other_cols),\n",
    "           \"Categorical features\": len(df.columns[list(np.logical_and(df.nunique() > 2, df.dtypes == \"object\"))]),     \n",
    "           \"Total cardinality\": df[df.columns[list(np.logical_and(df.nunique() > 2, df.dtypes == \"object\"))]].nunique().sum(),     \n",
    "#            \"High cardinality levels\":  list(df.loc[:,list(df.columns[list(np.logical_and(df.nunique() >= 10, df.dtypes == \"object\"))])].nunique().sort_values().values),\n",
    "          \n",
    "}\n",
    "desc_df = pd.DataFrame([desc_df_dict],index=[\"cortez\"])\n",
    "desc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAT_S11</th>\n",
       "      <td>0.643838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR_S11</th>\n",
       "      <td>0.653572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC_S11</th>\n",
       "      <td>0.634900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIO_S11</th>\n",
       "      <td>0.666635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENG_S11</th>\n",
       "      <td>0.662169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEL</th>\n",
       "      <td>0.271465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEL_IHE</th>\n",
       "      <td>0.374400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           target\n",
       "MAT_S11  0.643838\n",
       "CR_S11   0.653572\n",
       "CC_S11   0.634900\n",
       "BIO_S11  0.666635\n",
       "ENG_S11  0.662169\n",
       "SEL      0.271465\n",
       "SEL_IHE  0.374400\n",
       "target   1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pd.concat([df.drop(y_col,axis=1),pd.Series(df[y_col].values,index=df.index,name=\"target\")],axis=1).corr()[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "{} &             cortez \\\\\n",
      "\\midrule\n",
      "N                    &              12411 \\\\\n",
      "d                    &                 33 \\\\\n",
      "\\% NA                 &                  0 \\\\\n",
      "Target               &  \\$y \\textbackslash in [\\$37..247] \\\\\n",
      "Performance features &                  5 \\\\\n",
      "Demographic features &                 25 \\\\\n",
      "Activity features    &                  0 \\\\\n",
      "Other features       &                  2 \\\\\n",
      "Categorical features &                 13 \\\\\n",
      "Total cardinality    &               3980 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(desc_df.transpose().to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = f\"{mode}_RS{RS}_hct{hct}\"\n",
    "if mode == \"cv\":\n",
    "    data_path += f\"_{folds}folds\"\n",
    "elif mode == \"train_test\":\n",
    "    data_path += f\"_split{1-test_ratio*100}-{test_ratio*100}\"\n",
    "elif mode == \"train_val_test\":\n",
    "    data_path += f\"_split{round(100-(test_ratio+val_ratio)*100)}-{round(test_ratio*100)}-{round(val_ratio*100)}\"\n",
    "\n",
    "\n",
    "# If no data_dict for the configuration exists, run preprocessing, else load data_dict\n",
    "if not os.path.exists(f\"../data/prepared/{dataset_name}/\"+data_path+\"/data_dict.pickle\"):\n",
    "    dataset_preprocessing.process_dataset(dataset_name, target, mode, RS, hct, test_ratio, val_ratio, folds)\n",
    "with open(f\"../data/prepared/{dataset_name}/{data_path}/data_dict.pickle\", 'rb') as handle:\n",
    "        data_dict = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of categorical data treatment methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\"ignore\", \"ohe\", \"target\", \"ordinal\", \"catboost\", \"glmm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_rounds = 10\n",
    "max_evals = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow5_col1 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow5_col2 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow24_col4 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow24_col5 {\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddf\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >RMSE Train</th>        <th class=\"col_heading level0 col1\" >MSE Train</th>        <th class=\"col_heading level0 col2\" >R2 Train</th>        <th class=\"col_heading level0 col3\" >RMSE Test</th>        <th class=\"col_heading level0 col4\" >MSE Test</th>        <th class=\"col_heading level0 col5\" >R2 Test</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row0\" class=\"row_heading level0 row0\" >Baseline</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow0_col0\" class=\"data row0 col0\" >23.112800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow0_col1\" class=\"data row0 col1\" >534.203800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow0_col2\" class=\"data row0 col2\" >-0.000000</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow0_col3\" class=\"data row0 col3\" >23.108900</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow0_col4\" class=\"data row0 col4\" >534.021700</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow0_col5\" class=\"data row0 col5\" >-0.000500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row1\" class=\"row_heading level0 row1\" >XGB_catboost</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow1_col0\" class=\"data row1 col0\" >8.050500</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow1_col1\" class=\"data row1 col1\" >64.811300</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow1_col2\" class=\"data row1 col2\" >0.878700</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow1_col3\" class=\"data row1 col3\" >15.952600</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow1_col4\" class=\"data row1 col4\" >254.486000</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow1_col5\" class=\"data row1 col5\" >0.523200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row2\" class=\"row_heading level0 row2\" >XGB_ignore</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow2_col0\" class=\"data row2 col0\" >9.924400</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow2_col1\" class=\"data row2 col1\" >98.493500</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow2_col2\" class=\"data row2 col2\" >0.815600</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow2_col3\" class=\"data row2 col3\" >15.501000</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow2_col4\" class=\"data row2 col4\" >240.281000</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow2_col5\" class=\"data row2 col5\" >0.549800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row3\" class=\"row_heading level0 row3\" >XGB_ordinal</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow3_col0\" class=\"data row3 col0\" >8.463300</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow3_col1\" class=\"data row3 col1\" >71.627700</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow3_col2\" class=\"data row3 col2\" >0.865900</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow3_col3\" class=\"data row3 col3\" >15.408000</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow3_col4\" class=\"data row3 col4\" >237.405700</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow3_col5\" class=\"data row3 col5\" >0.555200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row4\" class=\"row_heading level0 row4\" >XGB_target</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow4_col0\" class=\"data row4 col0\" >7.833200</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow4_col1\" class=\"data row4 col1\" >61.359700</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow4_col2\" class=\"data row4 col2\" >0.885100</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow4_col3\" class=\"data row4 col3\" >15.310800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow4_col4\" class=\"data row4 col4\" >234.420500</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow4_col5\" class=\"data row4 col5\" >0.560800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row5\" class=\"row_heading level0 row5\" >XGB_glmm</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow5_col0\" class=\"data row5 col0\" >7.643300</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow5_col1\" class=\"data row5 col1\" >58.419500</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow5_col2\" class=\"data row5 col2\" >0.890600</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow5_col3\" class=\"data row5 col3\" >15.294000</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow5_col4\" class=\"data row5 col4\" >233.906000</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow5_col5\" class=\"data row5 col5\" >0.561800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row6\" class=\"row_heading level0 row6\" >XGB_ohe</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow6_col0\" class=\"data row6 col0\" >10.147200</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow6_col1\" class=\"data row6 col1\" >102.966500</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow6_col2\" class=\"data row6 col2\" >0.807300</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow6_col3\" class=\"data row6 col3\" >14.834000</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow6_col4\" class=\"data row6 col4\" >220.046800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow6_col5\" class=\"data row6 col5\" >0.587700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row7\" class=\"row_heading level0 row7\" >LR_target_tuned</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow7_col0\" class=\"data row7 col0\" >13.600400</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow7_col1\" class=\"data row7 col1\" >184.971800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow7_col2\" class=\"data row7 col2\" >0.653700</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow7_col3\" class=\"data row7 col3\" >14.825100</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow7_col4\" class=\"data row7 col4\" >219.783600</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow7_col5\" class=\"data row7 col5\" >0.588200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row8\" class=\"row_heading level0 row8\" >LR_target</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow8_col0\" class=\"data row8 col0\" >13.604500</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow8_col1\" class=\"data row8 col1\" >185.083000</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow8_col2\" class=\"data row8 col2\" >0.653500</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow8_col3\" class=\"data row8 col3\" >14.815900</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow8_col4\" class=\"data row8 col4\" >219.509400</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow8_col5\" class=\"data row8 col5\" >0.588700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row9\" class=\"row_heading level0 row9\" >LR_ordinal_tuned</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow9_col0\" class=\"data row9 col0\" >14.214000</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow9_col1\" class=\"data row9 col1\" >202.037400</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow9_col2\" class=\"data row9 col2\" >0.621800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow9_col3\" class=\"data row9 col3\" >14.762900</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow9_col4\" class=\"data row9 col4\" >217.944100</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow9_col5\" class=\"data row9 col5\" >0.591700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row10\" class=\"row_heading level0 row10\" >LR_ordinal</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow10_col0\" class=\"data row10 col0\" >14.216500</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow10_col1\" class=\"data row10 col1\" >202.107800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow10_col2\" class=\"data row10 col2\" >0.621700</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow10_col3\" class=\"data row10 col3\" >14.758000</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow10_col4\" class=\"data row10 col4\" >217.797700</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow10_col5\" class=\"data row10 col5\" >0.591900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row11\" class=\"row_heading level0 row11\" >LR_ignore_tuned</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow11_col0\" class=\"data row11 col0\" >14.232200</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow11_col1\" class=\"data row11 col1\" >202.556200</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow11_col2\" class=\"data row11 col2\" >0.620800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow11_col3\" class=\"data row11 col3\" >14.750100</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow11_col4\" class=\"data row11 col4\" >217.566300</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow11_col5\" class=\"data row11 col5\" >0.592400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row12\" class=\"row_heading level0 row12\" >LR_ignore</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow12_col0\" class=\"data row12 col0\" >14.234400</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow12_col1\" class=\"data row12 col1\" >202.618300</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow12_col2\" class=\"data row12 col2\" >0.620700</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow12_col3\" class=\"data row12 col3\" >14.745200</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow12_col4\" class=\"data row12 col4\" >217.419600</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow12_col5\" class=\"data row12 col5\" >0.592600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row13\" class=\"row_heading level0 row13\" >LR_catboost</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow13_col0\" class=\"data row13 col0\" >14.025300</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow13_col1\" class=\"data row13 col1\" >196.710300</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow13_col2\" class=\"data row13 col2\" >0.631800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow13_col3\" class=\"data row13 col3\" >14.672300</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow13_col4\" class=\"data row13 col4\" >215.276600</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow13_col5\" class=\"data row13 col5\" >0.596700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row14\" class=\"row_heading level0 row14\" >LR_catboost_tuned</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow14_col0\" class=\"data row14 col0\" >14.027200</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow14_col1\" class=\"data row14 col1\" >196.763200</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow14_col2\" class=\"data row14 col2\" >0.631700</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow14_col3\" class=\"data row14 col3\" >14.672100</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow14_col4\" class=\"data row14 col4\" >215.271100</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow14_col5\" class=\"data row14 col5\" >0.596700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row15\" class=\"row_heading level0 row15\" >XGB_catboost_tuned</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow15_col0\" class=\"data row15 col0\" >12.651800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow15_col1\" class=\"data row15 col1\" >160.066800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow15_col2\" class=\"data row15 col2\" >0.700400</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow15_col3\" class=\"data row15 col3\" >14.593200</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow15_col4\" class=\"data row15 col4\" >212.961000</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow15_col5\" class=\"data row15 col5\" >0.601000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row16\" class=\"row_heading level0 row16\" >XGB_ignore_tuned</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow16_col0\" class=\"data row16 col0\" >14.009100</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow16_col1\" class=\"data row16 col1\" >196.255300</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow16_col2\" class=\"data row16 col2\" >0.632600</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow16_col3\" class=\"data row16 col3\" >14.588200</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow16_col4\" class=\"data row16 col4\" >212.815300</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow16_col5\" class=\"data row16 col5\" >0.601300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row17\" class=\"row_heading level0 row17\" >XGB_target_tuned</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow17_col0\" class=\"data row17 col0\" >12.482500</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow17_col1\" class=\"data row17 col1\" >155.813900</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow17_col2\" class=\"data row17 col2\" >0.708300</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow17_col3\" class=\"data row17 col3\" >14.587800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow17_col4\" class=\"data row17 col4\" >212.802900</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow17_col5\" class=\"data row17 col5\" >0.601300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row18\" class=\"row_heading level0 row18\" >LR_ohe</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow18_col0\" class=\"data row18 col0\" >13.914600</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow18_col1\" class=\"data row18 col1\" >193.614900</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow18_col2\" class=\"data row18 col2\" >0.637600</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow18_col3\" class=\"data row18 col3\" >14.556100</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow18_col4\" class=\"data row18 col4\" >211.879500</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow18_col5\" class=\"data row18 col5\" >0.603000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row19\" class=\"row_heading level0 row19\" >LR_ohe_tuned</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow19_col0\" class=\"data row19 col0\" >13.634600</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow19_col1\" class=\"data row19 col1\" >185.901600</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow19_col2\" class=\"data row19 col2\" >0.652000</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow19_col3\" class=\"data row19 col3\" >14.541400</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow19_col4\" class=\"data row19 col4\" >211.451900</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow19_col5\" class=\"data row19 col5\" >0.603800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row20\" class=\"row_heading level0 row20\" >LR_glmm_tuned</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow20_col0\" class=\"data row20 col0\" >13.994600</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow20_col1\" class=\"data row20 col1\" >195.847700</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow20_col2\" class=\"data row20 col2\" >0.633400</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow20_col3\" class=\"data row20 col3\" >14.540800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow20_col4\" class=\"data row20 col4\" >211.433600</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow20_col5\" class=\"data row20 col5\" >0.603900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row21\" class=\"row_heading level0 row21\" >LR_glmm</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow21_col0\" class=\"data row21 col0\" >13.995100</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow21_col1\" class=\"data row21 col1\" >195.864000</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow21_col2\" class=\"data row21 col2\" >0.633400</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow21_col3\" class=\"data row21 col3\" >14.540500</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow21_col4\" class=\"data row21 col4\" >211.426400</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow21_col5\" class=\"data row21 col5\" >0.603900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row22\" class=\"row_heading level0 row22\" >XGB_ordinal_tuned</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow22_col0\" class=\"data row22 col0\" >12.987700</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow22_col1\" class=\"data row22 col1\" >168.681500</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow22_col2\" class=\"data row22 col2\" >0.684200</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow22_col3\" class=\"data row22 col3\" >14.446200</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow22_col4\" class=\"data row22 col4\" >208.691500</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow22_col5\" class=\"data row22 col5\" >0.609000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row23\" class=\"row_heading level0 row23\" >XGB_ohe_tuned</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow23_col0\" class=\"data row23 col0\" >12.970100</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow23_col1\" class=\"data row23 col1\" >168.223000</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow23_col2\" class=\"data row23 col2\" >0.685100</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow23_col3\" class=\"data row23 col3\" >14.423800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow23_col4\" class=\"data row23 col4\" >208.045200</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow23_col5\" class=\"data row23 col5\" >0.610200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddflevel0_row24\" class=\"row_heading level0 row24\" >XGB_glmm_tuned</th>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow24_col0\" class=\"data row24 col0\" >13.159100</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow24_col1\" class=\"data row24 col1\" >173.162900</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow24_col2\" class=\"data row24 col2\" >0.675800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow24_col3\" class=\"data row24 col3\" >14.388800</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow24_col4\" class=\"data row24 col4\" >207.036300</td>\n",
       "                        <td id=\"T_a65aad8e_9822_11ed_ac67_abaaea1eaddfrow24_col5\" class=\"data row24 col5\" >0.612100</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f83081c7c70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(f\"../results/{dataset_name}/{experiment_name}/results_encodings.pickle\"):\n",
    "\n",
    "    results_encodings = {}\n",
    "    results_encodings_feature_importances = {}\n",
    "\n",
    "    for fold in range(folds):\n",
    "        target_scaler = data_dict[f\"target_scaler_{fold}\"]\n",
    "        results_encodings[fold] = {}\n",
    "        results_encodings_feature_importances[fold] = {}\n",
    "        # Create baseline\n",
    "        y_train = data_dict[f\"y_train_{fold}\"]\n",
    "        y_val = data_dict[f\"y_val_{fold}\"]\n",
    "        y_test = target_scaler.inverse_transform(data_dict[f\"y_test_{fold}\"].reshape(-1,1)).ravel()\n",
    "        y_train_val = target_scaler.inverse_transform(np.concatenate([y_train,y_val]).reshape(-1,1)).ravel()\n",
    "\n",
    "        y_train_val_pred_base = np.ones(y_train_val.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "        y_test_pred_base = np.ones(y_test.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "\n",
    "        results_encodings[fold][\"Baseline\"] = {}\n",
    "        eval_res_train = get_metrics(y_train_val, y_train_val_pred_base, target=target)\n",
    "        for metric in eval_res_train.keys():\n",
    "            results_encodings[fold][\"Baseline\"][metric + \" Train\"] = eval_res_train[metric]\n",
    "        eval_res_test = get_metrics(y_test, y_test_pred_base, target=target)\n",
    "        for metric in eval_res_test.keys():\n",
    "            results_encodings[fold][\"Baseline\"][metric + \" Test\"] = eval_res_test[metric]\n",
    "        results_encodings[fold][\"Baseline\"][\"RMSE Test\"] = np.sqrt(results_encodings[fold][\"Baseline\"][\"MSE Test\"])\n",
    "        results_encodings[fold][\"Baseline\"][\"RMSE Train\"] = np.sqrt(results_encodings[fold][\"Baseline\"][\"MSE Train\"])\n",
    "\n",
    "\n",
    "        for condition in conditions:\n",
    "            print(f\"Preparing results for fold {fold}, condition={condition}\")\n",
    "            # Retrieve data\n",
    "            z_cols = data_dict[\"z_cols\"]\n",
    "\n",
    "            X_train = data_dict[f\"X_train_{fold}\"]\n",
    "            y_train = data_dict[f\"y_train_{fold}\"]\n",
    "\n",
    "            X_val = data_dict[f\"X_val_{fold}\"]\n",
    "            y_val = data_dict[f\"y_val_{fold}\"]\n",
    "\n",
    "            X_test = data_dict[f\"X_test_{fold}\"]\n",
    "            y_test = data_dict[f\"y_test_{fold}\"]\n",
    "\n",
    "    #         Define condition data subset\n",
    "            if condition != \"ignore\":\n",
    "                z_encoded_train = data_dict[f\"z_{condition}_encoded_train_{fold}\"] \n",
    "                z_encoded_val = data_dict[f\"z_{condition}_encoded_val_{fold}\"] \n",
    "                z_encoded_test = data_dict[f\"z_{condition}_encoded_test_{fold}\"] \n",
    "\n",
    "                X_train = pd.concat([X_train,z_encoded_train],axis=1)\n",
    "                X_val = pd.concat([X_val,z_encoded_val],axis=1)\n",
    "                X_test = pd.concat([X_test,z_encoded_test],axis=1)\n",
    "\n",
    "            X_train_val = pd.concat([X_train,X_val])\n",
    "            y_train_val = np.concatenate([y_train,y_val])\n",
    "\n",
    "            # Train base models\n",
    "            res, feats = evaluate_lr(X_train_val, y_train_val, X_test, y_test, target=target,tune=False, seed=RS, target_scaler=target_scaler)\n",
    "            results_encodings[fold][\"LR_\"+condition] = res\n",
    "            results_encodings_feature_importances[fold][\"LR_\"+condition] = feats\n",
    "            results_encodings[fold][\"LR_\"+condition][\"RMSE Test\"] = np.sqrt(results_encodings[fold][\"LR_\"+condition][\"MSE Test\"])\n",
    "            results_encodings[fold][\"LR_\"+condition][\"RMSE Train\"] = np.sqrt(results_encodings[fold][\"LR_\"+condition][\"MSE Train\"])\n",
    "\n",
    "            res, feats = evaluate_xgb(X_train_val, y_train_val, X_test, y_test, target, tune=False, max_evals=max_evals, early_stopping_rounds=early_stopping_rounds, seed=RS, target_scaler=target_scaler)\n",
    "            results_encodings[fold][\"XGB_\"+condition] = res\n",
    "            results_encodings_feature_importances[fold][\"XGB_\"+condition] = feats\n",
    "            results_encodings[fold][\"XGB_\"+condition][\"RMSE Test\"] = np.sqrt(results_encodings[fold][\"XGB_\"+condition][\"MSE Test\"])\n",
    "            results_encodings[fold][\"XGB_\"+condition][\"RMSE Train\"] = np.sqrt(results_encodings[fold][\"XGB_\"+condition][\"MSE Train\"])\n",
    "\n",
    "            # Train tuned models\n",
    "            res, feats = evaluate_lr(X_train_val, y_train_val, X_test, y_test, target=target, max_evals=max_evals, tune=True, seed=RS, target_scaler=target_scaler)\n",
    "            results_encodings[fold][\"LR_\"+condition+\"_tuned\"] = res\n",
    "            results_encodings_feature_importances[fold][\"LR_\"+condition+\"_tuned\"] = feats\n",
    "            results_encodings[fold][\"LR_\"+condition+\"_tuned\"][\"RMSE Test\"] = np.sqrt(results_encodings[fold][\"LR_\"+condition+\"_tuned\"][\"MSE Test\"])\n",
    "            results_encodings[fold][\"LR_\"+condition+\"_tuned\"][\"RMSE Train\"] = np.sqrt(results_encodings[fold][\"LR_\"+condition+\"_tuned\"][\"MSE Train\"])\n",
    "\n",
    "            res, feats = evaluate_xgb(X_train_val, y_train_val, X_test, y_test, target, tune=True, max_evals=max_evals, early_stopping_rounds=early_stopping_rounds, seed=RS, target_scaler=target_scaler)\n",
    "            results_encodings[fold][\"XGB_\"+condition+\"_tuned\"] = res\n",
    "            results_encodings_feature_importances[fold][\"XGB_\"+condition+\"_tuned\"] = feats\n",
    "            results_encodings[fold][\"XGB_\"+condition+\"_tuned\"][\"RMSE Test\"] = np.sqrt(results_encodings[fold][\"XGB_\"+condition+\"_tuned\"][\"MSE Test\"])\n",
    "            results_encodings[fold][\"XGB_\"+condition+\"_tuned\"][\"RMSE Train\"] = np.sqrt(results_encodings[fold][\"XGB_\"+condition+\"_tuned\"][\"MSE Train\"])\n",
    "    \n",
    "    if not os.path.exists(f\"../results/{dataset_name}/{experiment_name}\"):\n",
    "        os.makedirs(f\"../results/{dataset_name}/{experiment_name}\")\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_encodings.pickle\", 'wb') as handle:\n",
    "        pickle.dump(results_encodings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_encodings_feature_importances.pickle\", 'wb') as handle:\n",
    "        pickle.dump(results_encodings_feature_importances, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_encodings.pickle\", 'rb') as handle:\n",
    "        results_encodings = pickle.load(handle)\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_encodings_feature_importances.pickle\", 'rb') as handle:\n",
    "        results_encodings_feature_importances = pickle.load(handle)\n",
    "    for fold in range(folds):\n",
    "        target_scaler = data_dict[f\"target_scaler_{fold}\"]\n",
    "        # Create baseline\n",
    "        y_train = data_dict[f\"y_train_{fold}\"]\n",
    "        y_val = data_dict[f\"y_val_{fold}\"]\n",
    "        y_test = target_scaler.inverse_transform(data_dict[f\"y_test_{fold}\"].reshape(-1,1)).ravel()\n",
    "        y_train_val = target_scaler.inverse_transform(np.concatenate([y_train,y_val]).reshape(-1,1)).ravel()\n",
    "\n",
    "        y_train_val_pred_base = np.ones(y_train_val.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "        y_test_pred_base = np.ones(y_test.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "\n",
    "        results_encodings[fold][\"Baseline\"] = {}\n",
    "        eval_res_train = get_metrics(y_train_val, y_train_val_pred_base, target=target)\n",
    "        for metric in eval_res_train.keys():\n",
    "            results_encodings[fold][\"Baseline\"][metric + \" Train\"] = eval_res_train[metric]\n",
    "        eval_res_test = get_metrics(y_test, y_test_pred_base, target=target)\n",
    "        for metric in eval_res_test.keys():\n",
    "            results_encodings[fold][\"Baseline\"][metric + \" Test\"] = eval_res_test[metric]\n",
    "        results_encodings[fold][\"Baseline\"][\"RMSE Test\"] = np.sqrt(results_encodings[fold][\"Baseline\"][\"MSE Test\"])\n",
    "        results_encodings[fold][\"Baseline\"][\"RMSE Train\"] = np.sqrt(results_encodings[fold][\"Baseline\"][\"MSE Train\"])\n",
    "        \n",
    "        \n",
    "results_encodings_df = pd.DataFrame(results_encodings[0]).transpose().sort_values(\"MSE Test\",ascending=False).round(4)\n",
    "results_encodings_df[[\"RMSE Train\", \"MSE Train\", \"R2 Train\", \"RMSE Test\", \"MSE Test\", \"R2 Test\"]].style.highlight_min(subset=[\"MSE Train\", \"MSE Test\"], color = 'lightgreen', axis = 0).highlight_max(subset=[\"R2 Train\", \"R2 Test\"], color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_a66665c0_9822_11ed_ac67_abaaea1eaddfrow0_col2 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_a66665c0_9822_11ed_ac67_abaaea1eaddfrow0_col6 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_a66665c0_9822_11ed_ac67_abaaea1eaddf\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Baseline</th>        <th class=\"col_heading level0 col1\" >LR_ignore_tuned</th>        <th class=\"col_heading level0 col2\" >LR_ohe_tuned</th>        <th class=\"col_heading level0 col3\" >LR_target_tuned</th>        <th class=\"col_heading level0 col4\" >LR_ordinal_tuned</th>        <th class=\"col_heading level0 col5\" >LR_catboost_tuned</th>        <th class=\"col_heading level0 col6\" >LR_glmm_tuned</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a66665c0_9822_11ed_ac67_abaaea1eaddflevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_a66665c0_9822_11ed_ac67_abaaea1eaddfrow0_col0\" class=\"data row0 col0\" >23.11 (0.26)</td>\n",
       "                        <td id=\"T_a66665c0_9822_11ed_ac67_abaaea1eaddfrow0_col1\" class=\"data row0 col1\" >14.36 (0.26)</td>\n",
       "                        <td id=\"T_a66665c0_9822_11ed_ac67_abaaea1eaddfrow0_col2\" class=\"data row0 col2\" >14.11 (0.29)</td>\n",
       "                        <td id=\"T_a66665c0_9822_11ed_ac67_abaaea1eaddfrow0_col3\" class=\"data row0 col3\" >14.55 (0.23)</td>\n",
       "                        <td id=\"T_a66665c0_9822_11ed_ac67_abaaea1eaddfrow0_col4\" class=\"data row0 col4\" >14.36 (0.25)</td>\n",
       "                        <td id=\"T_a66665c0_9822_11ed_ac67_abaaea1eaddfrow0_col5\" class=\"data row0 col5\" >14.22 (0.29)</td>\n",
       "                        <td id=\"T_a66665c0_9822_11ed_ac67_abaaea1eaddfrow0_col6\" class=\"data row0 col6\" >14.13 (0.29)</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8306d7f9d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For LR\n",
    "models = [\"Baseline\"]+[i for i in results_encodings[0].keys() if (\"tuned\" in i and \"LR\" in i)]\n",
    "metric = \"RMSE Test\"\n",
    "\n",
    "#####\n",
    "dataset_res_dict = {}\n",
    "best_models = {}\n",
    "t_test_results = {}\n",
    "\n",
    "round_mean_at = 2\n",
    "round_std_at = 2\n",
    "\n",
    "use_df = pd.DataFrame([pd.DataFrame(results_encodings[fold_num]).loc[metric,models] for fold_num in results_encodings.keys()],index=results_encodings.keys())*-1\n",
    "\n",
    "df_mean = pd.DataFrame((-1*use_df).mean(axis=0).round(round_mean_at).astype(str) + \" (\" + use_df.std(axis=0).round(round_std_at).astype(str) + \")\").transpose()\n",
    "model_dict = {i: df_mean[i].values[0] for i in df_mean.columns}\n",
    "\n",
    "best_model = use_df.columns[use_df.mean(axis=0).argmax()]\n",
    "\n",
    "t_test_res = np.array([stats.ttest_rel(use_df[best_model].values, use_df[model].values)[1] for model in models]).round(3)\n",
    "t_test_res[np.isnan(t_test_res)] = 1.\n",
    "    \n",
    "res_df_lr = pd.DataFrame([model_dict])\n",
    "\n",
    "def negative_bold(val):\n",
    "    i = np.where(val.name==np.array(models))[0][0]\n",
    "    return [\"font-weight: bold\"  if t_test_res[i]>=0.05 else \"\" for dataset_name in val.keys()]\n",
    "    # Case without transpose:\n",
    "#     return [\"font-weight: bold\"  if t_test_results[val.name][i]>=0.05 else \"\" for i in range(len(val))]\n",
    "\n",
    "res_df_lr.style.apply(negative_bold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_a66cd248_9822_11ed_ac67_abaaea1eaddfrow0_col6 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_a66cd248_9822_11ed_ac67_abaaea1eaddf\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Baseline</th>        <th class=\"col_heading level0 col1\" >XGB_ignore_tuned</th>        <th class=\"col_heading level0 col2\" >XGB_ohe_tuned</th>        <th class=\"col_heading level0 col3\" >XGB_target_tuned</th>        <th class=\"col_heading level0 col4\" >XGB_ordinal_tuned</th>        <th class=\"col_heading level0 col5\" >XGB_catboost_tuned</th>        <th class=\"col_heading level0 col6\" >XGB_glmm_tuned</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a66cd248_9822_11ed_ac67_abaaea1eaddflevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_a66cd248_9822_11ed_ac67_abaaea1eaddfrow0_col0\" class=\"data row0 col0\" >23.11 (0.26)</td>\n",
       "                        <td id=\"T_a66cd248_9822_11ed_ac67_abaaea1eaddfrow0_col1\" class=\"data row0 col1\" >14.28 (0.25)</td>\n",
       "                        <td id=\"T_a66cd248_9822_11ed_ac67_abaaea1eaddfrow0_col2\" class=\"data row0 col2\" >14.11 (0.26)</td>\n",
       "                        <td id=\"T_a66cd248_9822_11ed_ac67_abaaea1eaddfrow0_col3\" class=\"data row0 col3\" >14.38 (0.23)</td>\n",
       "                        <td id=\"T_a66cd248_9822_11ed_ac67_abaaea1eaddfrow0_col4\" class=\"data row0 col4\" >14.15 (0.25)</td>\n",
       "                        <td id=\"T_a66cd248_9822_11ed_ac67_abaaea1eaddfrow0_col5\" class=\"data row0 col5\" >14.17 (0.28)</td>\n",
       "                        <td id=\"T_a66cd248_9822_11ed_ac67_abaaea1eaddfrow0_col6\" class=\"data row0 col6\" >14.04 (0.28)</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8306d7f160>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For LR\n",
    "models = [\"Baseline\"]+[i for i in results_encodings[0].keys() if (\"tuned\" in i and \"XGB\" in i)]\n",
    "metric = \"RMSE Test\"\n",
    "\n",
    "#####\n",
    "dataset_res_dict = {}\n",
    "best_models = {}\n",
    "t_test_results = {}\n",
    "\n",
    "round_mean_at = 2\n",
    "round_std_at = 2\n",
    "\n",
    "use_df = pd.DataFrame([pd.DataFrame(results_encodings[fold_num]).loc[metric,models] for fold_num in results_encodings.keys()],index=results_encodings.keys())*-1\n",
    "\n",
    "df_mean = pd.DataFrame((-1*use_df).mean(axis=0).round(round_mean_at).astype(str) + \" (\" + use_df.std(axis=0).round(round_std_at).astype(str) + \")\").transpose()\n",
    "model_dict = {i: df_mean[i].values[0] for i in df_mean.columns}\n",
    "\n",
    "best_model = use_df.columns[use_df.mean(axis=0).argmax()]\n",
    "\n",
    "t_test_res = np.array([stats.ttest_rel(use_df[best_model].values, use_df[model].values)[1] for model in models]).round(3)\n",
    "t_test_res[np.isnan(t_test_res)] = 1.\n",
    "    \n",
    "res_df_xgb = pd.DataFrame([model_dict])\n",
    "    \n",
    "def negative_bold(val):\n",
    "    i = np.where(val.name==np.array(models))[0][0]\n",
    "    return [\"font-weight: bold\"  if t_test_res[i]>=0.05 else \"\" for dataset_name in val.keys()]\n",
    "    # Case without transpose:\n",
    "#     return [\"font-weight: bold\"  if t_test_results[val.name][i]>=0.05 else \"\" for i in range(len(val))]\n",
    "\n",
    "res_df_xgb.style.apply(negative_bold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>ignore</th>\n",
       "      <th>ohe</th>\n",
       "      <th>target</th>\n",
       "      <th>ordinal</th>\n",
       "      <th>catboost</th>\n",
       "      <th>glmm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>23.11 (0.26)</td>\n",
       "      <td>14.36 (0.26)</td>\n",
       "      <td>14.11 (0.29)</td>\n",
       "      <td>14.55 (0.23)</td>\n",
       "      <td>14.36 (0.25)</td>\n",
       "      <td>14.22 (0.29)</td>\n",
       "      <td>14.13 (0.29)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>23.11 (0.26)</td>\n",
       "      <td>14.28 (0.25)</td>\n",
       "      <td>14.11 (0.26)</td>\n",
       "      <td>14.38 (0.23)</td>\n",
       "      <td>14.15 (0.25)</td>\n",
       "      <td>14.17 (0.28)</td>\n",
       "      <td>14.04 (0.28)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Baseline        ignore           ohe        target       ordinal  \\\n",
       "LR   23.11 (0.26)  14.36 (0.26)  14.11 (0.29)  14.55 (0.23)  14.36 (0.25)   \n",
       "XGB  23.11 (0.26)  14.28 (0.25)  14.11 (0.26)  14.38 (0.23)  14.15 (0.25)   \n",
       "\n",
       "         catboost          glmm  \n",
       "LR   14.22 (0.29)  14.13 (0.29)  \n",
       "XGB  14.17 (0.28)  14.04 (0.28)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_lr.columns = [i.split(\"_\")[1] if i != \"Baseline\" else \"Baseline\" for i in res_df_lr.columns]    \n",
    "res_df_xgb.columns = [i.split(\"_\")[1] if i != \"Baseline\" else \"Baseline\" for i in res_df_xgb.columns]    \n",
    "\n",
    "latex_df_encodings = pd.concat([res_df_lr,res_df_xgb],axis=0)\n",
    "latex_df_encodings.index = [\"LR\", \"XGB\"]\n",
    "latex_df_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "{} &      Baseline &        ignore &           ohe &        target &       ordinal &      catboost &          glmm \\\\\n",
      "\\midrule\n",
      "LR  &  23.11 (0.26) &  14.36 (0.26) &  14.11 (0.29) &  14.55 (0.23) &  14.36 (0.25) &  14.22 (0.29) &  14.13 (0.29) \\\\\n",
      "XGB &  23.11 (0.26) &  14.28 (0.25) &  14.11 (0.26) &  14.38 (0.23) &  14.15 (0.25) &  14.17 (0.28) &  14.04 (0.28) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex_df_encodings.round(2).to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data subset comparisons\n",
    "\n",
    "As it does not matter which encoding method is used we use 5CV-GLMM encoding for LR and Ordinal encoding for XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = {\"demo_only\": demographic_cols,\n",
    "           \"perfact_only\": perf_cols+activity_cols,\n",
    "           \"perfact_and_demo\": perf_cols+activity_cols+demographic_cols,\n",
    "           \"all\": list(df.columns)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_a697996a_9822_11ed_ac67_abaaea1eaddfrow7_col1 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_a697996a_9822_11ed_ac67_abaaea1eaddfrow7_col2 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_a697996a_9822_11ed_ac67_abaaea1eaddfrow16_col4 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_a697996a_9822_11ed_ac67_abaaea1eaddfrow16_col5 {\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddf\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >RMSE Train</th>        <th class=\"col_heading level0 col1\" >MSE Train</th>        <th class=\"col_heading level0 col2\" >R2 Train</th>        <th class=\"col_heading level0 col3\" >RMSE Test</th>        <th class=\"col_heading level0 col4\" >MSE Test</th>        <th class=\"col_heading level0 col5\" >R2 Test</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row0\" class=\"row_heading level0 row0\" >Baseline</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow0_col0\" class=\"data row0 col0\" >23.112800</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow0_col1\" class=\"data row0 col1\" >534.203800</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow0_col2\" class=\"data row0 col2\" >-0.000000</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow0_col3\" class=\"data row0 col3\" >23.108900</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow0_col4\" class=\"data row0 col4\" >534.021700</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow0_col5\" class=\"data row0 col5\" >-0.000500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row1\" class=\"row_heading level0 row1\" >XGB_demo_only</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow1_col0\" class=\"data row1 col0\" >12.888600</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow1_col1\" class=\"data row1 col1\" >166.115500</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow1_col2\" class=\"data row1 col2\" >0.689000</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow1_col3\" class=\"data row1 col3\" >21.995000</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow1_col4\" class=\"data row1 col4\" >483.779400</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow1_col5\" class=\"data row1 col5\" >0.093600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row2\" class=\"row_heading level0 row2\" >LR_demo_only</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow2_col0\" class=\"data row2 col0\" >20.477900</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow2_col1\" class=\"data row2 col1\" >419.344700</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow2_col2\" class=\"data row2 col2\" >0.215000</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow2_col3\" class=\"data row2 col3\" >20.672300</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow2_col4\" class=\"data row2 col4\" >427.343400</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow2_col5\" class=\"data row2 col5\" >0.199300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row3\" class=\"row_heading level0 row3\" >LR_demo_only_tuned</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow3_col0\" class=\"data row3 col0\" >20.478700</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow3_col1\" class=\"data row3 col1\" >419.378300</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow3_col2\" class=\"data row3 col2\" >0.214900</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow3_col3\" class=\"data row3 col3\" >20.671300</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow3_col4\" class=\"data row3 col4\" >427.301800</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow3_col5\" class=\"data row3 col5\" >0.199400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row4\" class=\"row_heading level0 row4\" >XGB_demo_only_tuned</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow4_col0\" class=\"data row4 col0\" >19.831100</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow4_col1\" class=\"data row4 col1\" >393.272200</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow4_col2\" class=\"data row4 col2\" >0.263800</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow4_col3\" class=\"data row4 col3\" >20.639700</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow4_col4\" class=\"data row4 col4\" >425.998200</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow4_col5\" class=\"data row4 col5\" >0.201800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row5\" class=\"row_heading level0 row5\" >XGB_perfact_and_demo</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow5_col0\" class=\"data row5 col0\" >8.329200</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow5_col1\" class=\"data row5 col1\" >69.375600</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow5_col2\" class=\"data row5 col2\" >0.870100</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow5_col3\" class=\"data row5 col3\" >15.627800</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow5_col4\" class=\"data row5 col4\" >244.228800</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow5_col5\" class=\"data row5 col5\" >0.542400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row6\" class=\"row_heading level0 row6\" >XGB_perfact_only</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow6_col0\" class=\"data row6 col0\" >10.945400</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow6_col1\" class=\"data row6 col1\" >119.802300</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow6_col2\" class=\"data row6 col2\" >0.775700</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow6_col3\" class=\"data row6 col3\" >15.396800</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow6_col4\" class=\"data row6 col4\" >237.061200</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow6_col5\" class=\"data row6 col5\" >0.555800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row7\" class=\"row_heading level0 row7\" >XGB_all</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow7_col0\" class=\"data row7 col0\" >7.643300</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow7_col1\" class=\"data row7 col1\" >58.419500</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow7_col2\" class=\"data row7 col2\" >0.890600</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow7_col3\" class=\"data row7 col3\" >15.294000</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow7_col4\" class=\"data row7 col4\" >233.906000</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow7_col5\" class=\"data row7 col5\" >0.561800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row8\" class=\"row_heading level0 row8\" >LR_perfact_only</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow8_col0\" class=\"data row8 col0\" >14.369000</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow8_col1\" class=\"data row8 col1\" >206.467000</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow8_col2\" class=\"data row8 col2\" >0.613500</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow8_col3\" class=\"data row8 col3\" >14.829200</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow8_col4\" class=\"data row8 col4\" >219.904600</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow8_col5\" class=\"data row8 col5\" >0.588000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row9\" class=\"row_heading level0 row9\" >LR_perfact_only_tuned</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow9_col0\" class=\"data row9 col0\" >14.369100</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow9_col1\" class=\"data row9 col1\" >206.471100</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow9_col2\" class=\"data row9 col2\" >0.613500</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow9_col3\" class=\"data row9 col3\" >14.828700</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow9_col4\" class=\"data row9 col4\" >219.889300</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow9_col5\" class=\"data row9 col5\" >0.588000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row10\" class=\"row_heading level0 row10\" >LR_perfact_and_demo_tuned</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow10_col0\" class=\"data row10 col0\" >14.214400</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow10_col1\" class=\"data row10 col1\" >202.048000</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow10_col2\" class=\"data row10 col2\" >0.621800</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow10_col3\" class=\"data row10 col3\" >14.742000</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow10_col4\" class=\"data row10 col4\" >217.325800</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow10_col5\" class=\"data row10 col5\" >0.592800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row11\" class=\"row_heading level0 row11\" >LR_perfact_and_demo</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow11_col0\" class=\"data row11 col0\" >14.215500</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow11_col1\" class=\"data row11 col1\" >202.080800</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow11_col2\" class=\"data row11 col2\" >0.621700</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow11_col3\" class=\"data row11 col3\" >14.740700</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow11_col4\" class=\"data row11 col4\" >217.287000</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow11_col5\" class=\"data row11 col5\" >0.592900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row12\" class=\"row_heading level0 row12\" >XGB_perfact_only_tuned</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow12_col0\" class=\"data row12 col0\" >14.162200</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow12_col1\" class=\"data row12 col1\" >200.569100</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow12_col2\" class=\"data row12 col2\" >0.624500</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow12_col3\" class=\"data row12 col3\" >14.672100</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow12_col4\" class=\"data row12 col4\" >215.270100</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow12_col5\" class=\"data row12 col5\" >0.596700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row13\" class=\"row_heading level0 row13\" >LR_all</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow13_col0\" class=\"data row13 col0\" >13.991400</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow13_col1\" class=\"data row13 col1\" >195.758700</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow13_col2\" class=\"data row13 col2\" >0.633500</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow13_col3\" class=\"data row13 col3\" >14.544100</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow13_col4\" class=\"data row13 col4\" >211.531300</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow13_col5\" class=\"data row13 col5\" >0.603700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row14\" class=\"row_heading level0 row14\" >LR_all_tuned</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow14_col0\" class=\"data row14 col0\" >13.995400</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow14_col1\" class=\"data row14 col1\" >195.871600</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow14_col2\" class=\"data row14 col2\" >0.633300</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow14_col3\" class=\"data row14 col3\" >14.542200</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow14_col4\" class=\"data row14 col4\" >211.475200</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow14_col5\" class=\"data row14 col5\" >0.603800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row15\" class=\"row_heading level0 row15\" >XGB_perfact_and_demo_tuned</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow15_col0\" class=\"data row15 col0\" >13.713500</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow15_col1\" class=\"data row15 col1\" >188.058700</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow15_col2\" class=\"data row15 col2\" >0.648000</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow15_col3\" class=\"data row15 col3\" >14.537000</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow15_col4\" class=\"data row15 col4\" >211.324300</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow15_col5\" class=\"data row15 col5\" >0.604100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddflevel0_row16\" class=\"row_heading level0 row16\" >XGB_all_tuned</th>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow16_col0\" class=\"data row16 col0\" >13.401100</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow16_col1\" class=\"data row16 col1\" >179.588800</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow16_col2\" class=\"data row16 col2\" >0.663800</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow16_col3\" class=\"data row16 col3\" >14.442800</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow16_col4\" class=\"data row16 col4\" >208.593400</td>\n",
       "                        <td id=\"T_a697996a_9822_11ed_ac67_abaaea1eaddfrow16_col5\" class=\"data row16 col5\" >0.609200</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f83ed2b13a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(f\"../results/{dataset_name}/{experiment_name}/results_subsets.pickle\"):\n",
    "\n",
    "    results_subsets = {}\n",
    "    results_subsets_feature_importances = {}\n",
    "\n",
    "    for fold in range(folds):\n",
    "        target_scaler = data_dict[f\"target_scaler_{fold}\"]\n",
    "        results_subsets[fold] = {}\n",
    "        results_subsets_feature_importances[fold] = {}\n",
    "        # Create baseline\n",
    "        y_train = data_dict[f\"y_train_{fold}\"]\n",
    "        y_val = data_dict[f\"y_val_{fold}\"]\n",
    "        y_test = target_scaler.inverse_transform(data_dict[f\"y_test_{fold}\"].reshape(-1,1)).ravel()\n",
    "        y_train_val = target_scaler.inverse_transform(np.concatenate([y_train,y_val]).reshape(-1,1)).ravel()\n",
    "\n",
    "        y_train_val_pred_base = np.ones(y_train_val.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "        y_test_pred_base = np.ones(y_test.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "\n",
    "        results_subsets[fold][\"Baseline\"] = {}\n",
    "        eval_res_train = get_metrics(y_train_val, y_train_val_pred_base, target=target)\n",
    "        for metric in eval_res_train.keys():\n",
    "            results_subsets[fold][\"Baseline\"][metric + \" Train\"] = eval_res_train[metric]\n",
    "        eval_res_test = get_metrics(y_test, y_test_pred_base, target=target)\n",
    "        for metric in eval_res_test.keys():\n",
    "            results_subsets[fold][\"Baseline\"][metric + \" Test\"] = eval_res_test[metric]\n",
    "        results_subsets[fold][\"Baseline\"][\"RMSE Test\"] = np.sqrt(results_subsets[fold][\"Baseline\"][\"MSE Test\"])\n",
    "        results_subsets[fold][\"Baseline\"][\"RMSE Train\"] = np.sqrt(results_subsets[fold][\"Baseline\"][\"MSE Train\"])\n",
    "\n",
    "\n",
    "        for subset_key in subsets:\n",
    "            print(f\"Preparing results for fold {fold}, subset={subset_key}\")\n",
    "            # Retrieve data\n",
    "            z_cols = data_dict[\"z_cols\"]\n",
    "\n",
    "            X_train = data_dict[f\"X_train_{fold}\"]\n",
    "            y_train = data_dict[f\"y_train_{fold}\"]\n",
    "\n",
    "            X_val = data_dict[f\"X_val_{fold}\"]\n",
    "            y_val = data_dict[f\"y_val_{fold}\"]\n",
    "\n",
    "            X_test = data_dict[f\"X_test_{fold}\"]\n",
    "            y_test = data_dict[f\"y_test_{fold}\"]\n",
    "        \n",
    "            y_train_val = np.concatenate([y_train,y_val])\n",
    "\n",
    "            # Define data subset for LR\n",
    "            z_glmm_encoded_train = data_dict[f\"z_glmm_encoded_train_{fold}\"] \n",
    "            z_glmm_encoded_val = data_dict[f\"z_glmm_encoded_val_{fold}\"] \n",
    "            z_glmm_encoded_test = data_dict[f\"z_glmm_encoded_test_{fold}\"] \n",
    "            \n",
    "            X_train_lr = pd.concat([X_train,z_glmm_encoded_train],axis=1)\n",
    "            X_val_lr = pd.concat([X_val,z_glmm_encoded_val],axis=1)\n",
    "            X_test_lr = pd.concat([X_test,z_glmm_encoded_test],axis=1)      \n",
    "            X_train_val_lr = pd.concat([X_train_lr,X_val_lr])\n",
    "\n",
    "            # Rescale GLMM\n",
    "            for col in z_glmm_encoded_train.columns:\n",
    "                z_mean = X_train_val_lr[col].mean()\n",
    "                z_std = X_train_val_lr[col].std()\n",
    "            \n",
    "                X_train_val_lr[col] = (X_train_val_lr[col]-z_mean)/z_std\n",
    "                X_test_lr[col] = (X_test_lr[col]-z_mean)/z_std\n",
    "            \n",
    "            \n",
    "            # Define data subset for XGB\n",
    "#             z_ordinal_encoded_train = data_dict[f\"z_ordinal_encoded_train_{fold}\"] \n",
    "#             z_ordinal_encoded_val = data_dict[f\"z_ordinal_encoded_val_{fold}\"] \n",
    "#             z_ordinal_encoded_test = data_dict[f\"z_ordinal_encoded_test_{fold}\"] \n",
    "#             X_train_xgb = pd.concat([X_train,z_ordinal_encoded_train],axis=1)\n",
    "#             X_val_xgb = pd.concat([X_val,z_ordinal_encoded_val],axis=1)\n",
    "#             X_test_xgb = pd.concat([X_test,z_ordinal_encoded_test],axis=1)\n",
    "#             X_train_val_xgb = pd.concat([X_train_xgb,X_val_xgb])\n",
    "            X_train_val_xgb = X_train_val_lr\n",
    "            X_test_xgb = X_test_lr\n",
    "\n",
    "            # Define data subset for evaluation\n",
    "            X_train_val_lr = X_train_val_lr[[i for i in X_train_val_lr.columns if i in subsets[subset_key]]]\n",
    "            X_test_lr = X_test_lr[[i for i in X_test_lr.columns if i in subsets[subset_key]]]\n",
    "            X_train_val_xgb = X_train_val_xgb[[i for i in X_train_val_xgb.columns if i in subsets[subset_key]]]\n",
    "            X_test_xgb = X_test_xgb[[i for i in X_test_xgb.columns if i in subsets[subset_key]]]\n",
    "\n",
    "\n",
    "            # Train base models\n",
    "            res, feats = evaluate_lr(X_train_val_lr, y_train_val, X_test_lr, y_test, target=target,tune=False, seed=RS, target_scaler=target_scaler)\n",
    "            results_subsets[fold][\"LR_\"+subset_key] = res\n",
    "            results_subsets_feature_importances[fold][\"LR_\"+subset_key] = feats\n",
    "            results_subsets[fold][\"LR_\"+subset_key][\"RMSE Test\"] = np.sqrt(results_subsets[fold][\"LR_\"+subset_key][\"MSE Test\"])\n",
    "            results_subsets[fold][\"LR_\"+subset_key][\"RMSE Train\"] = np.sqrt(results_subsets[fold][\"LR_\"+subset_key][\"MSE Train\"])\n",
    "\n",
    "            res, feats = evaluate_xgb(X_train_val_xgb, y_train_val, X_test_xgb, y_test, target, tune=False, max_evals=max_evals, early_stopping_rounds=early_stopping_rounds, seed=RS, target_scaler=target_scaler)\n",
    "            results_subsets[fold][\"XGB_\"+subset_key] = res\n",
    "            results_subsets_feature_importances[fold][\"XGB_\"+subset_key] = feats\n",
    "            results_subsets[fold][\"XGB_\"+subset_key][\"RMSE Test\"] = np.sqrt(results_subsets[fold][\"XGB_\"+subset_key][\"MSE Test\"])\n",
    "            results_subsets[fold][\"XGB_\"+subset_key][\"RMSE Train\"] = np.sqrt(results_subsets[fold][\"XGB_\"+subset_key][\"MSE Train\"])\n",
    "\n",
    "            # Train tuned models\n",
    "            res, feats = evaluate_lr(X_train_val_lr, y_train_val, X_test_lr, y_test, target=target, max_evals=max_evals, tune=True, seed=RS, target_scaler=target_scaler)\n",
    "            results_subsets[fold][\"LR_\"+subset_key+\"_tuned\"] = res\n",
    "            results_subsets_feature_importances[fold][\"LR_\"+subset_key+\"_tuned\"] = feats\n",
    "            results_subsets[fold][\"LR_\"+subset_key+\"_tuned\"][\"RMSE Test\"] = np.sqrt(results_subsets[fold][\"LR_\"+subset_key+\"_tuned\"][\"MSE Test\"])\n",
    "            results_subsets[fold][\"LR_\"+subset_key+\"_tuned\"][\"RMSE Train\"] = np.sqrt(results_subsets[fold][\"LR_\"+subset_key+\"_tuned\"][\"MSE Train\"])\n",
    "\n",
    "            res, feats = evaluate_xgb(X_train_val_xgb, y_train_val, X_test_xgb, y_test, target, tune=True, max_evals=max_evals, early_stopping_rounds=early_stopping_rounds, seed=RS, target_scaler=target_scaler)\n",
    "            results_subsets[fold][\"XGB_\"+subset_key+\"_tuned\"] = res\n",
    "            results_subsets_feature_importances[fold][\"XGB_\"+subset_key+\"_tuned\"] = feats\n",
    "            results_subsets[fold][\"XGB_\"+subset_key+\"_tuned\"][\"RMSE Test\"] = np.sqrt(results_subsets[fold][\"XGB_\"+subset_key+\"_tuned\"][\"MSE Test\"])\n",
    "            results_subsets[fold][\"XGB_\"+subset_key+\"_tuned\"][\"RMSE Train\"] = np.sqrt(results_subsets[fold][\"XGB_\"+subset_key+\"_tuned\"][\"MSE Train\"])\n",
    "    \n",
    "    if not os.path.exists(f\"../results/{dataset_name}/{experiment_name}\"):\n",
    "        os.makedirs(f\"../results/{dataset_name}/{experiment_name}\")\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_subsets.pickle\", 'wb') as handle:\n",
    "        pickle.dump(results_subsets, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_subsets_feature_importances.pickle\", 'wb') as handle:\n",
    "        pickle.dump(results_subsets_feature_importances, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_subsets.pickle\", 'rb') as handle:\n",
    "        results_subsets = pickle.load(handle)\n",
    "    with open(f\"../results/{dataset_name}/{experiment_name}/results_subsets_feature_importances.pickle\", 'rb') as handle:\n",
    "        results_subsets_feature_importances = pickle.load(handle)\n",
    "    for fold in range(folds):\n",
    "        target_scaler = data_dict[f\"target_scaler_{fold}\"]\n",
    "        # Create baseline\n",
    "        y_train = data_dict[f\"y_train_{fold}\"]\n",
    "        y_val = data_dict[f\"y_val_{fold}\"]\n",
    "        y_test = target_scaler.inverse_transform(data_dict[f\"y_test_{fold}\"].reshape(-1,1)).ravel()\n",
    "        y_train_val = target_scaler.inverse_transform(np.concatenate([y_train,y_val]).reshape(-1,1)).ravel()\n",
    "\n",
    "        y_train_val_pred_base = np.ones(y_train_val.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "        y_test_pred_base = np.ones(y_test.shape[0])*target_scaler.mean_[0]#*np.mean(y_train_val)\n",
    "\n",
    "        results_subsets[fold][\"Baseline\"] = {}\n",
    "        eval_res_train = get_metrics(y_train_val, y_train_val_pred_base, target=target)\n",
    "        for metric in eval_res_train.keys():\n",
    "            results_subsets[fold][\"Baseline\"][metric + \" Train\"] = eval_res_train[metric]\n",
    "        eval_res_test = get_metrics(y_test, y_test_pred_base, target=target)\n",
    "        for metric in eval_res_test.keys():\n",
    "            results_subsets[fold][\"Baseline\"][metric + \" Test\"] = eval_res_test[metric]\n",
    "        results_subsets[fold][\"Baseline\"][\"RMSE Test\"] = np.sqrt(results_subsets[fold][\"Baseline\"][\"MSE Test\"])\n",
    "        results_subsets[fold][\"Baseline\"][\"RMSE Train\"] = np.sqrt(results_subsets[fold][\"Baseline\"][\"MSE Train\"])\n",
    "        \n",
    "        \n",
    "results_subsets_df = pd.DataFrame(results_subsets[0]).transpose().sort_values(\"RMSE Test\",ascending=False).round(4)\n",
    "results_subsets_df[[\"RMSE Train\", \"MSE Train\", \"R2 Train\", \"RMSE Test\", \"MSE Test\", \"R2 Test\"]].style.highlight_min(subset=[\"MSE Train\", \"MSE Test\"], color = 'lightgreen', axis = 0).highlight_max(subset=[\"R2 Train\", \"R2 Test\"], color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow7_col1 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow7_col2 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow16_col4 {\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow16_col5 {\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddf\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >RMSE Train</th>        <th class=\"col_heading level0 col1\" >MSE Train</th>        <th class=\"col_heading level0 col2\" >R2 Train</th>        <th class=\"col_heading level0 col3\" >RMSE Test</th>        <th class=\"col_heading level0 col4\" >MSE Test</th>        <th class=\"col_heading level0 col5\" >R2 Test</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row0\" class=\"row_heading level0 row0\" >Baseline</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow0_col0\" class=\"data row0 col0\" >23.112800</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow0_col1\" class=\"data row0 col1\" >534.203800</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow0_col2\" class=\"data row0 col2\" >-0.000000</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow0_col3\" class=\"data row0 col3\" >23.108900</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow0_col4\" class=\"data row0 col4\" >534.021700</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow0_col5\" class=\"data row0 col5\" >-0.000500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row1\" class=\"row_heading level0 row1\" >XGB_demo_only</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow1_col0\" class=\"data row1 col0\" >12.888600</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow1_col1\" class=\"data row1 col1\" >166.115500</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow1_col2\" class=\"data row1 col2\" >0.689000</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow1_col3\" class=\"data row1 col3\" >21.995000</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow1_col4\" class=\"data row1 col4\" >483.779400</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow1_col5\" class=\"data row1 col5\" >0.093600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row2\" class=\"row_heading level0 row2\" >LR_demo_only</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow2_col0\" class=\"data row2 col0\" >20.477900</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow2_col1\" class=\"data row2 col1\" >419.344700</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow2_col2\" class=\"data row2 col2\" >0.215000</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow2_col3\" class=\"data row2 col3\" >20.672300</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow2_col4\" class=\"data row2 col4\" >427.343400</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow2_col5\" class=\"data row2 col5\" >0.199300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row3\" class=\"row_heading level0 row3\" >LR_demo_only_tuned</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow3_col0\" class=\"data row3 col0\" >20.478700</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow3_col1\" class=\"data row3 col1\" >419.378300</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow3_col2\" class=\"data row3 col2\" >0.214900</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow3_col3\" class=\"data row3 col3\" >20.671300</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow3_col4\" class=\"data row3 col4\" >427.301800</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow3_col5\" class=\"data row3 col5\" >0.199400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row4\" class=\"row_heading level0 row4\" >XGB_demo_only_tuned</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow4_col0\" class=\"data row4 col0\" >19.831100</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow4_col1\" class=\"data row4 col1\" >393.272200</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow4_col2\" class=\"data row4 col2\" >0.263800</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow4_col3\" class=\"data row4 col3\" >20.639700</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow4_col4\" class=\"data row4 col4\" >425.998200</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow4_col5\" class=\"data row4 col5\" >0.201800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row5\" class=\"row_heading level0 row5\" >XGB_perfact_and_demo</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow5_col0\" class=\"data row5 col0\" >8.329200</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow5_col1\" class=\"data row5 col1\" >69.375600</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow5_col2\" class=\"data row5 col2\" >0.870100</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow5_col3\" class=\"data row5 col3\" >15.627800</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow5_col4\" class=\"data row5 col4\" >244.228800</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow5_col5\" class=\"data row5 col5\" >0.542400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row6\" class=\"row_heading level0 row6\" >XGB_perfact_only</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow6_col0\" class=\"data row6 col0\" >10.945400</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow6_col1\" class=\"data row6 col1\" >119.802300</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow6_col2\" class=\"data row6 col2\" >0.775700</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow6_col3\" class=\"data row6 col3\" >15.396800</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow6_col4\" class=\"data row6 col4\" >237.061200</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow6_col5\" class=\"data row6 col5\" >0.555800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row7\" class=\"row_heading level0 row7\" >XGB_all</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow7_col0\" class=\"data row7 col0\" >7.643300</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow7_col1\" class=\"data row7 col1\" >58.419500</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow7_col2\" class=\"data row7 col2\" >0.890600</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow7_col3\" class=\"data row7 col3\" >15.294000</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow7_col4\" class=\"data row7 col4\" >233.906000</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow7_col5\" class=\"data row7 col5\" >0.561800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row8\" class=\"row_heading level0 row8\" >LR_perfact_only</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow8_col0\" class=\"data row8 col0\" >14.369000</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow8_col1\" class=\"data row8 col1\" >206.467000</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow8_col2\" class=\"data row8 col2\" >0.613500</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow8_col3\" class=\"data row8 col3\" >14.829200</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow8_col4\" class=\"data row8 col4\" >219.904600</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow8_col5\" class=\"data row8 col5\" >0.588000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row9\" class=\"row_heading level0 row9\" >LR_perfact_only_tuned</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow9_col0\" class=\"data row9 col0\" >14.369100</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow9_col1\" class=\"data row9 col1\" >206.471100</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow9_col2\" class=\"data row9 col2\" >0.613500</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow9_col3\" class=\"data row9 col3\" >14.828700</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow9_col4\" class=\"data row9 col4\" >219.889300</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow9_col5\" class=\"data row9 col5\" >0.588000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row10\" class=\"row_heading level0 row10\" >LR_perfact_and_demo_tuned</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow10_col0\" class=\"data row10 col0\" >14.214400</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow10_col1\" class=\"data row10 col1\" >202.048000</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow10_col2\" class=\"data row10 col2\" >0.621800</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow10_col3\" class=\"data row10 col3\" >14.742000</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow10_col4\" class=\"data row10 col4\" >217.325800</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow10_col5\" class=\"data row10 col5\" >0.592800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row11\" class=\"row_heading level0 row11\" >LR_perfact_and_demo</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow11_col0\" class=\"data row11 col0\" >14.215500</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow11_col1\" class=\"data row11 col1\" >202.080800</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow11_col2\" class=\"data row11 col2\" >0.621700</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow11_col3\" class=\"data row11 col3\" >14.740700</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow11_col4\" class=\"data row11 col4\" >217.287000</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow11_col5\" class=\"data row11 col5\" >0.592900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row12\" class=\"row_heading level0 row12\" >XGB_perfact_only_tuned</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow12_col0\" class=\"data row12 col0\" >14.162200</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow12_col1\" class=\"data row12 col1\" >200.569100</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow12_col2\" class=\"data row12 col2\" >0.624500</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow12_col3\" class=\"data row12 col3\" >14.672100</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow12_col4\" class=\"data row12 col4\" >215.270100</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow12_col5\" class=\"data row12 col5\" >0.596700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row13\" class=\"row_heading level0 row13\" >LR_all</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow13_col0\" class=\"data row13 col0\" >13.991400</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow13_col1\" class=\"data row13 col1\" >195.758700</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow13_col2\" class=\"data row13 col2\" >0.633500</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow13_col3\" class=\"data row13 col3\" >14.544100</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow13_col4\" class=\"data row13 col4\" >211.531300</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow13_col5\" class=\"data row13 col5\" >0.603700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row14\" class=\"row_heading level0 row14\" >LR_all_tuned</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow14_col0\" class=\"data row14 col0\" >13.995400</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow14_col1\" class=\"data row14 col1\" >195.871600</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow14_col2\" class=\"data row14 col2\" >0.633300</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow14_col3\" class=\"data row14 col3\" >14.542200</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow14_col4\" class=\"data row14 col4\" >211.475200</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow14_col5\" class=\"data row14 col5\" >0.603800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row15\" class=\"row_heading level0 row15\" >XGB_perfact_and_demo_tuned</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow15_col0\" class=\"data row15 col0\" >13.713500</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow15_col1\" class=\"data row15 col1\" >188.058700</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow15_col2\" class=\"data row15 col2\" >0.648000</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow15_col3\" class=\"data row15 col3\" >14.537000</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow15_col4\" class=\"data row15 col4\" >211.324300</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow15_col5\" class=\"data row15 col5\" >0.604100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddflevel0_row16\" class=\"row_heading level0 row16\" >XGB_all_tuned</th>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow16_col0\" class=\"data row16 col0\" >13.401100</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow16_col1\" class=\"data row16 col1\" >179.588800</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow16_col2\" class=\"data row16 col2\" >0.663800</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow16_col3\" class=\"data row16 col3\" >14.442800</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow16_col4\" class=\"data row16 col4\" >208.593400</td>\n",
       "                        <td id=\"T_a69fb6b8_9822_11ed_ac67_abaaea1eaddfrow16_col5\" class=\"data row16 col5\" >0.609200</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8307256f10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_subsets_df = pd.DataFrame(results_subsets[0]).transpose().sort_values(\"RMSE Test\",ascending=False).round(4)\n",
    "results_subsets_df[[\"RMSE Train\", \"MSE Train\", \"R2 Train\", \"RMSE Test\", \"MSE Test\", \"R2 Test\"]].style.highlight_min(subset=[\"MSE Train\", \"MSE Test\"], color = 'lightgreen', axis = 0).highlight_max(subset=[\"R2 Train\", \"R2 Test\"], color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_a6a95e70_9822_11ed_ac67_abaaea1eaddfrow0_col4 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_a6a95e70_9822_11ed_ac67_abaaea1eaddf\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Baseline</th>        <th class=\"col_heading level0 col1\" >LR_demo_only_tuned</th>        <th class=\"col_heading level0 col2\" >LR_perfact_only_tuned</th>        <th class=\"col_heading level0 col3\" >LR_perfact_and_demo_tuned</th>        <th class=\"col_heading level0 col4\" >LR_all_tuned</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a6a95e70_9822_11ed_ac67_abaaea1eaddflevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_a6a95e70_9822_11ed_ac67_abaaea1eaddfrow0_col0\" class=\"data row0 col0\" >23.112 (0.264)</td>\n",
       "                        <td id=\"T_a6a95e70_9822_11ed_ac67_abaaea1eaddfrow0_col1\" class=\"data row0 col1\" >20.533 (0.3)</td>\n",
       "                        <td id=\"T_a6a95e70_9822_11ed_ac67_abaaea1eaddfrow0_col2\" class=\"data row0 col2\" >14.468 (0.222)</td>\n",
       "                        <td id=\"T_a6a95e70_9822_11ed_ac67_abaaea1eaddfrow0_col3\" class=\"data row0 col3\" >14.352 (0.254)</td>\n",
       "                        <td id=\"T_a6a95e70_9822_11ed_ac67_abaaea1eaddfrow0_col4\" class=\"data row0 col4\" >14.136 (0.285)</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8306d7fd90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For LR\n",
    "models = [\"Baseline\"]+[i for i in results_subsets[0].keys() if (\"tuned\" in i and \"LR\" in i)]\n",
    "metric = \"RMSE Test\"\n",
    "\n",
    "#####\n",
    "dataset_res_dict = {}\n",
    "best_models = {}\n",
    "t_test_results = {}\n",
    "\n",
    "use_df = pd.DataFrame([pd.DataFrame(results_subsets[fold_num]).loc[metric,models] for fold_num in results_subsets.keys()],index=results_subsets.keys())*-1\n",
    "\n",
    "df_mean = pd.DataFrame((-1*use_df).mean(axis=0).round(3).astype(str) + \" (\" + use_df.std(axis=0).round(3).astype(str) + \")\").transpose()\n",
    "model_dict = {i: df_mean[i].values[0] for i in df_mean.columns}\n",
    "\n",
    "best_model = use_df.columns[use_df.mean(axis=0).argmax()]\n",
    "\n",
    "t_test_res = np.array([stats.ttest_rel(use_df[best_model].values, use_df[model].values)[1] for model in models]).round(3)\n",
    "t_test_res[np.isnan(t_test_res)] = 1.\n",
    "    \n",
    "res_df_lr = pd.DataFrame([model_dict])\n",
    "\n",
    "def negative_bold(val):\n",
    "    i = np.where(val.name==np.array(models))[0][0]\n",
    "    return [\"font-weight: bold\"  if t_test_res[i]>=0.05 else \"\" for dataset_name in val.keys()]\n",
    "    # Case without transpose:\n",
    "#     return [\"font-weight: bold\"  if t_test_results[val.name][i]>=0.05 else \"\" for i in range(len(val))]\n",
    "\n",
    "res_df_lr.style.apply(negative_bold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_a6b01c4c_9822_11ed_ac67_abaaea1eaddfrow0_col4 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_a6b01c4c_9822_11ed_ac67_abaaea1eaddf\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Baseline</th>        <th class=\"col_heading level0 col1\" >XGB_demo_only_tuned</th>        <th class=\"col_heading level0 col2\" >XGB_perfact_only_tuned</th>        <th class=\"col_heading level0 col3\" >XGB_perfact_and_demo_tuned</th>        <th class=\"col_heading level0 col4\" >XGB_all_tuned</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a6b01c4c_9822_11ed_ac67_abaaea1eaddflevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_a6b01c4c_9822_11ed_ac67_abaaea1eaddfrow0_col0\" class=\"data row0 col0\" >23.112 (0.264)</td>\n",
       "                        <td id=\"T_a6b01c4c_9822_11ed_ac67_abaaea1eaddfrow0_col1\" class=\"data row0 col1\" >20.434 (0.34)</td>\n",
       "                        <td id=\"T_a6b01c4c_9822_11ed_ac67_abaaea1eaddfrow0_col2\" class=\"data row0 col2\" >14.393 (0.196)</td>\n",
       "                        <td id=\"T_a6b01c4c_9822_11ed_ac67_abaaea1eaddfrow0_col3\" class=\"data row0 col3\" >14.275 (0.225)</td>\n",
       "                        <td id=\"T_a6b01c4c_9822_11ed_ac67_abaaea1eaddfrow0_col4\" class=\"data row0 col4\" >14.048 (0.292)</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8306d905e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For XGB\n",
    "models = [\"Baseline\"]+[i for i in results_subsets[0].keys() if (\"tuned\" in i and \"XGB\" in i)]\n",
    "metric = \"RMSE Test\"\n",
    "\n",
    "#####\n",
    "dataset_res_dict = {}\n",
    "best_models = {}\n",
    "t_test_results = {}\n",
    "\n",
    "use_df = pd.DataFrame([pd.DataFrame(results_subsets[fold_num]).loc[metric,models] for fold_num in results_subsets.keys()],index=results_subsets.keys())*-1\n",
    "\n",
    "df_mean = pd.DataFrame((-1*use_df).mean(axis=0).round(3).astype(str) + \" (\" + use_df.std(axis=0).round(3).astype(str) + \")\").transpose()\n",
    "model_dict = {i: df_mean[i].values[0] for i in df_mean.columns}\n",
    "\n",
    "best_model = use_df.columns[use_df.mean(axis=0).argmax()]\n",
    "\n",
    "t_test_res = np.array([stats.ttest_rel(use_df[best_model].values, use_df[model].values)[1] for model in models]).round(3)\n",
    "t_test_res[np.isnan(t_test_res)] = 1.\n",
    "    \n",
    "res_df_xgb = pd.DataFrame([model_dict])\n",
    "\n",
    "def negative_bold(val):\n",
    "    i = np.where(val.name==np.array(models))[0][0]\n",
    "    return [\"font-weight: bold\"  if t_test_res[i]>=0.05 else \"\" for dataset_name in val.keys()]\n",
    "    # Case without transpose:\n",
    "#     return [\"font-weight: bold\"  if t_test_results[val.name][i]>=0.05 else \"\" for i in range(len(val))]\n",
    "\n",
    "res_df_xgb.style.apply(negative_bold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>demo_only</th>\n",
       "      <th>perfact_only</th>\n",
       "      <th>perfact_and_demo</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>23.112 (0.264)</td>\n",
       "      <td>20.533 (0.3)</td>\n",
       "      <td>14.468 (0.222)</td>\n",
       "      <td>14.352 (0.254)</td>\n",
       "      <td>14.136 (0.285)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>23.112 (0.264)</td>\n",
       "      <td>20.434 (0.34)</td>\n",
       "      <td>14.393 (0.196)</td>\n",
       "      <td>14.275 (0.225)</td>\n",
       "      <td>14.048 (0.292)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Baseline      demo_only    perfact_only perfact_and_demo  \\\n",
       "LR   23.112 (0.264)   20.533 (0.3)  14.468 (0.222)   14.352 (0.254)   \n",
       "XGB  23.112 (0.264)  20.434 (0.34)  14.393 (0.196)   14.275 (0.225)   \n",
       "\n",
       "                all  \n",
       "LR   14.136 (0.285)  \n",
       "XGB  14.048 (0.292)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_lr.columns = [i[3:-6] if i != \"Baseline\" else \"Baseline\" for i in res_df_lr.columns]    \n",
    "res_df_xgb.columns = [i[4:-6] if i != \"Baseline\" else \"Baseline\" for i in res_df_xgb.columns]    \n",
    "\n",
    "latex_df_subsets = pd.concat([res_df_lr,res_df_xgb],axis=0)\n",
    "latex_df_subsets.index = [\"LR\", \"XGB\"]\n",
    "latex_df_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "{} &              LR &             XGB \\\\\n",
      "\\midrule\n",
      "Baseline         &  23.112 (0.264) &  23.112 (0.264) \\\\\n",
      "demo\\_only        &    20.533 (0.3) &   20.434 (0.34) \\\\\n",
      "perfact\\_only     &  14.468 (0.222) &  14.393 (0.196) \\\\\n",
      "perfact\\_and\\_demo &  14.352 (0.254) &  14.275 (0.225) \\\\\n",
      "all              &  14.136 (0.285) &  14.048 (0.292) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex_df_subsets.round(2).transpose().to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_10_importances = {}\n",
    "\n",
    "# for model in list(results_subsets_feature_importances[fold].keys()):\n",
    "#     imp_df = pd.concat([results_subsets_feature_importances[fold][model] for fold in range(folds)],axis=1)\n",
    "\n",
    "#     if \"LR\" in model:\n",
    "#         direction = imp_df.apply(lambda x: np.sign(x))\n",
    "#         imp_df = imp_df.abs()\n",
    "\n",
    "#     imp_df = imp_df/imp_df.sum(axis=0)\n",
    "\n",
    "#     mean_imp_df = imp_df.mean(axis=1)\n",
    "#     std_imp_df = imp_df.std(axis=1)\n",
    "\n",
    "#     mean_imp_df = mean_imp_df.sort_values(ascending=False)\n",
    "#     std_imp_df = std_imp_df.loc[mean_imp_df.index]\n",
    "#     final_imps = mean_imp_df[:10]\n",
    "#     final_imps[\"Rest\"] = sum(mean_imp_df[10:])\n",
    "#     top_5_importances[model] = np.array([final_imps.index.values, final_imps.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_importances = {}\n",
    "demo_importances_stds = {}\n",
    "\n",
    "for model in list(results_subsets_feature_importances[fold].keys()):\n",
    "    if \"demo\" in model or \"all\" in model:\n",
    "        imp_df_all = pd.concat([results_subsets_feature_importances[fold][model] for fold in range(folds)],axis=1)\n",
    "        \n",
    "        if \"LR\" in model:\n",
    "            direction = imp_df_all.apply(lambda x: np.sign(x))\n",
    "            imp_df_all = imp_df_all.abs()\n",
    "        if imp_df_all.sum().sum()!=0:\n",
    "            imp_df = imp_df_all/imp_df_all.sum(axis=0)\n",
    "        imp_df = imp_df.fillna(1/imp_df.shape[0])\n",
    "#         imp_df = imp_df.loc[demographic_cols]\n",
    "\n",
    "#         mean_imp_df = imp_df.mean(axis=1)\n",
    "#         std_imp_df = imp_df.std(axis=1)\n",
    "\n",
    "#         mean_imp_df = mean_imp_df.sort_values(ascending=False)\n",
    "#         std_imp_df = std_imp_df.loc[mean_imp_df.index]\n",
    "#         final_imps = mean_imp_df#[:10]\n",
    "#         final_imps[\"Rest\"] = sum(mean_imp_df[10:])\n",
    "#         final_imps[\"Total\"] = sum(mean_imp_df)\n",
    "        demo_importances[model] = np.round(np.mean(imp_df.loc[demographic_cols].sum(axis=0)),2)#final_imps.values\n",
    "        demo_importances_stds[model] = np.round(np.std(imp_df.loc[demographic_cols].sum(axis=0)),2)#final_imps.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demo_only</th>\n",
       "      <th>perfact_and_demo</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>1.0 (0.0)</td>\n",
       "      <td>0.25 (0.03)</td>\n",
       "      <td>0.23 (0.02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>1.0 (0.0)</td>\n",
       "      <td>0.23 (0.06)</td>\n",
       "      <td>0.19 (0.09)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     demo_only perfact_and_demo          all\n",
       "LR   1.0 (0.0)      0.25 (0.03)  0.23 (0.02)\n",
       "XGB  1.0 (0.0)      0.23 (0.06)  0.19 (0.09)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_demo_imp = pd.Series({i: demo_importances[i] for i in demo_importances if \"LR\" in i and \"tuned\" in i})\n",
    "xgb_demo_imp = pd.Series({i: demo_importances[i] for i in demo_importances if \"XGB\" in i and \"tuned\" in i})\n",
    "lr_demo_imp.index = [i[3:-6] for i in lr_demo_imp.index]    \n",
    "xgb_demo_imp.index = [i[4:-6] for i in xgb_demo_imp.index]    \n",
    "\n",
    "lr_demo_imp_stds = pd.Series({i: demo_importances_stds[i] for i in demo_importances_stds if \"LR\" in i and \"tuned\" in i})\n",
    "xgb_demo_imp_stds = pd.Series({i: demo_importances_stds[i] for i in demo_importances_stds if \"XGB\" in i and \"tuned\" in i})\n",
    "lr_demo_imp_stds.index = [i[3:-6] for i in lr_demo_imp_stds.index]    \n",
    "xgb_demo_imp_stds.index = [i[4:-6] for i in xgb_demo_imp_stds.index]    \n",
    "\n",
    "\n",
    "latex_df_imp = pd.DataFrame([lr_demo_imp.astype(str) + \" (\" + lr_demo_imp_stds.astype(str) + \")\",\n",
    "                             xgb_demo_imp.astype(str) + \" (\" + xgb_demo_imp_stds.astype(str) + \")\"])\n",
    "latex_df_imp.index = [\"LR\", \"XGB\"]\n",
    "latex_df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "{} &           LR &          XGB \\\\\n",
      "\\midrule\n",
      "demo\\_only        &    1.0 (0.0) &    1.0 (0.0) \\\\\n",
      "perfact\\_and\\_demo &  0.25 (0.03) &  0.23 (0.06) \\\\\n",
      "all              &  0.23 (0.02) &  0.19 (0.09) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex_df_imp.transpose().to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean impact of using demo features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.3844196869294715                             \n",
      "SCORE: 0.5687690331195043                                                       \n",
      "SCORE: 0.720201745892618                                                        \n",
      "SCORE: 0.4993240193909855                                                       \n",
      "SCORE: 0.6722046168605272                                                       \n",
      "SCORE: 0.7408250377352987                                                       \n",
      "SCORE: 0.39366658306078117                                                      \n",
      "SCORE: 0.40740431456859855                                                      \n",
      "SCORE: 0.46113296602228404                                                      \n",
      "SCORE: 0.580246050109633                                                        \n",
      "SCORE: 0.6076300853509391                                                        \n",
      "SCORE: 0.4423272406365726                                                        \n",
      "SCORE: 0.6502727801054494                                                        \n",
      "SCORE: 0.46393334077966975                                                       \n",
      "SCORE: 0.6290911685972929                                                        \n",
      "SCORE: 0.5955285995920698                                                        \n",
      "SCORE: 0.5389699965575648                                                        \n",
      "SCORE: 0.6998943955829221                                                        \n",
      "SCORE: 0.6757931568567248                                                        \n",
      "SCORE: 0.543923585470079                                                         \n",
      "SCORE: 0.37106128557112344                                                       \n",
      "SCORE: 0.3727904078652796                                                         \n",
      "SCORE: 0.3703695063540604                                                         \n",
      "SCORE: 0.37043726350335965                                                        \n",
      "SCORE: 0.377353669421401                                                         \n",
      "SCORE: 0.4124787785704026                                                        \n",
      "SCORE: 0.37632903610742474                                                       \n",
      "SCORE: 0.3744475407848852                                                        \n",
      "SCORE: 0.383283247887377                                                         \n",
      "SCORE: 0.38551212932377543                                                       \n",
      "SCORE: 0.42282087152282666                                                       \n",
      "SCORE: 0.39632879356459927                                                       \n",
      "SCORE: 0.37192471127418114                                                       \n",
      "SCORE: 0.49885830921670554                                                       \n",
      "SCORE: 0.3821604822950255                                                        \n",
      "SCORE: 0.3706076614262175                                                        \n",
      "SCORE: 0.43018782230263736                                                       \n",
      "SCORE: 0.3950085001715282                                                        \n",
      "SCORE: 0.49908926143786997                                                       \n",
      "SCORE: 0.3739341841465506                                                        \n",
      "SCORE: 0.400565020604928                                                         \n",
      "SCORE: 0.44704095974163527                                                       \n",
      "SCORE: 0.38729255346135494                                                       \n",
      "SCORE: 0.38066837419546357                                                       \n",
      "SCORE: 0.47719828166679507                                                       \n",
      "SCORE: 0.4130988780617944                                                        \n",
      "SCORE: 0.3774030767510915                                                        \n",
      "SCORE: 0.3737753596704215                                                        \n",
      "SCORE: 0.5257811926023213                                                        \n",
      "SCORE: 0.3893077893493872                                                        \n",
      "100%|██████████| 50/50 [00:10<00:00,  4.85trial/s, best loss: 0.3703695063540604]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'alpha': 0.0019650649201695125}\n",
      "Mean absolute Difference w\\o Demo: 0.91\n",
      "RMSE Difference w\\o Demo: 1.13\n",
      "SCORE: 0.679347390753755                              \n",
      "SCORE: 0.382708914893045                                                       \n",
      "SCORE: 0.4091972597968515                                                      \n",
      "SCORE: 0.44610304685264096                                                     \n",
      "SCORE: 0.42969862634118305                                                     \n",
      "SCORE: 0.45815291744765674                                                     \n",
      "SCORE: 0.7435206103230352                                                      \n",
      "SCORE: 0.47818107592261966                                                     \n",
      "SCORE: 0.6496563297687878                                                      \n",
      "SCORE: 0.4303504532644647                                                      \n",
      "SCORE: 0.6267131017795038                                                       \n",
      "SCORE: 0.6137161342181943                                                       \n",
      "SCORE: 0.4116105985808839                                                       \n",
      "SCORE: 0.567707221051797                                                        \n",
      "SCORE: 0.39182121597868513                                                      \n",
      "SCORE: 0.6077082761957288                                                       \n",
      "SCORE: 0.5347688211568814                                                       \n",
      "SCORE: 0.3857298818370122                                                       \n",
      "SCORE: 0.5300076574755159                                                       \n",
      "SCORE: 0.7087004635274772                                                       \n",
      "SCORE: 0.377028173952127                                                        \n",
      "SCORE: 0.37847468525788575                                                      \n",
      "SCORE: 0.3780911816163853                                                       \n",
      "SCORE: 0.377846176140736                                                        \n",
      "SCORE: 0.37552749117273077                                                      \n",
      "SCORE: 0.3976861592213085                                                         \n",
      "SCORE: 0.3816842197445676                                                         \n",
      "SCORE: 0.37655351701317036                                                        \n",
      "SCORE: 0.4826580388507291                                                         \n",
      "SCORE: 0.39700602893504444                                                        \n",
      "SCORE: 0.37609714969392777                                                        \n",
      "SCORE: 0.37541132975797814                                                        \n",
      "SCORE: 0.38635821919496105                                                        \n",
      "SCORE: 0.38105038010426406                                                        \n",
      "SCORE: 0.4113163745303132                                                         \n",
      "SCORE: 0.42934772060469595                                                        \n",
      "SCORE: 0.3755885020723429                                                         \n",
      "SCORE: 0.3993561580239681                                                         \n",
      "SCORE: 0.5094828303290864                                                         \n",
      "SCORE: 0.43658457632734854                                                        \n",
      "SCORE: 0.4595676829987526                                                         \n",
      "SCORE: 0.3795454167651193                                                         \n",
      "SCORE: 0.41766809696138896                                                        \n",
      "SCORE: 0.39314458822180204                                                        \n",
      "SCORE: 0.388570152130324                                                          \n",
      "SCORE: 0.49709458195407547                                                        \n",
      "SCORE: 0.449000054445231                                                          \n",
      "SCORE: 0.3832319280431985                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.405763561776748                                                          \n",
      "SCORE: 0.6731209443457145                                                         \n",
      "100%|██████████| 50/50 [00:09<00:00,  5.14trial/s, best loss: 0.37541132975797814]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'alpha': 0.0009711868490754763}\n",
      "Mean absolute Difference w\\o Demo: 0.94\n",
      "RMSE Difference w\\o Demo: 1.16\n",
      "SCORE: 0.5162246517153749                             \n",
      "SCORE: 0.37582693901262554                            \n",
      "SCORE: 0.3738943920673966                                                        \n",
      "SCORE: 0.3877910170552713                                                        \n",
      "SCORE: 0.6329793424951399                                                       \n",
      "SCORE: 0.5728079966588925                                                       \n",
      "SCORE: 0.39484426447370946                                                      \n",
      "SCORE: 0.6043028249581632                                                       \n",
      "SCORE: 0.5162028500938298                                                       \n",
      "SCORE: 0.5466325339546065                                                       \n",
      "SCORE: 0.6302056660623843                                                        \n",
      "SCORE: 0.5260150212182066                                                        \n",
      "SCORE: 0.5039999232546688                                                        \n",
      "SCORE: 0.4103110153417072                                                        \n",
      "SCORE: 0.5258168238141455                                                        \n",
      "SCORE: 0.42996520616941075                                                       \n",
      "SCORE: 0.5171762198364872                                                        \n",
      "SCORE: 0.622574848402889                                                         \n",
      "SCORE: 0.3832393001751312                                                        \n",
      "SCORE: 0.7421874640224634                                                        \n",
      "SCORE: 0.3750833703161734                                                        \n",
      "SCORE: 0.3747029787928106                                                        \n",
      "SCORE: 0.3788205831530931                                                        \n",
      "SCORE: 0.4432022486877578                                                        \n",
      "SCORE: 0.37381464218912075                                                       \n",
      "SCORE: 0.3972520736955763                                                         \n",
      "SCORE: 0.37737391426151107                                                        \n",
      "SCORE: 0.46572943641628994                                                        \n",
      "SCORE: 0.40595085238972006                                                        \n",
      "SCORE: 0.3810312390873827                                                         \n",
      "SCORE: 0.7072279036932738                                                         \n",
      "SCORE: 0.3738741849412726                                                         \n",
      "SCORE: 0.4257362416867506                                                         \n",
      "SCORE: 0.386474776710222                                                          \n",
      "SCORE: 0.3772794332370235                                                         \n",
      "SCORE: 0.4713577518722136                                                         \n",
      "SCORE: 0.3738001891001435                                                         \n",
      "SCORE: 0.39982110720025754                                                        \n",
      "SCORE: 0.3882427833710577                                                        \n",
      "SCORE: 0.4156996629291328                                                        \n",
      "SCORE: 0.45410281196885116                                                       \n",
      "SCORE: 0.39176693421104297                                                       \n",
      "SCORE: 0.49060097713880857                                                       \n",
      "SCORE: 0.6676098431819686                                                        \n",
      "SCORE: 0.5653901999355171                                                        \n",
      "SCORE: 0.37646644108621086                                                       \n",
      "SCORE: 0.37985922493986335                                                       \n",
      "SCORE: 0.3832208933767972                                                        \n",
      "SCORE: 0.43074620471624686                                                       \n",
      "SCORE: 0.41736596675754284                                                       \n",
      "100%|██████████| 50/50 [00:09<00:00,  5.30trial/s, best loss: 0.3738001891001435]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'alpha': 0.0008753194187795512}\n",
      "Mean absolute Difference w\\o Demo: 1.1\n",
      "RMSE Difference w\\o Demo: 1.35\n",
      "SCORE: 0.3984835896867409                             \n",
      "SCORE: 0.4309818954443962                             \n",
      "SCORE: 0.7014533333922243                                                       \n",
      "SCORE: 0.4488842728932935                                                       \n",
      "SCORE: 0.41349247247557186                                                      \n",
      "SCORE: 0.5606565122921858                                                       \n",
      "SCORE: 0.4200639978843273                                                       \n",
      "SCORE: 0.4005228450420316                                                       \n",
      "SCORE: 0.38793962084789774                                                      \n",
      "SCORE: 0.7272270590770455                                                        \n",
      "SCORE: 0.37528402912229436                                                        \n",
      "SCORE: 0.3928150369676914                                                         \n",
      "SCORE: 0.3752884698495026                                                         \n",
      "SCORE: 0.5383583172272426                                                         \n",
      "SCORE: 0.3841790710816369                                                         \n",
      "SCORE: 0.7319798104588371                                                         \n",
      "SCORE: 0.6629629344925534                                                         \n",
      "SCORE: 0.41335094557462                                                           \n",
      "SCORE: 0.5905316557415994                                                         \n",
      "SCORE: 0.5952527264194905                                                         \n",
      "SCORE: 0.37726805092267035                                                        \n",
      "SCORE: 0.37583015937697406                                                        \n",
      "SCORE: 0.3756068096972888                                                         \n",
      "SCORE: 0.4818990420998134                                                         \n",
      "SCORE: 0.3827458047934292                                                         \n",
      "SCORE: 0.3796291048859092                                                         \n",
      "SCORE: 0.47991504733983137                                                        \n",
      "SCORE: 0.37817265652360416                                                        \n",
      "SCORE: 0.3999078045760973                                                         \n",
      "SCORE: 0.45091220423413986                                                        \n",
      "SCORE: 0.5169145302564198                                                         \n",
      "SCORE: 0.3798874063548001                                                         \n",
      "SCORE: 0.4409035827294751                                                         \n",
      "SCORE: 0.3909032883332101                                                         \n",
      "SCORE: 0.40724199417146806                                                        \n",
      "SCORE: 0.3819828416212433                                                         \n",
      "SCORE: 0.42280747551852793                                                        \n",
      "SCORE: 0.6470853263297899                                                         \n",
      "SCORE: 0.45752288293027676                                                        \n",
      "SCORE: 0.38828770258324175                                                        \n",
      "SCORE: 0.492822015720756                                                          \n",
      "SCORE: 0.4322667395698875                                                         \n",
      "SCORE: 0.39659296804400657                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.37915908060952924                                                        \n",
      "SCORE: 0.3854136797353644                                                         \n",
      "SCORE: 0.4083450504658293                                                         \n",
      "SCORE: 0.4238904558218972                                                         \n",
      "SCORE: 0.5237190917242334                                                         \n",
      "SCORE: 0.37543355488318014                                                        \n",
      "SCORE: 0.5850740218688164                                                         \n",
      "100%|██████████| 50/50 [00:09<00:00,  5.55trial/s, best loss: 0.37528402912229436]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'alpha': 0.0017910537667827297}\n",
      "Mean absolute Difference w\\o Demo: 0.94\n",
      "RMSE Difference w\\o Demo: 1.17\n",
      "SCORE: 0.5103659789269701                             \n",
      "SCORE: 0.44366425531962517                                                      \n",
      "SCORE: 0.5248404263966083                                                        \n",
      "SCORE: 0.5527303018110463                                                        \n",
      "SCORE: 0.5754755022301593                                                        \n",
      "SCORE: 0.641296691636282                                                         \n",
      "SCORE: 0.7077246911639631                                                        \n",
      "SCORE: 0.44624140906748105                                                       \n",
      "SCORE: 0.6820604017361391                                                        \n",
      "SCORE: 0.5737072962412257                                                        \n",
      "SCORE: 0.4190192445092027                                                         \n",
      "SCORE: 0.5199597530377738                                                         \n",
      "SCORE: 0.48678712223161746                                                       \n",
      "SCORE: 0.40476638004827237                                                       \n",
      "SCORE: 0.462440323271311                                                          \n",
      "SCORE: 0.45435498822875575                                                        \n",
      "SCORE: 0.384084772641953                                                          \n",
      "SCORE: 0.6641749003884299                                                         \n",
      "SCORE: 0.38697416921724426                                                      \n",
      "SCORE: 0.4092028392175311                                                       \n",
      "SCORE: 0.37763444487211084                                                      \n",
      "SCORE: 0.3762410004144777                                                         \n",
      "SCORE: 0.37614267239376464                                                        \n",
      "SCORE: 0.3786140047998454                                                         \n",
      "SCORE: 0.38991384499551573                                                        \n",
      "SCORE: 0.38040773693964447                                                        \n",
      "SCORE: 0.39966263376977146                                                        \n",
      "SCORE: 0.3768213427900468                                                         \n",
      "SCORE: 0.3816575942656583                                                         \n",
      "SCORE: 0.42308570579582516                                                        \n",
      "SCORE: 0.39142929936548637                                                        \n",
      "SCORE: 0.42793517291546923                                                        \n",
      "SCORE: 0.3953995415552116                                                         \n",
      "SCORE: 0.48733746490201335                                                        \n",
      "SCORE: 0.38162018088762906                                                        \n",
      "SCORE: 0.6276141865180731                                                         \n",
      "SCORE: 0.3762989138965944                                                         \n",
      "SCORE: 0.7499114840129364                                                         \n",
      "SCORE: 0.43668452314948014                                                        \n",
      "SCORE: 0.41158554849239887                                                        \n",
      "SCORE: 0.37971476882339267                                                        \n",
      "SCORE: 0.55292383814894                                                           \n",
      "SCORE: 0.38548336461919935                                                        \n",
      "SCORE: 0.49546908621564273                                                        \n",
      "SCORE: 0.3981281331212149                                                         \n",
      "SCORE: 0.608105070223661                                                          \n",
      "SCORE: 0.4658846112611535                                                         \n",
      "SCORE: 0.38363675436539724                                                        \n",
      "SCORE: 0.5371699912227845                                                         \n",
      "SCORE: 0.4441727247872344                                                         \n",
      "100%|██████████| 50/50 [00:09<00:00,  5.48trial/s, best loss: 0.37614267239376464]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'alpha': 0.0016545309410105988}\n",
      "Mean absolute Difference w\\o Demo: 0.95\n",
      "RMSE Difference w\\o Demo: 1.17\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RS)\n",
    "mean_abs_differences = []\n",
    "for fold in range(folds):\n",
    "    X_train = data_dict[f\"X_train_{fold}\"]\n",
    "    y_train = data_dict[f\"y_train_{fold}\"]\n",
    "\n",
    "    X_val = data_dict[f\"X_val_{fold}\"]\n",
    "    y_val = data_dict[f\"y_val_{fold}\"]\n",
    "\n",
    "    X_test = data_dict[f\"X_test_{fold}\"]\n",
    "    y_test = data_dict[f\"y_test_{fold}\"]\n",
    "\n",
    "    target_scaler = data_dict[f\"target_scaler_{fold}\"]\n",
    "\n",
    "    y_train_val = np.concatenate([y_train,y_val])\n",
    "\n",
    "    # Define data subset for LR\n",
    "    z_glmm_encoded_train = data_dict[f\"z_glmm_encoded_train_{fold}\"] \n",
    "    z_glmm_encoded_val = data_dict[f\"z_glmm_encoded_val_{fold}\"] \n",
    "    z_glmm_encoded_test = data_dict[f\"z_glmm_encoded_test_{fold}\"] \n",
    "\n",
    "    X_train_lr = pd.concat([X_train,z_glmm_encoded_train],axis=1)\n",
    "    X_val_lr = pd.concat([X_val,z_glmm_encoded_val],axis=1)\n",
    "    X_test_lr = pd.concat([X_test,z_glmm_encoded_test],axis=1)      \n",
    "    X_train_val_lr = pd.concat([X_train_lr,X_val_lr])\n",
    "\n",
    "    # Rescale GLMM\n",
    "    for col in z_glmm_encoded_train.columns:\n",
    "        z_mean = X_train_val_lr[col].mean()\n",
    "        z_std = X_train_val_lr[col].std()\n",
    "\n",
    "        X_train_val_lr[col] = (X_train_val_lr[col]-z_mean)/z_std\n",
    "        X_test_lr[col] = (X_test_lr[col]-z_mean)/z_std\n",
    "\n",
    "\n",
    "    # Define data subset for XGB\n",
    "    z_ordinal_encoded_train = data_dict[f\"z_ordinal_encoded_train_{fold}\"] \n",
    "    z_ordinal_encoded_val = data_dict[f\"z_ordinal_encoded_val_{fold}\"] \n",
    "    z_ordinal_encoded_test = data_dict[f\"z_ordinal_encoded_test_{fold}\"] \n",
    "    X_train_xgb = pd.concat([X_train,z_ordinal_encoded_train],axis=1)\n",
    "    X_val_xgb = pd.concat([X_val,z_ordinal_encoded_val],axis=1)\n",
    "    X_test_xgb = pd.concat([X_test,z_ordinal_encoded_test],axis=1)\n",
    "    X_train_val_xgb = pd.concat([X_train_xgb,X_val_xgb])\n",
    "\n",
    "    final_hyperparameters = tune_lasso(X_train_val_lr, y_train_val, max_evals=max_evals, seed=RS)\n",
    "    lr = Lasso(alpha=final_hyperparameters[\"alpha\"],\n",
    "               random_state=RS)\n",
    "#     lr = Lasso(alpha=0.001)\n",
    "    lr.fit(X_train_val_lr,y_train_val)\n",
    "    y_pred = target_scaler.inverse_transform(lr.predict(X_test_lr).reshape(-1,1)).ravel()\n",
    "\n",
    "    is_not_demo = [i not in demographic_cols for i in X_train_val_lr.columns]\n",
    "    y_pred_notdemo = target_scaler.inverse_transform(np.dot(X_test_lr.loc[:,is_not_demo],lr.coef_[is_not_demo]).reshape(-1,1)).ravel()\n",
    "    mean_abs_diff = np.round(np.mean(np.abs(y_pred-y_pred_notdemo)),2)\n",
    "    print(f\"Mean absolute Difference w\\o Demo: {mean_abs_diff}\")\n",
    "    print(f\"RMSE Difference w\\o Demo: {np.round(np.sqrt(np.mean(np.power(y_pred-y_pred_notdemo,2))),2)}\")\n",
    "    mean_abs_differences.append(mean_abs_diff)\n",
    "    # is_demo = [i in demographic_cols for i in X_train_val_lr.columns]\n",
    "    # y_pred_demo = target_scaler.inverse_transform(np.dot(X_test_lr.loc[:,is_demo],lr.coef_[is_demo]).reshape(-1,1)).ravel()\n",
    "\n",
    "    # print(f\"Mean absolute Difference with Demo: {np.mean(np.abs(y_pred-y_pred_demo))}\")\n",
    "    # print(f\"RMSE Difference with Demo: {np.sqrt(np.mean(np.power(y_pred-y_pred_demo,2)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.97, 0.07)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mean_abs_differences).round(2),np.std(mean_abs_differences).round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc07112e7ae1e8e28a0232207620ff002934c05692de8df42430404c766a0a8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
